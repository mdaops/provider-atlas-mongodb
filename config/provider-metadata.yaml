name: mongodb/mongodbatlas
resources:
    mongodbatlas_access_list_api_key:
        subCategory: ""
        name: mongodbatlas_access_list_api_key
        title: mongodbatlas_access_list_api_key Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "api_key_id": "a29120e123cd",
                  "cidr_block": "1.2.3.4/32",
                  "org_id": "\u003cORG-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "api_key_id": "a29120e123cd",
                  "ip_address": "2.3.4.5",
                  "org_id": "\u003cORG-ID\u003e"
                }
        argumentDocs:
            api_key_id: '- Unique identifier for the Organization API Key for which you want to create a new access list entry.'
            cidr_block: '- (Optional) Range of IP addresses in CIDR notation to be added to the access list. Your access list entry can include only one cidrBlock, or one ipAddress.'
            ip_address: '- (Optional) Single IP address to be added to the access list.'
            org_id: '- (Required) Unique 24-hexadecimal digit string that identifies the organization that contains your projects.'
        importStatements: []
    mongodbatlas_advanced_cluster:
        subCategory: ""
        name: mongodbatlas_advanced_cluster
        title: mongodbatlas_advanced_cluster Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "backing_provider_name": "AWS",
                          "electable_specs": [
                            {
                              "instance_size": "M0"
                            }
                          ],
                          "priority": 7,
                          "provider_name": "TENANT",
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M10"
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "GCP",
                          "region_name": "NORTH_AMERICA_NORTHEAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: cluster
              manifest: |-
                {
                  "advanced_configuration": [
                    {
                      "javascript_enabled": true,
                      "oplog_size_mb": 991,
                      "sample_refresh_interval_bi_connector": 300
                    }
                  ],
                  "backup_enabled": true,
                  "cluster_type": "SHARDED",
                  "name": "${var.cluster_name}",
                  "project_id": "${mongodbatlas_project.project.id}",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "US_EAST_2"
                        }
                      ]
                    },
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "US_EAST_2"
                        }
                      ]
                    }
                  ]
                }
              references:
                name: var.cluster_name
                project_id: mongodbatlas_project.project.id
            - name: cluster
              manifest: |-
                {
                  "advanced_configuration": [
                    {
                      "javascript_enabled": true,
                      "oplog_size_mb": 999,
                      "sample_refresh_interval_bi_connector": 300
                    }
                  ],
                  "backup_enabled": true,
                  "cluster_type": "GEOSHARDED",
                  "name": "${var.cluster_name}",
                  "project_id": "${mongodbatlas_project.project.id}",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "US_EAST_2"
                        }
                      ],
                      "zone_name": "zone n1"
                    },
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "US_EAST_2"
                        }
                      ],
                      "zone_name": "zone n1"
                    },
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "EU_WEST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "EUROPE_NORTH"
                        }
                      ],
                      "zone_name": "zone n2"
                    },
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "EU_WEST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M30",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "EUROPE_NORTH"
                        }
                      ],
                      "zone_name": "zone n2"
                    }
                  ]
                }
              references:
                name: var.cluster_name
                project_id: mongodbatlas_project.project.id
        argumentDocs:
            AWS: '- Amazon AWS'
            AZURE: '- Microsoft Azure'
            CONTINUOUS: ':  Atlas creates your cluster using the most recent MongoDB release. Atlas automatically updates your cluster to the latest major and rapid MongoDB releases as they become available.'
            GCP: '- Google Cloud Platform'
            LTS: ': Atlas creates your cluster using the latest patch release of the MongoDB version that you specify in the mongoDBMajorVersion field. Atlas automatically updates your cluster to subsequent patch releases of this MongoDB version. Atlas doesn''t update your cluster to newer rapid or major MongoDB releases as they become available.'
            PROVISIONED: volume types must fall within the allowable IOPS range for the selected volume size.
            STANDARD: volume types can't exceed the default IOPS rate for the selected volume size.
            TENANT: '- M0, M2 or M5 multi-tenant cluster. Use replication_specs.#.region_configs.#.backing_provider_name to set the cloud service provider.'
            accept_data_risks_and_force_replica_set_reconfig: '- (Optional) If reconfiguration is necessary to regain a primary due to a regional outage, submit this field alongside your topology reconfiguration to request a new regional outage resistant topology. Forced reconfigurations during an outage of the majority of electable nodes carry a risk of data loss if replicated writes (even majority committed writes) have not been replicated to the new primary node. MongoDB Atlas docs contain more information. To proceed with an operation which carries that risk, set accept_data_risks_and_force_replica_set_reconfig to the current date. Learn more about Reconfiguring a Replica Set during a regional outage here.'
            backup_enabled: |-
                - (Optional) Flag that indicates whether the cluster can perform backups.
                If true, the cluster can perform backups. You must set this value to true for NVMe clusters.
            bi_connector_config: '- (Optional) Configuration settings applied to BI Connector for Atlas on this cluster. The MongoDB Connector for Business Intelligence for Atlas (BI Connector) is only available for M10 and larger clusters. The BI Connector is a powerful tool which provides users SQL-based access to their MongoDB databases. As a result, the BI Connector performs operations which may be CPU and memory intensive. Given the limited hardware resources on M10 and M20 cluster tiers, you may experience performance degradation of the cluster when enabling the BI Connector. If this occurs, upgrade to an M30 or larger cluster or disable the BI Connector. See below.'
            bi_connector_config.enabled: '- (Optional) Specifies whether or not BI Connector for Atlas is enabled on the cluster.l'
            bi_connector_config.false: to disable BI Connector for Atlas.
            bi_connector_config.read_preference: '- (Optional) Specifies the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of readPreference and readPreferenceTags options. For details on BI Connector for Atlas read preferences, refer to the BI Connector Read Preferences Table.'
            bi_connector_config.true: to enable BI Connector for Atlas.
            change_stream_options_pre_and_post_images_expire_after_seconds: '- (Optional) The minimum pre- and post-image retention time in seconds. This option corresponds to the changeStreamOptions.preAndPostImages.expireAfterSeconds cluster parameter. Defaults to -1(off). This setting controls the retention policy of change stream pre- and post-images. Pre- and post-images are the versions of a document before and after document modification, respectively. expireAfterSeconds controls how long MongoDB retains pre- and post-images. When set to -1 (off), MongoDB uses the default retention policy: pre- and post-images are retained until the corresponding change stream events are removed from the oplog. To set the minimum pre- and post-image retention time, specify an integer value greater than zero. Setting this too low could increase the risk of interrupting Realm sync or triggers processing. This parameter is only supported for MongoDB version 6.0 and above.'
            cluster_id: '- The cluster ID.'
            cluster_type: |-
                - (Required)Type of the cluster that you want to create.
                Accepted values include:
                - REPLICASET Replica set
                - SHARDED	Sharded cluster
                - GEOSHARDED Global Cluster
            config_server_management_mode: '- (Optional) Config Server Management Mode for creating or updating a sharded cluster. Valid values are ATLAS_MANAGED (default) and FIXED_TO_DEDICATED. When configured as ATLAS_MANAGED, Atlas may automatically switch the cluster''s config server type for optimal performance and savings. When configured as FIXED_TO_DEDICATED, the cluster will always use a dedicated config server. To learn more, see the Sharded Cluster Config Servers documentation.'
            config_server_type: Describes a sharded cluster's config server type. Valid values are DEDICATED and EMBEDDED. To learn more, see the Sharded Cluster Config Servers documentation.
            connection_strings: '- Set of connection strings that your applications use to connect to this cluster. More info in Connection-strings. Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see Connection String Options. NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.'
            connection_strings.private: '-   Network-peering-endpoint-aware mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.private_endpoint: '- Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster''s nodes.'
            connection_strings.private_endpoint.#.connection_string: '- Private-endpoint-aware mongodb://connection string for this private endpoint.'
            connection_strings.private_endpoint.#.endpoints: '- Private endpoint through which you connect to Atlas when you use connection_strings.private_endpoint[n].connection_string or connection_strings.private_endpoint[n].srv_connection_string'
            connection_strings.private_endpoint.#.endpoints.#.endpoint_id: '- Unique identifier of the private endpoint.'
            connection_strings.private_endpoint.#.endpoints.#.provider_name: '- Cloud provider to which you deployed the private endpoint. Atlas returns AWS or AZURE.'
            connection_strings.private_endpoint.#.endpoints.#.region: '- Region to which you deployed the private endpoint.'
            connection_strings.private_endpoint.#.srv_connection_string: '- Private-endpoint-aware mongodb+srv:// connection string for this private endpoint. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don''t need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn''t, use connection_strings.private_endpoint[n].connection_string'
            connection_strings.private_endpoint.#.srv_shard_optimized_connection_string: '- Private endpoint-aware connection string optimized for sharded clusters that uses the mongodb+srv:// protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don''t need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn''t, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.'
            connection_strings.private_endpoint.#.type: '- Type of MongoDB process that you connect to with the connection strings. Atlas returns MONGOD for replica sets, or MONGOS for sharded clusters.'
            connection_strings.private_srv: '-  Network-peering-endpoint-aware mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.standard: '-   Public mongodb:// connection string for this cluster.'
            connection_strings.standard_srv: '- Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.'
            custom_openssl_cipher_config_tls12: '- (Optional) The custom OpenSSL cipher suite list for TLS 1.2. This field is only valid when tls_cipher_config_mode is set to CUSTOM.'
            default_max_time_ms: '- (Optional) Default time limit in milliseconds for individual read operations to complete. This option corresponds to the [defaultMaxTimeMS(https://www.mongodb.com/docs/upcoming/reference/cluster-parameters/defaultMaxTimeMS/) cluster parameter. This parameter is supported only for MongoDB version 8.0 and above.'
            default_read_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for read operations set for this cluster. MongoDB 4.4 clusters default to available. (DEPRECATED) MongoDB 5.0 and later clusters default to local. To use a custom read concern level, please refer to your driver documentation.'
            default_write_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for write operations set for this cluster. MongoDB 4.4 clusters default to 1.'
            disk_gb_enabled.compute_max_instance_size: '- (Optional) Maximum instance size to which your cluster can automatically scale (such as M40). Atlas requires this parameter if replication_specs.#.region_configs.#.auto_scaling.0.compute_enabled is true.'
            disk_gb_enabled.compute_min_instance_size: '- (Optional) Minimum instance size to which your cluster can automatically scale (such as M10). Atlas requires this parameter if replication_specs.#.region_configs.#.auto_scaling.0.compute_scale_down_enabled is true.'
            disk_gb_enabled.compute_scale_down_enabled: '- (Optional) Flag that indicates whether the instance size may scale down. Atlas requires this parameter if replication_specs.#.region_configs.#.auto_scaling.0.compute_enabled : true. If you enable this option, specify a value for replication_specs.#.region_configs.#.auto_scaling.0.compute_min_instance_size.'
            disk_size_gb: '- (Optional) Capacity, in gigabytes, of the host''s root volume. Increase this number to add capacity, up to a maximum possible value of 4096 (4 TB). This value must be a positive number. You can''t set this value with clusters with local NVMe SSDs. The minimum disk size for dedicated clusters is 10 GB for AWS and GCP. If you specify diskSizeGB with a lower disk size, Atlas defaults to the minimum disk size value. If your cluster includes Azure nodes, this value must correspond to an existing Azure disk type (8, 16, 32, 64, 128, 256, 512, 1024, 2048, or 4095)Atlas calculates storage charges differently depending on whether you choose the default value or a custom value. The maximum value for disk storage cannot exceed 50 times the maximum RAM for the selected cluster. If you require additional storage space beyond this limitation, consider upgrading your cluster to a higher tier. If your cluster spans cloud service providers, this value defaults to the minimum default of the providers involved. (DEPRECATED) Use replication_specs.#.region_config.#.(analytics_specs|electable_specs|read_only_specs).disk_size_gb instead. To learn more, see the 1.18.0 upgrade guide.'
            encryption_at_rest_provider: '- (Optional) Possible values are AWS, GCP, AZURE or NONE.  Only needed if you desire to manage the keys, see Encryption at Rest using Customer Key Management for complete documentation.  You must configure encryption at rest for the Atlas project before enabling it on any cluster in the project. For Documentation, see AWS, GCP and Azure. Requirements are if replication_specs.#.region_configs.#.<type>Specs.instance_size is M10 or greater and backup_enabled is false or omitted.'
            fail_index_key_too_long: '- (Optional) When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them. (DEPRECATED) This parameter has been removed as of MongoDB 4.4.'
            global_cluster_self_managed_sharding: '- (Optional) Flag that indicates if cluster uses Atlas-Managed Sharding (false, default) or Self-Managed Sharding (true). It can only be enabled for Global Clusters (GEOSHARDED). It cannot be changed once the cluster is created. Use this mode if you''re an advanced user and the default configuration is too restrictive for your workload. If you select this option, you must manually configure the sharding strategy, more info here.'
            id: "-\tThe Terraform's unique identifier used internally for state management."
            javascript_enabled: '- (Optional) When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.'
            key: '- (Required) Constant that defines the set of the tag.'
            labels: '- (Optional) Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below. DEPRECATED Use tags instead.'
            labels.key: '- The key that you want to write.'
            labels.value: '- The value that you want to write.'
            minimum_enabled_tls_protocol: '- (Optional) Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:'
            mongo_db_major_version: '- (Optional) Version of the cluster to deploy. Atlas supports all the MongoDB versions that have not reached End of Live for M10+ clusters. If omitted, Atlas deploys the cluster with the default version. For more details, see documentation. Atlas always deploys the cluster with the latest stable release of the specified version.  If you set a value to this parameter and set version_release_system CONTINUOUS, the resource returns an error. Either clear this parameter or set version_release_system: LTS.'
            mongo_db_version: '- Version of MongoDB the cluster runs, in major-version.minor-version format.'
            mongodbatlas_privatelink_endpoint_service: resources are fully applied. Add a depends_on = [mongodbatlas_privatelink_endpoint_service.example] to ensure connection_strings are available following terraform apply. If the expected connection string(s) do not contain a value, a terraform refresh may need to be performed to obtain the value. One can also view the status of the peered connection in the Atlas UI.
            name: '- (Required) Name of the cluster as it appears in Atlas. Once the cluster is created, its name cannot be changed. WARNING Changing the name will result in destruction of the existing cluster and the creation of a new cluster.'
            no_table_scan: '- (Optional) When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.'
            oplog_min_retention_hours: '- (Optional) Minimum retention window for cluster''s oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.'
            oplog_size_mb: '- (Optional) The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.'
            paused: |-
                (Optional) - Flag that indicates whether the cluster is paused or not. You can pause M10 or larger clusters.  You cannot initiate pausing for a shared/tenant tier cluster. If you try to update a paused cluster you will get a CANNOT_UPDATE_PAUSED_CLUSTER error. See Considerations for Paused Clusters.
                NOTE Pause lasts for up to 30 days. If you don't resume the cluster within 30 days, Atlas resumes the cluster.  When the cluster resumption happens Terraform will flag the changed state.  If you wish to keep the cluster paused, reapply your Terraform configuration.   If you prefer to allow the automated change of state to unpaused use:
                lifecycle { ignore_changes = [paused] }
            pinned_fcv: '- (Optional) Pins the Feature Compatibility Version (FCV) to the current MongoDB version with a provided expiration date. To unpin the FCV the pinned_fcv attribute must be removed. This operation can take several minutes as the request processes through the MongoDB data plane. Once FCV is unpinned it will not be possible to downgrade the mongo_db_major_version. It is advised that updates to pinned_fcv are done isolated from other cluster changes. If a plan contains multiple changes, the FCV change will be applied first. If FCV is unpinned past the expiration date the pinned_fcv attribute must be removed. The following knowledge hub article and FCV documentation can be referenced for more details. See below.'
            pinned_fcv.expiration_date: '- (Required) Expiration date of the fixed FCV. This value is in the ISO 8601 timestamp format (e.g. "2024-12-04T16:25:00Z"). Note that this field cannot exceed 4 weeks from the pinned date.'
            pinned_fcv.version: '- Feature compatibility version of the cluster.'
            pit_enabled: '- (Optional) Flag that indicates if the cluster uses Continuous Cloud Backup.'
            project_id: '- (Required) Unique ID for the project to create the database user.'
            redact_client_log_data: '- (Optional) Flag that enables or disables log redaction, see the manual for more info. Use this in conjunction with Encryption at Rest and TLS/SSL (Transport Encryption) to assist compliance with regulatory requirements. Note: Changing this setting on a cluster will trigger a rolling restart as soon as the cluster is updated.'
            region_configs: objects (your cluster is multi-region or multi-cloud), they must have priorities in descending order. The highest priority is 7.
            region_configs.#.electable_specs.0.node_count: to 1 or higher, it must have a priority of exactly one (1) less than another region in the replication_specs.#.region_configs.# array. The highest-priority region must have a priority of 7. The lowest possible priority is 1.
            region_configs.provider_name: |-
                - (Optional) Cloud service provider on which the servers are provisioned.
                The possible values are:
            region_configs.read_only_specs: '- (Optional) Hardware specifications for read-only nodes in the region. Read-only nodes can become the primary and can enable local reads. If you don''t specify this parameter, no read-only nodes are deployed to the region. See below'
            region_configs.read_only_specs.disk_iops: '- (Optional) Target IOPS (Input/Output Operations Per Second) desired for storage attached to this hardware. Define this attribute only if you selected AWS as your cloud service provider, instance_size is set to "M30" or greater (not including "Mxx_NVME" tiers), and ebs_volume_type is "PROVISIONED". You can''t set this attribute for a multi-cloud cluster. This parameter defaults to the cluster tier''s standard IOPS value.'
            region_configs.read_only_specs.disk_size_gb: '- (Optional) Storage capacity that the host''s root volume possesses expressed in gigabytes. This value must be equal for all shards and node types. If disk size specified is below the minimum (10 GB), this parameter defaults to the minimum disk size value. Storage charge calculations depend on whether you choose the default value or a custom value.  The maximum value for disk storage cannot exceed 50 times the maximum RAM for the selected cluster. If you require more storage space, consider upgrading your cluster to a higher tier. Note: Using disk_size_gb with Standard IOPS could lead to errors and configuration issues. Therefore, it should be used only with the Provisioned IOPS volume type. When using Provisioned IOPS, the disk_size_gb parameter specifies the storage capacity, but the IOPS are set independently. Ensuring that disk_size_gb is used exclusively with Provisioned IOPS will help avoid these issues.'
            region_configs.read_only_specs.ebs_volume_type: '- (Optional) Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster. Valid values are:'
            region_configs.read_only_specs.instance_size: '- (Required) Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size. Electable nodes and read-only nodes (known as "base nodes") within a single shard must use the same instance size. Analytics nodes can scale independently from base nodes within a shard. Both base nodes and analytics nodes can scale independently from their equivalents in other shards.'
            region_configs.read_only_specs.node_count: '- (Optional) Number of nodes of the given type for MongoDB Atlas to deploy to the region.'
            region_configs.region_name: '- (Optional) Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases.  Requires the Atlas region name, see the reference list for AWS, GCP, Azure.'
            replica_set_scaling_strategy: '- (Optional) Replica set scaling mode for your cluster. Valid values are WORKLOAD_TYPE, SEQUENTIAL and NODE_TYPE. By default, Atlas scales under WORKLOAD_TYPE. This mode allows Atlas to scale your analytics nodes in parallel to your operational nodes. When configured as SEQUENTIAL, Atlas scales all nodes sequentially. This mode is intended for steady-state workloads and applications performing latency-sensitive secondary reads. When configured as NODE_TYPE, Atlas scales your electable nodes in parallel with your read-only and analytics nodes. This mode is intended for large, dynamic workloads requiring frequent and timely cluster tier scaling. This is the fastest scaling strategy, but it might impact latency of workloads when performing extensive secondary reads. Modify the Replica Set Scaling Mode'
            replication_specs: '- List of settings that configure your cluster regions. This attribute has one object per shard representing node configurations in each shard. For replica sets there is only one object representing node configurations. If for each replication_spec num_shards is configured with a value greater than 1 (using deprecated sharding configurations), then each object represents a zone with one or more shards. See below'
            replication_specs.#.container_id: '- A key-value map of the Network Peering Container ID(s) for the configuration specified in region_configs. The Container ID is the id of the container created when the first cluster in the region (AWS/Azure) or project (GCP) was created.  The syntax is "providerName:regionName" = "containerId". Example AWS:US_EAST_1" = "61e0797dde08fb498ca11a71.'
            replication_specs.external_id: '- Unique 24-hexadecimal digit string that identifies the replication object for a shard in a Cluster. This value corresponds to Shard ID displayed in the UI. When using old sharding configuration (replication spec with num_shards greater than 1) this value is not populated.'
            replication_specs.id: '- (DEPRECATED) Unique identifer of the replication document for a zone in a Global Cluster. This value corresponds to the legacy sharding schema (no independent shard scaling) and is different from the Shard ID you may see in the Atlas UI. This value is not populated (empty string) when a sharded cluster has independently scaled shards.'
            replication_specs.num_shards: |-
                - (Optional) Provide this value if you set a cluster_type of SHARDED or GEOSHARDED. Omit this value if you selected a cluster_type of REPLICASET. This API resource accepts 1 through 50, inclusive. This parameter defaults to 1. If you specify a num_shards value of 1 and a cluster_type of SHARDED, Atlas deploys a single-shard sharded cluster. Don't create a sharded cluster with a single shard for production environments. Single-shard sharded clusters don't provide the same benefits as multi-shard configurations.
                If you are upgrading a replica set to a sharded cluster, you cannot increase the number of shards in the same update request. You should wait until after the cluster has completed upgrading to sharded and you have reconnected all application clients to the MongoDB router before adding additional shards. Otherwise, your data might become inconsistent once MongoDB Cloud begins distributing data across shards. To learn more, see Convert a replica set to a sharded cluster documentation and Convert a replica set to a sharded cluster tutorial. (DEPRECATED) To learn more, see the 1.18.0 Upgrade Guide.
            replication_specs.region_configs: '- (Optional) Configuration for the hardware specifications for nodes set for a given regionEach region_configs object describes the region''s priority in elections and the number and type of MongoDB nodes that Atlas deploys to the region. Each region_configs object must have either an analytics_specs object, electable_specs object, or read_only_specs object. See below'
            replication_specs.region_configs.analytics_auto_scaling: '- (Optional) Configuration for the Collection of settings that configures analytics-auto-scaling information for the cluster. The values for the analytics_auto_scaling attribute must be the same for all region_configs of a cluster. See below'
            replication_specs.region_configs.analytics_auto_scaling.compute_enabled: '- (Optional) Flag that indicates whether analytics instance size auto-scaling is enabled. This parameter defaults to false. If a sharded cluster is making use of the New Sharding Configuration, auto-scaling of analytics instance size will be independent for each individual shard. Please reference the Use Auto-Scaling Per Shard section for more details. On the contrary, if a sharded cluster makes use of deprecated num_shards attribute (with values > 1), analytics instance size auto-scaling will be performed uniformily across all shards in the cluster.'
            replication_specs.region_configs.analytics_auto_scaling.disk_gb_enabled: '- (Optional) Flag that indicates whether this cluster enables disk auto-scaling. This parameter defaults to false.'
            replication_specs.region_configs.analytics_auto_scaling.disk_gb_enabled.compute_max_instance_size: '- (Optional) Maximum instance size to which your cluster can automatically scale (such as M40). Atlas requires this parameter if replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_enabled is true.'
            replication_specs.region_configs.analytics_auto_scaling.disk_gb_enabled.compute_min_instance_size: '- (Optional) Minimum instance size to which your cluster can automatically scale (such as M10). Atlas requires this parameter if replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_scale_down_enabled is true.'
            replication_specs.region_configs.analytics_auto_scaling.disk_gb_enabled.compute_scale_down_enabled: '- (Optional) Flag that indicates whether the instance size may scale down. Atlas requires this parameter if replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_enabled : true. If you enable this option, specify a value for replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_min_instance_size.'
            replication_specs.region_configs.analytics_specs: '- (Optional) Hardware specifications for analytics nodes needed in the region. Analytics nodes handle analytic data such as reporting queries from BI Connector for Atlas. Analytics nodes are read-only and can never become the primary. If you don''t specify this parameter, no analytics nodes deploy to this region. See below'
            replication_specs.region_configs.analytics_specs.disk_iops: '- (Optional) Target IOPS (Input/Output Operations Per Second) desired for storage attached to this hardware. Define this attribute only if you selected AWS as your cloud service provider, instance_size is set to "M30" or greater (not including "Mxx_NVME" tiers), and ebs_volume_type is "PROVISIONED". You can''t set this attribute for a multi-cloud cluster.'
            replication_specs.region_configs.analytics_specs.disk_size_gb: '- (Optional) Storage capacity that the host''s root volume possesses expressed in gigabytes. This value must be equal for all shards and node types. If disk size specified is below the minimum (10 GB), this parameter defaults to the minimum disk size value. Storage charge calculations depend on whether you choose the default value or a custom value.  The maximum value for disk storage cannot exceed 50 times the maximum RAM for the selected cluster. If you require more storage space, consider upgrading your cluster to a higher tier. Note: Using disk_size_gb with Standard IOPS could lead to errors and configuration issues. Therefore, it should be used only with the Provisioned IOPS volume type. When using Provisioned IOPS, the disk_size_gb parameter specifies the storage capacity, but the IOPS are set independently. Ensuring that disk_size_gb is used exclusively with Provisioned IOPS will help avoid these issues.'
            replication_specs.region_configs.analytics_specs.ebs_volume_type: '- (Optional) Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster. Valid values are:'
            replication_specs.region_configs.analytics_specs.instance_size: '- (Required) Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size. Electable nodes and read-only nodes (known as "base nodes") within a single shard must use the same instance size. Analytics nodes can scale independently from base nodes within a shard. Both base nodes and analytics nodes can scale independently from their equivalents in other shards.'
            replication_specs.region_configs.analytics_specs.node_count: '- (Optional) Number of nodes of the given type for MongoDB Atlas to deploy to the region.'
            replication_specs.region_configs.auto_scaling: '- (Optional) Configuration for the collection of settings that configures auto-scaling information for the cluster. The values for the auto_scaling attribute must be the same for all region_configs of a cluster. See below'
            replication_specs.region_configs.auto_scaling.compute_enabled: '- (Optional) Flag that indicates whether instance size auto-scaling is enabled. This parameter defaults to false. If a sharded cluster is making use of the New Sharding Configuration, auto-scaling of the instance size will be independent for each individual shard. Please reference the Use Auto-Scaling Per Shard section for more details. On the contrary, if a sharded cluster makes use of deprecated num_shards attribute (with values > 1), instance size auto-scaling will be performed uniformly across all shards in the cluster.'
            replication_specs.region_configs.auto_scaling.disk_gb_enabled: '- (Optional) Flag that indicates whether this cluster enables disk auto-scaling. This parameter defaults to false.'
            replication_specs.region_configs.backing_provider_name: '- (Optional) Cloud service provider on which you provision the host for a multi-tenant cluster. Use this only when a provider_name is TENANT and instance_size of a specs is M2 or M5.'
            replication_specs.region_configs.electable_specs: '- (Optional) Hardware specifications for electable nodes in the region. Electable nodes can become the primary and can enable local reads. If you do not specify this option, no electable nodes are deployed to the region. See below'
            replication_specs.region_configs.electable_specs.disk_iops: '- (Optional) Target IOPS (Input/Output Operations Per Second) desired for storage attached to this hardware. Define this attribute only if you selected AWS as your cloud service provider, instance_size is set to "M30" or greater (not including "Mxx_NVME" tiers), and ebs_volume_type is "PROVISIONED". You can''t set this attribute for a multi-cloud cluster.'
            replication_specs.region_configs.electable_specs.disk_size_gb: '- (Optional) Storage capacity that the host''s root volume possesses expressed in gigabytes. This value must be equal for all shards and node types. If disk size specified is below the minimum (10 GB), this parameter defaults to the minimum disk size value. Storage charge calculations depend on whether you choose the default value or a custom value.  The maximum value for disk storage cannot exceed 50 times the maximum RAM for the selected cluster. If you require more storage space, consider upgrading your cluster to a higher tier. Note: Using disk_size_gb with Standard IOPS could lead to errors and configuration issues. Therefore, it should be used only with the Provisioned IOPS volume type. When using Provisioned IOPS, the disk_size_gb parameter specifies the storage capacity, but the IOPS are set independently. Ensuring that disk_size_gb is used exclusively with Provisioned IOPS will help avoid these issues.'
            replication_specs.region_configs.electable_specs.ebs_volume_type: '- (Optional) Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster. Valid values are:'
            replication_specs.region_configs.electable_specs.instance_size: '- (Required) Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size. Electable nodes and read-only nodes (known as "base nodes") within a single shard must use the same instance size. Analytics nodes can scale independently from base nodes within a shard. Both base nodes and analytics nodes can scale independently from their equivalents in other shards.'
            replication_specs.region_configs.electable_specs.node_count: '- (Optional) Number of nodes of the given type for MongoDB Atlas to deploy to the region.'
            replication_specs.region_configs.priority: '- (Optional)  Election priority of the region. For regions with only read-only nodes, set this value to 0.'
            replication_specs.zone_id: '- Unique 24-hexadecimal digit string that identifies the zone in a Global Cluster. If clusterType is GEOSHARDED, this value indicates the zone that the given shard belongs to and can be used to configure Global Cluster backup policies.'
            replication_specs.zone_name: '- (Optional) Name for the zone in a Global Cluster.'
            retain_backups_enabled: '- (Optional) Set to true to retain backup snapshots for the deleted cluster. M10 and above only.'
            root_cert_type: '- (Optional) - Certificate Authority that MongoDB Atlas clusters use. You can specify ISRGROOTX1 (for ISRG Root X1).'
            sample_refresh_interval_bi_connector: '- (Optional) Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            sample_size_bi_connector: '- (Optional) Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            state_name: '- Current state of the cluster. The possible states are:'
            tags: '- (Optional) Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.'
            termination_protection_enabled: '- Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won''t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.'
            timeouts: '- (Optional) The duration of time to wait for Cluster to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Advanced Cluster create & delete is 3h. Learn more about timeouts here.'
            tls_cipher_config_mode: '- (Optional) The TLS cipher suite configuration mode. Valid values include CUSTOM or DEFAULT. The DEFAULT mode uses the default cipher suites. The CUSTOM mode allows you to specify custom cipher suites for both TLS 1.2 and TLS 1.3. To unset, this should be set back to DEFAULT.'
            transaction_lifetime_limit_seconds: '- (Optional) Lifetime, in seconds, of multi-document transactions. Defaults to 60 seconds.'
            value: '- (Required) Variable that belongs to the set of the tag.'
            version_release_system: '- (Optional) - Release cadence that Atlas uses for this cluster. This parameter defaults to LTS. If you set this field to CONTINUOUS, you must omit the mongo_db_major_version field. Atlas accepts:'
        importStatements: []
    mongodbatlas_alert_configuration:
        subCategory: ""
        name: mongodbatlas_alert_configuration
        title: mongodbatlas_alert_configuration Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "event_type": "OUTSIDE_METRIC_THRESHOLD",
                  "matcher": [
                    {
                      "field_name": "HOSTNAME_AND_PORT",
                      "operator": "EQUALS",
                      "value": "SECONDARY"
                    }
                  ],
                  "metric_threshold_config": [
                    {
                      "metric_name": "ASSERT_REGULAR",
                      "mode": "AVERAGE",
                      "operator": "LESS_THAN",
                      "threshold": 99,
                      "units": "RAW"
                    }
                  ],
                  "notification": [
                    {
                      "delay_min": 0,
                      "email_enabled": true,
                      "interval_min": 5,
                      "roles": [
                        "GROUP_CLUSTER_MANAGER"
                      ],
                      "sms_enabled": false,
                      "type_name": "GROUP"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "event_type": "REPLICATION_OPLOG_WINDOW_RUNNING_OUT",
                  "matcher": [
                    {
                      "field_name": "CLUSTER_NAME",
                      "operator": "EQUALS",
                      "value": "my-cluster"
                    }
                  ],
                  "notification": [
                    {
                      "delay_min": 0,
                      "email_enabled": true,
                      "interval_min": 5,
                      "roles": [
                        "GROUP_CLUSTER_MANAGER"
                      ],
                      "sms_enabled": false,
                      "type_name": "GROUP"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "threshold_config": [
                    {
                      "operator": "LESS_THAN",
                      "threshold": 1,
                      "units": "HOURS"
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "event_type": "OUTSIDE_METRIC_THRESHOLD",
                  "matcher": [
                    {
                      "field_name": "HOSTNAME_AND_PORT",
                      "operator": "EQUALS",
                      "value": "SECONDARY"
                    }
                  ],
                  "metric_threshold_config": [
                    {
                      "metric_name": "ASSERT_REGULAR",
                      "mode": "AVERAGE",
                      "operator": "LESS_THAN",
                      "threshold": 99,
                      "units": "RAW"
                    }
                  ],
                  "notification": [
                    {
                      "delay_min": 0,
                      "email_enabled": true,
                      "interval_min": 5,
                      "roles": [
                        "GROUP_DATA_ACCESS_READ_ONLY",
                        "GROUP_CLUSTER_MANAGER",
                        "GROUP_DATA_ACCESS_ADMIN"
                      ],
                      "sms_enabled": false,
                      "type_name": "GROUP"
                    },
                    {
                      "delay_min": 0,
                      "email_enabled": false,
                      "interval_min": 5,
                      "sms_enabled": true,
                      "type_name": "ORG"
                    }
                  ],
                  "project_id": "PROJECT ID"
                }
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "event_type": "USERS_WITHOUT_MULTI_FACTOR_AUTH",
                  "notification": [
                    {
                      "integration_id": "${data.mongodbatlas_third_party_integration.test.id}",
                      "type_name": "PAGER_DUTY"
                    }
                  ],
                  "project_id": "PROJECT ID"
                }
              references:
                notification.integration_id: data.mongodbatlas_third_party_integration.test.id
        argumentDocs:
            GROUP: (Project)
            GROUP_CLUSTER_MANAGER: |-
                | ORG_OWNER         |
                | GROUP_DATA_ACCESS_ADMIN       | ORG_MEMBER        |
                | GROUP_DATA_ACCESS_READ_ONLY   | ORG_GROUP_CREATOR |
                | GROUP_DATA_ACCESS_READ_WRITE  | ORG_BILLING_ADMIN |
                | GROUP_OWNER                   | ORG_READ_ONLY     |
                | GROUP_READ_ONLY               |                     |
            alert_configuration_id: '- Unique identifier for the alert configuration.'
            api_token: '- Slack API token. Required for the SLACK notifications type. If the token later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.'
            channel_name: '- Slack channel name. Required for the SLACK notifications type.'
            created: '- Timestamp in ISO 8601 date and time format in UTC when this alert configuration was created.'
            datadog_api_key: '- Datadog API Key. Found in the Datadog dashboard. Required for the DATADOG notifications type.'
            datadog_region: '- Region that indicates which API URL to use. See the datadogRegion field in the notifications request parameter of MongoDB API Alert Configuration documentation for more details. The default Datadog region is US.'
            delay_min: '- Number of minutes to wait after an alert condition is detected before sending out the first notification.'
            email_address: '- Email address to which alert notifications are sent. Required for the EMAIL notifications type.'
            email_enabled: '- Flag indicating email notifications should be sent. This flag is only valid if type_name is set to ORG, GROUP, or USER.'
            enabled: '- It is not required, but If the attribute is omitted, by default will be false, and the configuration would be disabled. You must set true to enable the configuration.'
            event_type: '- (Required) The type of event that will trigger an alert.'
            field_name: '- (Required) Name of the field in the target object to match on.'
            group_id: '- Unique identifier of the project that owns this alert configuration.'
            id: '- Unique identifier used for terraform for internal manages and can be used to import.'
            integration_id: '- The ID of the associated integration, the credentials of which to use for requests.'
            interval_min: '- Number of minutes to wait between successive notifications for unacknowledged alerts that are not resolved. The minimum value is 5. NOTE PAGER_DUTY, VICTOR_OPS, and OPS_GENIE notifications do not return this value. The notification interval must be configured and managed within each external service.'
            metric_name: '- (Required) Name of the metric to check. The full list being quite large, please refer to atlas docs here for general metrics and here for serverless metrics'
            microsoft_teams_webhook_url: '- Microsoft Teams Webhook Uniform Resource Locator (URL) that MongoDB Cloud needs to send this notification via Microsoft Teams. Required if type_name is MICROSOFT_TEAMS. If the URL later becomes invalid, MongoDB Cloud sends an email to the project owners. If the key remains invalid, MongoDB Cloud removes it.'
            mobile_number: '- Mobile number to which alert notifications are sent. Required for the SMS notifications type.'
            mode: '- This must be set to AVERAGE. Atlas computes the current metric value as an average.'
            notifier_id: '- The notifier ID is a system-generated unique identifier assigned to each notification method. This is needed when updating third-party notifications without requiring explicit authentication credentials.'
            operator: |-
                - (Required) The operator to test the field’s value.
                Accepted values are:
            ops_genie_api_key: '- Opsgenie API Key. Required for the OPS_GENIE notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.'
            ops_genie_region: '- Region that indicates which API URL to use. Accepted regions are: US ,EU. The default Opsgenie region is US.'
            project_id: '- (Required) The ID of the project where the alert configuration will create.'
            roles: |-
                - Optional. One or more roles that receive the configured alert. If you include this field, Atlas sends alerts only to users assigned the roles you specify in the array. If you omit this field, Atlas sends alerts to users assigned any role. This parameter is only valid if type_name is set to ORG, GROUP, or USER.
                Accepted values are:
            service_key: '- PagerDuty service key. Required for the PAGER_DUTY notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.'
            sms_enabled: '- Flag indicating if text message notifications should be sent to this user''s mobile phone. This flag is only valid if type_name is set to ORG, GROUP, or USER.'
            team_id: '- Unique identifier of a team.'
            team_name: '- Label for the team that receives this notification.'
            threshold: '- Threshold value outside of which an alert will be triggered.'
            type_name: |-
                - (Required) Type of alert notification.
                Accepted values are:
            units: |-
                - The units for the threshold value. Depends on the type of metric.
                Refer to the MongoDB API Alert Configuration documentation for a list of accepted values.
            updated: '- Timestamp in ISO 8601 date and time format in UTC when this alert configuration was last updated.'
            username: '- Name of the Atlas user to which to send notifications. Only a user in the project that owns the alert configuration is allowed here. Required for the USER notifications type.'
            value: '- (Required) Value to test with the specified operator. If field_name is set to TYPE_NAME, you can match on the following values:'
            victor_ops_api_key: '- VictorOps API key. Required for the VICTOR_OPS notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.'
            victor_ops_routing_key: '- VictorOps routing key. Optional for the VICTOR_OPS notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.'
            webhook_secret: '- Optional authentication secret for the WEBHOOK notifications type.'
            webhook_url: '- Target URL  for the WEBHOOK notifications type.'
        importStatements: []
    mongodbatlas_api_key:
        subCategory: ""
        name: mongodbatlas_api_key
        title: mongodbatlas_api_key Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "description": "key-name",
                  "org_id": "\u003cORG_ID\u003e",
                  "role_names": [
                    "ORG_READ_ONLY"
                  ]
                }
        argumentDocs:
            api_key_id: '- Unique identifier for this Organization API key.'
            description: '- Description of this Organization API key.'
            org_id: '- Unique identifier for the organization whose API keys you want to retrieve. Use the /orgs endpoint to retrieve all organizations to which the authenticated user has access.'
            role_names: |-
                - Name of the role. This resource returns all the roles the user has in Atlas.
                The following are valid roles:
        importStatements: []
    mongodbatlas_auditing:
        subCategory: ""
        name: mongodbatlas_auditing
        title: mongodbatlas_auditing Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "audit_authorization_success": false,
                  "audit_filter": "{ 'atype': 'authenticate', 'param': {   'user': 'auditAdmin',   'db': 'admin',   'mechanism': 'SCRAM-SHA-1' }}",
                  "enabled": true,
                  "project_id": "\u003cproject-id\u003e"
                }
        argumentDocs:
            audit_authorization_success: '- Indicates whether the auditing system captures successful authentication attempts for audit filters using the "atype" : "authCheck" auditing event. For more information, see auditAuthorizationSuccess.  Warning! Enabling Audit authorization successes can severely impact cluster performance. Enable this option with caution.'
            audit_filter: '- JSON-formatted audit filter. For complete documentation on custom auditing filters, see Configure Audit Filters.'
            configuration_type: '- Denotes the configuration method for the audit filter. Possible values are:'
            enabled: '- Denotes whether or not the project associated with the {project_id} has database auditing enabled.  Defaults to false.'
            project_id: '- (Required) The unique ID for the project to configure auditing. Note: When changing this value to a different project_id it will delete the current audit settings for the original project that was assigned to.'
        importStatements: []
    mongodbatlas_backup_compliance_policy:
        subCategory: ""
        name: mongodbatlas_backup_compliance_policy
        title: mongodbatlas_backup_compliance_policy Resource - terraform-provider-mongodbatlas
        examples:
            - name: backup_policy
              manifest: |-
                {
                  "authorized_email": "user@email.com",
                  "authorized_user_first_name": "First",
                  "authorized_user_last_name": "Last",
                  "copy_protection_enabled": false,
                  "encryption_at_rest_enabled": false,
                  "on_demand_policy_item": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 3
                    }
                  ],
                  "pit_enabled": false,
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 7
                    }
                  ],
                  "policy_item_hourly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 7
                    }
                  ],
                  "policy_item_monthly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "months",
                      "retention_value": 12
                    }
                  ],
                  "policy_item_weekly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "weeks",
                      "retention_value": 4
                    }
                  ],
                  "policy_item_yearly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "years",
                      "retention_value": 1
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "restore_window_days": 7
                }
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "${var.region}"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_backup_schedule.test: |-
                    {
                      "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                      "policy_item_daily": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "days",
                          "retention_value": 7
                        }
                      ],
                      "policy_item_hourly": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "days",
                          "retention_value": 7
                        }
                      ],
                      "policy_item_monthly": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "months",
                          "retention_value": 12
                        }
                      ],
                      "policy_item_weekly": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "weeks",
                          "retention_value": 4
                        }
                      ],
                      "policy_item_yearly": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "years",
                          "retention_value": 1
                        }
                      ],
                      "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                      "reference_hour_of_day": 3,
                      "reference_minute_of_hour": 45,
                      "restore_window_days": 4
                    }
        argumentDocs:
            "1": through 28 where the number represents the day of the month (i.e. 1 is the first of the month and 5 is the fifth day of the month).
            "40": represents the last day of the month (depending on the month).
            authorized_email: '- (Required) Email address of a security or legal representative for the Backup Compliance Policy who is authorized to update the Backup Compliance Policy settings.'
            authorized_user_first_name: '- (Required) First name of the user who authorized to update the Backup Compliance Policy settings.'
            authorized_user_last_name: '- (Required) Last name of the user who authorized to update the Backup Compliance Policy settings.'
            copy_protection_enabled: '- Flag that indicates whether to enable additional backup copies for the cluster. If unspecified, this value defaults to false.'
            encryption_at_rest_enabled: '- Flag that indicates whether Encryption at Rest using Customer Key Management is required for all clusters with a Backup Compliance Policy. If unspecified, this value defaults to false.'
            frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (hourly in this case). The supported values for hourly policies are 1, 2, 4, 6, 8 or 12 hours. Note that 12 hours is the only accepted value for NVMe clusters.'
            frequency_type: '- Frequency associated with the backup policy item. For hourly policies, the frequency type is defined as ondemand. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.'
            id: '- Unique identifier of the backup policy item.'
            mongodbatlas_cloud_backup_schedule: |-
                fails when you delete an Atlas cluster because an existing backup compliancy policy is enabled, which is expected.
                We first suggest disabling mongodbatlas_backup_compliance_policy resource, which requires contacting MongoDB Support and completing an extensive verification process.
            pit_enabled: '- Flag that indicates whether the cluster uses Continuous Cloud Backups with a Backup Compliance Policy. If unspecified, this value defaults to false.'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies your project.'
            restore_window_days: '- Number of previous days that you can restore back to with Continuous Cloud Backup with a Backup Compliance Policy. You must specify a positive, non-zero integer, and the maximum retention window can''t exceed the hourly retention time. This parameter applies only to Continuous Cloud Backups with a Backup Compliance Policy.'
            retention_unit: '- Scope of the backup policy item: days, weeks, months, or years.'
            retention_value: '- Value to associate with retention_unit.'
            state: '- Label that indicates the state of the Backup Compliance Policy settings. MongoDB Cloud ignores this setting when you enable or update the Backup Compliance Policy settings.'
            updated_date: '- ISO 8601 timestamp format in UTC that indicates when the user updated the Data Protection Policy settings. MongoDB Cloud ignores this setting when you enable or update the Backup Compliance Policy settings.'
            updated_user: '- Email address that identifies the user who updated the Backup Compliance Policy settings. MongoDB Cloud ignores this email setting when you enable or update the Backup Compliance Policy settings.'
        importStatements: []
    mongodbatlas_cloud_backup_schedule:
        subCategory: ""
        name: mongodbatlas_cloud_backup_schedule
        title: mongodbatlas_cloud_backup_schedule Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 2
                    }
                  ],
                  "policy_item_hourly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 1
                    }
                  ],
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 2
                    }
                  ],
                  "policy_item_hourly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 1
                    }
                  ],
                  "policy_item_monthly": [
                    {
                      "frequency_interval": 5,
                      "retention_unit": "months",
                      "retention_value": 4
                    }
                  ],
                  "policy_item_weekly": [
                    {
                      "frequency_interval": 4,
                      "retention_unit": "weeks",
                      "retention_value": 3
                    }
                  ],
                  "policy_item_yearly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "years",
                      "retention_value": 1
                    }
                  ],
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "copy_settings": [
                    {
                      "cloud_provider": "AWS",
                      "frequencies": [
                        "HOURLY",
                        "DAILY",
                        "WEEKLY",
                        "MONTHLY",
                        "YEARLY",
                        "ON_DEMAND"
                      ],
                      "region_name": "US_EAST_1",
                      "should_copy_oplogs": false,
                      "zone_id": "${mongodbatlas_advanced_cluster.my_cluster.replication_specs.*.zone_id[0]}"
                    }
                  ],
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 14
                    }
                  ],
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ]
                        }
                      ]
                    }
        argumentDocs:
            "1": through 28 where the number represents the day of the month i.e. 1 is the first of the month and 5 is the fifth day of the month.
            "40": represents the last day of the month (depending on the month).
            auto_export_enabled: '- Flag that indicates whether automatic export of cloud backup snapshots to the AWS bucket is enabled. Value can be one of the following:'
            cluster_id: '- Unique identifier of the Atlas cluster.'
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshot backup policy you want to retrieve.'
            copy_settings: '- List that contains a document for each copy setting item in the desired backup policy. See below'
            copy_settings.cloud_provider: '- (Required) Human-readable label that identifies the cloud provider that stores the snapshot copy. i.e. "AWS" "AZURE" "GCP"'
            copy_settings.frequencies: '- (Required) List that describes which types of snapshots to copy. i.e. "HOURLY" "DAILY" "WEEKLY" "MONTHLY" "ON_DEMAND"'
            copy_settings.region_name: '- (Required) Target region to copy snapshots belonging to replicationSpecId to. Please supply the ''Atlas Region'' which can be found under https://www.mongodb.com/docs/atlas/reference/cloud-providers/ ''regions'' link'
            copy_settings.replication_spec_id: '- Unique 24-hexadecimal digit string that identifies the replication object for a zone in a cluster. For global clusters, there can be multiple zones to choose from. For sharded clusters and replica set clusters, there is only one zone in the cluster. To find the Replication Spec Id, consult the replicationSpecs array returned from Return One Multi-Cloud Cluster in One Project. (DEPRECATED) Use zone_id instead. To learn more, see the 1.18.0 upgrade guide.'
            copy_settings.should_copy_oplogs: '- (Required) Flag that indicates whether to copy the oplogs to the target region. You can use the oplogs to perform point-in-time restores.'
            copy_settings.zone_id: '- Unique 24-hexadecimal digit string that identifies the zone in a cluster. For global clusters, there can be multiple zones to choose from. For sharded clusters and replica set clusters, there is only one zone in the cluster. To find appropriate value for zone_id, do a GET request to Return One Cluster from One Project and consult the replicationSpecs array Return One Cluster From One Project. Alternately, use mongodbatlas_advanced_cluster data source or resource and reference replication_specs.#.zone_id.'
            export: '- Policy for automatically exporting Cloud Backup Snapshots. See below'
            export.export_bucket_id: '- Unique identifier of the mongodbatlas_cloud_backup_snapshot_export_bucket export_bucket_id value.'
            export.frequency_type: '- Frequency associated with the export snapshot item: weekly, monthly, yearly, daily (requires reaching out to Customer Support)'
            id_policy: '- Unique identifier of the backup policy.'
            next_snapshot: '- Timestamp in the number of seconds that have elapsed since the UNIX epoch when Atlas takes the next snapshot.'
            policy_item_daily: '- (Optional) Daily policy item. See below'
            policy_item_daily.frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (daily in this case). The only supported value for daily policies is 1 day.'
            policy_item_daily.frequency_type: '- Frequency associated with the backup policy item. For daily policies, the frequency type is defined as daily. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.'
            policy_item_daily.id: '- Unique identifier of the backup policy item.'
            policy_item_daily.retention_unit: '- Scope of the backup policy item: days, weeks, months, or years.'
            policy_item_daily.retention_value: '- Value to associate with retention_unit.  Note that for less frequent policy items, Atlas requires that you specify a retention period greater than or equal to the retention period specified for more frequent policy items. For example: If the hourly policy item specifies a retention of two days, the daily retention policy must specify two days or greater.'
            policy_item_hourly: '- (Optional) Hourly policy item. See below'
            policy_item_hourly.frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (hourly in this case). The supported values for hourly policies are 1, 2, 4, 6, 8 or 12 hours. Note that 12 hours is the only accepted value for NVMe clusters.'
            policy_item_hourly.frequency_type: '- Frequency associated with the backup policy item. For hourly policies, the frequency type is defined as hourly. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.'
            policy_item_hourly.id: '- Unique identifier of the backup policy item.'
            policy_item_hourly.retention_unit: '- Scope of the backup policy item: days, weeks, months, or years.'
            policy_item_hourly.retention_value: '- Value to associate with retention_unit.'
            policy_item_monthly: '- (Optional) Monthly policy item. See below'
            policy_item_monthly.frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (monthly in this case). The supported values for weekly policies are'
            policy_item_monthly.frequency_type: '- Frequency associated with the backup policy item. For monthly policies, the frequency type is defined as monthly. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.'
            policy_item_monthly.id: '- Unique identifier of the backup policy item.'
            policy_item_monthly.retention_unit: '- Scope of the backup policy item: days, weeks, months, or years.'
            policy_item_monthly.retention_value: '- Value to associate with retention_unit. Monthly policy must have retention days of at least 31 days or 5 weeks or 1 month. Note that for less frequent policy items, Atlas requires that you specify a retention period greater than or equal to the retention period specified for more frequent policy items. For example: If the weekly policy item specifies a retention of two weeks, the montly retention policy must specify two weeks or greater.'
            policy_item_weekly: '- (Optional) Weekly policy item. See below'
            policy_item_weekly.frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (weekly in this case). The supported values for weekly policies are 1 through 7, where 1 represents Monday and 7 represents Sunday.'
            policy_item_weekly.frequency_type: '- Frequency associated with the backup policy item. For weekly policies, the frequency type is defined as weekly. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.'
            policy_item_weekly.id: '- Unique identifier of the backup policy item.'
            policy_item_weekly.retention_unit: '- Scope of the backup policy item: days, weeks, months, or years.'
            policy_item_weekly.retention_value: '- Value to associate with retention_unit. Weekly policy must have retention of at least 7 days or 1 week. Note that for less frequent policy items, Atlas requires that you specify a retention period greater than or equal to the retention period specified for more frequent policy items. For example: If the daily policy item specifies a retention of two weeks, the weekly retention policy must specify two weeks or greater.'
            policy_item_yearly: '- (Optional) Yearly policy item. See below'
            policy_item_yearly.frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (yearly in this case). The supported values for yearly policies are'
            policy_item_yearly.frequency_type: '- Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as yearly. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.'
            policy_item_yearly.id: '- Unique identifier of the backup policy item.'
            policy_item_yearly.retention_unit: '- Scope of the backup policy item: days, weeks, months, or years.'
            policy_item_yearly.retention_value: '- Value to associate with retention_unit. Yearly policy must have retention of at least 1 year.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            reference_hour_of_day: '- (Optional) UTC Hour of day between 0 and 23, inclusive, representing which hour of the day that Atlas takes snapshots for backup policy items.'
            reference_minute_of_hour: '- (Optional) UTC Minutes after reference_hour_of_day that Atlas takes snapshots for backup policy items. Must be between 0 and 59, inclusive.'
            restore_window_days: '- (Optional) Number of days back in time you can restore to with point-in-time accuracy. Must be a positive, non-zero integer.'
            update_snapshots: '- (Optional) Specify true to apply the retention changes in the updated backup policy to snapshots that Atlas took previously.'
            use_org_and_group_names_in_export_prefix: '- Specify true to use organization and project names instead of organization and project UUIDs in the path for the metadata files that Atlas uploads to your S3 bucket after it finishes exporting the snapshots. To learn more about the metadata files that Atlas uploads, see Export Cloud Backup Snapshot.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot:
        subCategory: ""
        name: mongodbatlas_cloud_backup_snapshot
        title: mongodbatlas_cloud_backup_snapshot Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "description": "myDescription",
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "retention_in_days": 1
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_WEST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_backup_snapshot_restore_job.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cloud_backup_snapshot.test.cluster_name}",
                      "delivery_type_config": [
                        {
                          "download": true
                        }
                      ],
                      "project_id": "${mongodbatlas_cloud_backup_snapshot.test.project_id}",
                      "snapshot_id": "${mongodbatlas_cloud_backup_snapshot.test.snapshot_id}"
                    }
        argumentDocs:
            cloud_provider: '- Cloud provider that stores this snapshot. Atlas returns this parameter when type is replicaSet.'
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshots you want to retrieve.'
            created_at: '- UTC ISO 8601 formatted point in time when Atlas took the snapshot.'
            description: '- (Required) Description of the on-demand snapshot.'
            expires_at: '- UTC ISO 8601 formatted point in time when Atlas will delete the snapshot.'
            id: "-\tUnique identifier used for terraform for internal manages."
            master_key_uuid: '- Unique ID of the AWS KMS Customer Master Key used to encrypt the snapshot. Only visible for clusters using Encryption at Rest via Customer KMS.'
            members: '- Block of List of snapshots and the cloud provider where the snapshots are stored. Atlas returns this parameter when type is shardedCluster. See below'
            members.cloud_provider: '- Cloud provider that stores this snapshot.'
            members.id: '- Unique identifier for the sharded cluster snapshot.'
            members.replica_set_name: '- Label given to a shard or config server from which Atlas took this snapshot.'
            mongod_version: '- Version of the MongoDB server.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            replica_set_name: '- Label given to the replica set from which Atlas took this snapshot. Atlas returns this parameter when type is replicaSet.'
            retention_in_days: '- (Required) The number of days that Atlas should retain the on-demand snapshot. Must be at least 1.'
            snapshot_id: '- Unique identifier of the snapshot.'
            snapshot_ids: '- Unique identifiers of the snapshots created for the shards and config server for a sharded cluster. Atlas returns this parameter when type is shardedCluster. These identifiers should match those given in the members[n].id parameters. This allows you to map a snapshot to its shard or config server name.'
            snapshot_type: '- Specified the type of snapshot. Valid values are onDemand and scheduled.'
            status: '- Current status of the snapshot. One of the following values will be returned: queued, inProgress, completed, failed.'
            storage_size_bytes: '- Specifies the size of the snapshot in bytes.'
            type: '- Specifies the type of cluster: replicaSet or shardedCluster.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot_export_bucket:
        subCategory: ""
        name: mongodbatlas_cloud_backup_snapshot_export_bucket
        title: mongodbatlas_cloud_backup_snapshot_export_bucket Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "bucket_name": "example-bucket",
                  "cloud_provider": "AWS",
                  "iam_role_id": "{IAM_ROLE_ID}",
                  "project_id": "{PROJECT_ID}"
                }
            - name: test
              manifest: |-
                {
                  "bucket_name": "example-bucket",
                  "cloud_provider": "AZURE",
                  "project_id": "{PROJECT_ID}",
                  "role_id": "{ROLE_ID}",
                  "service_url": "{SERVICE_URL}"
                }
        argumentDocs:
            bucket_name: '- (Required) Name of the bucket that the provided role ID is authorized to access.'
            cloud_provider: '- (Required) Name of the provider of the cloud service where Atlas can access the S3 bucket.'
            export_bucket_id: '- Unique identifier of the snapshot export bucket.'
            iam_role_id: '- Unique identifier of the role that Atlas can use to access the bucket. Required if cloud_provider is set to AWS.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            role_id: '- Unique identifier of the Azure Service Principal that Atlas can use to access the Azure Blob Storage Container. Required if cloud_provider is set to AZURE.'
            service_url: '- URL that identifies the blob Endpoint of the Azure Blob Storage Account. Required if cloud_provider is set to AZURE.'
            tenant_id: '- (Deprecated) This field is ignored; the mongodbatlas_cloud_provider_access_authorization.azure.tenant_id is used instead and returned as an attribute. UUID that identifies the Azure Active Directory Tenant ID.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot_export_job:
        subCategory: ""
        name: mongodbatlas_cloud_backup_snapshot_export_job
        title: mongodbatlas_cloud_backup_snapshot_export_job Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "{CLUSTER_NAME}",
                  "custom_data": [
                    {
                      "key": "exported by",
                      "value": "myName"
                    }
                  ],
                  "export_bucket_id": "${mongodbatlas_cloud_backup_snapshot_export_bucket.test.export_bucket_id}",
                  "project_id": "{PROJECT_ID}",
                  "snapshot_id": "{SNAPSHOT_ID}"
                }
              references:
                export_bucket_id: mongodbatlas_cloud_backup_snapshot_export_bucket.test.export_bucket_id
              dependencies:
                mongodbatlas_cloud_backup_snapshot_export_bucket.test: |-
                    {
                      "bucket_name": "example_bucket",
                      "cloud_provider": "AWS",
                      "iam_role_id": "{IAM_ROLE_ID}",
                      "project_id": "{PROJECT_ID}"
                    }
        argumentDocs:
            Cancelled: '- indicates that the export job has cancelled'
            Failed: '- indicates that the export job has failed'
            InProgress: '- indicates that the snapshot is being exported'
            Queued: '- indicates that the export job is queued'
            Successful: '- indicates that the export job has completed successfully'
            cluster_name: '- (Required) Name of the Atlas cluster whose snapshot you want to export.'
            components: '- Returned for sharded clusters only. Export job details for each replica set in the sharded cluster.'
            components.export_id: '- Returned for sharded clusters only. Export job details for each replica set in the sharded cluster.'
            components.replica_set_name: '- Returned for sharded clusters only. Unique identifier of the export job for the replica set.'
            created_at: '- Timestamp in ISO 8601 date and time format in UTC when the export job was created.'
            custom_data: '- (Optional) Custom data to include in the metadata file named .complete that Atlas uploads to the bucket when the export job finishes. Custom data can be specified as key and value pairs.'
            export_bucket_id: '- (Required) Unique identifier of the AWS bucket to export the Cloud Backup snapshot to. If necessary, use the Get All Snapshot Export Buckets API to retrieve the IDs of all available export buckets for a project or use the data source mongodbatlas_cloud_backup_snapshot_export_buckets'
            export_job_id: '- Unique identifier of the export job.'
            export_status: '- Status of the export job.'
            export_status.exported_collections: '- Returned for replica set only. Number of collections that have been exported.'
            export_status.total_collections: '- Returned for replica set only. Total number of collections to export.'
            finished_at: '- Timestamp in ISO 8601 date and time format in UTC when the export job completes.'
            key: '- (Required) Required if you want to include custom data using custom_data in the metadata file uploaded to the bucket. Key to include in the metadata file that Atlas uploads to the bucket when the export job finishes.'
            'prefix ': '- Full path on the cloud provider bucket to the folder where the snapshot is exported. The path is in the following format:/exported_snapshots/{ORG-NAME}/{PROJECT-NAME}/{CLUSTER-NAME}/{SNAPSHOT-INITIATION-DATE}/{TIMESTAMP}'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies the project which contains the Atlas cluster whose snapshot you want to export.'
            snapshot_id: '- (Required) Unique identifier of the Cloud Backup snapshot to export. If necessary, use the Get All Cloud Backups API to retrieve the list of snapshot IDs for a cluster or use the data source mongodbatlas_cloud_cloud_backup_snapshots'
            state: '- Status of the export job. Value can be one of the following:'
            value: '- (Required) Required if you specify key.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot_restore_job:
        subCategory: ""
        name: mongodbatlas_cloud_backup_snapshot_restore_job
        title: mongodbatlas_cloud_backup_snapshot_restore_job Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "automated": true,
                      "target_cluster_name": "MyCluster",
                      "target_project_id": "5cf5a45a9ccf6400e60981b6"
                    }
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_WEST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "download": true
                    }
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_WEST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
        argumentDocs:
            cancelled: "-\tIndicates whether the restore job was canceled."
            cluster_name: '- (Required) The name of the Atlas cluster whose snapshot you want to restore.'
            created_at: "-\tUTC ISO 8601 formatted point in time when Atlas created the restore job."
            delivery_type_config: '- (Required) Type of restore job to create. Possible configurations are: download, automated, or pointInTime only one must be set it in true.'
            delivery_type_config.automated: '- Set to true to use the automated configuration.'
            delivery_type_config.download: '- Set to true to use the download configuration.'
            delivery_type_config.oplog_inc: '- Optional setting for pointInTime configuration. Oplog operation number from which to you want to restore this snapshot. This is the second part of an Oplog timestamp. Used in conjunction with oplog_ts.'
            delivery_type_config.oplog_ts: '- Optional setting for pointInTime configuration. Timestamp in the number of seconds that have elapsed since the UNIX epoch from which to you want to restore this snapshot. This is the first part of an Oplog timestamp.'
            delivery_type_config.point_in_time_utc_seconds: '- Optional setting for pointInTime configuration. Timestamp in the number of seconds that have elapsed since the UNIX epoch from which you want to restore this snapshot. Used instead of oplog settings.'
            delivery_type_config.pointInTime: '- Set to true to use the pointInTime configuration. If using pointInTime configuration, you must also specify either oplog_ts and oplog_inc, or point_in_time_utc_seconds.'
            delivery_type_config.target_cluster_name: '- Name of the target Atlas cluster to which the restore job restores the snapshot. Required for automated and pointInTime.'
            delivery_type_config.target_project_id: '- Name of the target Atlas cluster to which the restore job restores the snapshot. Required for automated and pointInTime.'
            delivery_url: "-\tOne or more URLs for the compressed snapshot files for manual download. Only visible if deliveryType is download."
            expired: "-\tIndicates whether the restore job expired."
            expires_at: "-\tUTC ISO 8601 formatted point in time when the restore job expires."
            failed: '-     Indicates whether the restore job failed.'
            finished_at: "-\tUTC ISO 8601 formatted point in time when the restore job completed."
            id: "-\tThe Terraform's unique identifier used internally for state management."
            links: "-\tOne or more links to sub-resources and/or related resources. The relations between URLs are explained in the Web Linking Specification."
            oplogInc: |-
                - Oplog operation number from which to you want to restore this snapshot. This is the second part of an Oplog timestamp.
                Three conditions apply to this parameter:
            oplogTs: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which to you want to restore this snapshot.
                Three conditions apply to this parameter:
            pointInTimeUTCSeconds: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which you want to restore this snapshot.
                Two conditions apply to this parameter:
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster whose snapshot you want to restore.'
            snapshot_id: '- Optional setting for pointInTime configuration. Unique identifier of the snapshot to restore.'
            snapshot_restore_job_id: '- The unique identifier of the restore job.'
            target_cluster_name: "-\tName of the target Atlas cluster to which the restore job restores the snapshot. Only visible if deliveryType is automated."
            target_project_id: "-\tName of the target Atlas project of the restore job. Only visible if deliveryType is automated."
            timestamp: '- Timestamp in ISO 8601 date and time format in UTC when the snapshot associated to snapshotId was taken.'
        importStatements: []
    mongodbatlas_cloud_provider_access Resource - terraform-provider-mongodbatlas:
        subCategory: ""
        name: mongodbatlas_cloud_provider_access Resource - terraform-provider-mongodbatlas
        title: mongodbatlas_cloud_provider_access Resource - terraform-provider-mongodbatlas
        argumentDocs:
            atlas_assumed_role_external_id: '- Unique external ID Atlas uses when assuming the IAM role in your AWS account.'
            atlas_aws_account_arn: '- ARN associated with the Atlas AWS account used to assume IAM roles in your AWS account.'
            atlas_azure_app_id: '- Azure Active Directory Application ID of Atlas. This property is required when provider_name = "AZURE".'
            authorized_date: '- Date on which this role was authorized.'
            aws: ""
            aws_config: '- aws related arn roles'
            azure_config: '- azure related configurations'
            created_date: '- Date on which this role was created.'
            feature_usages: '- Atlas features this AWS IAM role is linked to.'
            iam_assumed_role_arn: '- (Required) ARN of the IAM Role that Atlas assumes when accessing resources in your AWS account. This value is required after the creation (register of the role) as part of Set Up Unified AWS Access.'
            id: '- Unique identifier used by terraform for internal management.'
            last_updated_date: '- Date and time when this Azure Service Principal was last updated. This parameter expresses its value in the ISO 8601 timestamp format in UTC.'
            mongodbatlas_cloud_provider_access_setup: |-
                and mongodbatlas_cloud_provider_access_authorization. The first resource, mongodbatlas_cloud_provider_access_setup, only generates
                the initial configuration (create, delete operations). The second resource, mongodbatlas_cloud_provider_access_authorization, helps to perform the authorization using the role_id of the first resource. This path is helpful in a multi-provider Terraform file, and allows for a single and decoupled apply. See example of this Two Resource path option with AWS Cloud here and AZURE Cloud here.
            project_id: '- (Required) The unique ID for the project'
            provider_name: '- (Required) The cloud provider for which to create a new role. Currently only AWS and AZURE are supported. WARNING Changing the provider_name will result in destruction of the existing resource and the creation of a new resource.'
            role_id: '- Unique ID of this role.'
            service_principal_id: '- UUID string that identifies the Azure Service Principal. This property is required when provider_name = "AZURE".'
            tenant_id: '- UUID String that identifies the Azure Active Directory Tenant ID. This property is required when provider_name = "AZURE".'
        importStatements: []
    mongodbatlas_cloud_provider_snapshot:
        subCategory: ""
        name: mongodbatlas_cloud_provider_snapshot
        title: mongodbatlas_cloud_provider_snapshot Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "description": "myDescription",
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "retention_in_days": 1,
                  "timeout": "10m"
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_WEST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_provider_snapshot_restore_job.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                      "delivery_type_config": [
                        {
                          "download": true
                        }
                      ],
                      "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                      "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                    }
        argumentDocs:
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshots you want to retrieve.'
            created_at: '- UTC ISO 8601 formatted point in time when Atlas took the snapshot.'
            description: '- (Required) Description of the on-demand snapshot.'
            expires_at: '- UTC ISO 8601 formatted point in time when Atlas will delete the snapshot.'
            id: "-\tUnique identifier used for terraform for internal manages."
            master_key_uuid: '- Unique ID of the AWS KMS Customer Master Key used to encrypt the snapshot. Only visible for clusters using Encryption at Rest via Customer KMS.'
            mongod_version: '- Version of the MongoDB server.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            retention_in_days: '- (Required) The number of days that Atlas should retain the on-demand snapshot. Must be at least 1.'
            snapshot_id: '- Unique identifier of the snapshot.'
            snapshot_type: '- Specified the type of snapshot. Valid values are onDemand and scheduled.'
            status: '- Current status of the snapshot. One of the following values will be returned: queued, inProgress, completed, failed.'
            storage_size_bytes: '- Specifies the size of the snapshot in bytes.'
            timeout: '- (Optional) The duration of time to wait to finish the on-demand snapshot. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. Default value for the timeout is 10m'
            type: '- Specifies the type of cluster: replicaSet or shardedCluster.'
        importStatements: []
    mongodbatlas_cloud_provider_snapshot_backup_policy:
        subCategory: ""
        name: mongodbatlas_cloud_provider_snapshot_backup_policy
        title: mongodbatlas_cloud_provider_snapshot_backup_policy Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "policies": [
                    {
                      "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id}",
                      "policy_item": [
                        {
                          "frequency_interval": 1,
                          "frequency_type": "hourly",
                          "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.0.id}",
                          "retention_unit": "days",
                          "retention_value": 1
                        },
                        {
                          "frequency_interval": 1,
                          "frequency_type": "daily",
                          "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.1.id}",
                          "retention_unit": "days",
                          "retention_value": 2
                        },
                        {
                          "frequency_interval": 4,
                          "frequency_type": "weekly",
                          "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.2.id}",
                          "retention_unit": "weeks",
                          "retention_value": 3
                        },
                        {
                          "frequency_interval": 5,
                          "frequency_type": "monthly",
                          "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id}",
                          "retention_unit": "months",
                          "retention_value": 4
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                policies.id: mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id
                policies.policy_item.id: mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "policies": [
                    {
                      "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id}",
                      "policy_item": [
                        {
                          "frequency_interval": 1,
                          "frequency_type": "hourly",
                          "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.0.id}",
                          "retention_unit": "days",
                          "retention_value": 1
                        },
                        {
                          "frequency_interval": 1,
                          "frequency_type": "daily",
                          "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.1.id}",
                          "retention_unit": "days",
                          "retention_value": 2
                        },
                        {
                          "frequency_interval": 5,
                          "frequency_type": "monthly",
                          "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id}",
                          "retention_unit": "months",
                          "retention_value": 4
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                policies.id: mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id
                policies.policy_item.id: mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                  "policies": [
                    {
                      "id": "${mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id}",
                      "policy_item": [
                        {
                          "frequency_interval": 5,
                          "frequency_type": "monthly",
                          "id": 5,
                          "retention_unit": "months",
                          "retention_value": 4
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.my_cluster.name
                policies.id: mongodbatlas_advanced_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id
                project_id: mongodbatlas_advanced_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ]
                        }
                      ]
                    }
        argumentDocs:
            cluster_id: '- Unique identifier of the Atlas cluster.'
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshot backup policy you want to retrieve.'
            next_snapshot: '- Timestamp in the number of seconds that have elapsed since the UNIX epoch when Atlas takes the next snapshot.'
            policies: '- (Required) Contains a document for each backup policy item in the desired updated backup policy.'
            policies.#.id: '- (Required) Unique identifier of the backup policy that you want to update. policies.#.id is a value obtained via the mongodbatlas_advanced_cluster resource. cloud_backup of the mongodbatlas_advanced_cluster resource must be set to true. See the example above for how to refer to the mongodbatlas_advanced_cluster resource for policies.#.id'
            policies.#.policy_item: '- (Required) Array of backup policy items.'
            policies.#.policy_item.#.frequency_interval: '- (Required) Desired frequency of the new backup policy item specified by frequencyType.'
            policies.#.policy_item.#.frequency_type: '- (Required) Frequency associated with the backup policy item. One of the following values: hourly, daily, weekly or monthly.'
            policies.#.policy_item.#.id: '- (Required) Unique identifier of the backup policy item. policies.#.policy_item.#.id is a value obtained via the mongodbatlas_advanced_cluster resource. cloud_backup of the mongodbatlas_advanced_cluster resource must be set to true. See the example above for how to refer to the mongodbatlas_advanced_cluster resource for policies.#.policy_item.#.id'
            policies.#.policy_item.#.retention_unit: '- (Required) Scope of the backup policy item: days, weeks, or months.'
            policies.#.policy_item.#.retention_value: '- (Required) Value to associate with retentionUnit.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            reference_hour_of_day: '- (Optional) UTC Hour of day between 0 and 23, inclusive, representing which hour of the day that Atlas takes snapshots for backup policy items.'
            reference_minute_of_hour: '- (Optional) UTC Minutes after referenceHourOfDay that Atlas takes snapshots for backup policy items. Must be between 0 and 59, inclusive.'
            restore_window_days: '- (Optional) Number of days back in time you can restore to with point-in-time accuracy. Must be a positive, non-zero integer.'
            update_snapshots: '- (Optional) Specify true to apply the retention changes in the updated backup policy to snapshots that Atlas took previously.'
        importStatements: []
    mongodbatlas_cloud_provider_snapshot_restore_job:
        subCategory: ""
        name: mongodbatlas_cloud_provider_snapshot_restore_job
        title: mongodbatlas_cloud_provider_snapshot_restore_job Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "automated": true,
                      "target_cluster_name": "MyCluster",
                      "target_project_id": "5cf5a45a9ccf6400e60981b6"
                    }
                  ],
                  "depends_on": [
                    "${mongodbatlas_cloud_provider_snapshot.test}"
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_WEST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "download": true
                    }
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_advanced_cluster.my_cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "MyCluster",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_WEST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_advanced_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_advanced_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
        argumentDocs:
            cancelled: "-\tIndicates whether the restore job was canceled."
            cluster_name: '- (Required) The name of the Atlas cluster whose snapshot you want to restore.'
            created_at: "-\tUTC ISO 8601 formatted point in time when Atlas created the restore job."
            delivery_type_config: '- Type of restore job to create. Possible values are: automated and download.'
            delivery_url: "-\tOne or more URLs for the compressed snapshot files for manual download. Only visible if deliveryType is download."
            expired: "-\tIndicates whether the restore job expired."
            expires_at: "-\tUTC ISO 8601 formatted point in time when the restore job expires."
            finished_at: "-\tUTC ISO 8601 formatted point in time when the restore job completed."
            id: "-\tThe Terraform's unique identifier used internally for state management."
            links: "-\tOne or more links to sub-resources and/or related resources. The relations between URLs are explained in the Web Linking Specification."
            oplogInc: |-
                - Oplog operation number from which to you want to restore this snapshot. This is the second part of an Oplog timestamp.
                Three conditions apply to this parameter:
            oplogTs: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which to you want to restore this snapshot.
                Three conditions apply to this parameter:
            pointInTimeUTCSeconds: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which you want to restore this snapshot.
                Two conditions apply to this parameter:
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster whose snapshot you want to restore.'
            snapshot_id: '- (Required) Unique identifier of the snapshot to restore.'
            snapshot_restore_job_id: '- The unique identifier of the restore job.'
            target_cluster_name: "- (Required) \tName of the target Atlas cluster to which the restore job restores the snapshot. Only required if deliveryType is automated."
            target_project_id: "- (Required) \tUnique ID of the target Atlas project for the specified targetClusterName. Only required if deliveryType is automated."
            timestamp: '- Timestamp in ISO 8601 date and time format in UTC when the snapshot associated to snapshotId was taken.'
        importStatements: []
    mongodbatlas_cluster:
        subCategory: ""
        name: mongodbatlas_cluster
        title: mongodbatlas_cluster Resource - terraform-provider-mongodbatlas
        examples:
            - name: cluster-test
              manifest: |-
                {
                  "auto_scaling_disk_gb_enabled": true,
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "mongo_db_major_version": "7.0",
                  "name": "cluster-test",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M40",
                  "provider_name": "AWS",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "auto_scaling_disk_gb_enabled": true,
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "mongo_db_major_version": "7.0",
                  "name": "test",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_disk_type_name": "P6",
                  "provider_instance_size_name": "M30",
                  "provider_name": "AZURE",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "auto_scaling_disk_gb_enabled": true,
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "mongo_db_major_version": "7.0",
                  "name": "test",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M30",
                  "provider_name": "GCP",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "EASTERN_US"
                        }
                      ]
                    }
                  ]
                }
            - name: cluster-test
              manifest: |-
                {
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "name": "cluster-test-multi-region",
                  "num_shards": 1,
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M10",
                  "provider_name": "AWS",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_nodes": 2,
                          "priority": 6,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_2"
                        },
                        {
                          "electable_nodes": 2,
                          "priority": 5,
                          "read_only_nodes": 2,
                          "region_name": "US_WEST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: cluster-test
              manifest: |-
                {
                  "cloud_backup": true,
                  "cluster_type": "GEOSHARDED",
                  "name": "cluster-test-global",
                  "num_shards": 1,
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M30",
                  "provider_name": "AWS",
                  "replication_specs": [
                    {
                      "num_shards": 2,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_1"
                        }
                      ],
                      "zone_name": "Zone 1"
                    },
                    {
                      "num_shards": 2,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "EU_CENTRAL_1"
                        }
                      ],
                      "zone_name": "Zone 2"
                    }
                  ]
                }
            - name: cluster-test
              manifest: |-
                {
                  "backing_provider_name": "AWS",
                  "name": "cluster-test-global",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M0",
                  "provider_name": "TENANT",
                  "provider_region_name": "US_EAST_1"
                }
        argumentDocs:
            AWS: '- Amazon AWS'
            AZURE: '- Microsoft Azure'
            CONTINUOUS: ':  Atlas creates your cluster using the most recent MongoDB release. Atlas automatically updates your cluster to the latest major and rapid MongoDB releases as they become available.'
            GCP: '- Google Cloud Platform'
            LTS: ': Atlas creates your cluster using the latest patch release of the MongoDB version that you specify in the mongoDBMajorVersion field. Atlas automatically updates your cluster to subsequent patch releases of this MongoDB version. Atlas doesn''t update your cluster to newer rapid or major MongoDB releases as they become available.'
            TENANT: '- A multi-tenant deployment on one of the supported cloud service providers. Only valid when providerSettings.instanceSizeName is either M2 or M5.'
            analytics_nodes: '- (Optional) The number of analytics nodes for Atlas to deploy to the region. Analytics nodes are useful for handling analytic data such as reporting queries from BI Connector for Atlas. Analytics nodes are read-only, and can never become the primary. If you do not specify this option, no analytics nodes are deployed to the region.'
            auto_scaling_disk_gb_enabled: '- (Optional) Specifies whether disk auto-scaling is enabled. The default is false.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled: '- (Optional) Specifies whether cluster tier auto-scaling is enabled. The default is false.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.REPLICASET: |-
                Replica set
                - SHARDED Sharded cluster
                - GEOSHARDED Global Cluster
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.accept_data_risks_and_force_replica_set_reconfig: '- (Optional) If reconfiguration is necessary to regain a primary due to a regional outage, submit this field alongside your topology reconfiguration to request a new regional outage resistant topology. Forced reconfigurations during an outage of the majority of electable nodes carry a risk of data loss if replicated writes (even majority committed writes) have not been replicated to the new primary node. MongoDB Atlas docs contain more information. To proceed with an operation which carries that risk, set accept_data_risks_and_force_replica_set_reconfig to the current date. Learn more about Reconfiguring a Replica Set during a regional outage here.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.auto_scaling_compute_scale_down_enabled: '- (Optional) Set to true to enable the cluster tier to scale down. This option is only available if autoScaling.compute.enabled is true.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.backing_provider_name: '- (Optional) Cloud service provider on which the server for a multi-tenant cluster is provisioned.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.backup_enabled: |-
                - (Optional) Legacy Backup - Set to true to enable Atlas legacy backups for the cluster.
                Important - MongoDB deprecated the Legacy Backup feature. Clusters that use Legacy Backup can continue to use it. MongoDB recommends using Cloud Backups.
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.bi_connector_config: '- (Optional) Specifies BI Connector for Atlas configuration on this cluster. BI Connector for Atlas is only available for M10+ clusters. See BI Connector below for more details.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.cloud_backup: '- (Optional) Flag indicating if the cluster uses Cloud Backup for backups.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.cluster_type: '- (Required) Specifies the type of the cluster that you want to modify. You cannot convert a sharded cluster deployment to a replica set deployment.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.disk_size_gb: '- (Optional - GCP/AWS Only) Capacity, in gigabytes, of the host’s root volume. Increase this number to add capacity, up to a maximum possible value of 4096 (i.e., 4 TB). This value must be a positive integer.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.encryption_at_rest_provider: '- (Optional) Possible values are AWS, GCP, AZURE or NONE.  Only needed if you desire to manage the keys, see Encryption at Rest using Customer Key Management for complete documentation.  You must configure encryption at rest for the Atlas project before enabling it on any cluster in the project. For complete documentation on configuring Encryption at Rest, see Encryption at Rest using Customer Key Management. Requires M10 or greater. and for legacy backups, backup_enabled, to be false or omitted. Note: Atlas encrypts all cluster storage and snapshot volumes, securing all cluster data on disk: a concept known as encryption at rest, by default.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.labels: '- (Optional) Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below. DEPRECATED Use tags instead.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.mongo_db_major_version: '- (Optional) Version of the cluster to deploy. Atlas supports all the MongoDB versions that have not reached End of Live for M10+ clusters. If omitted, Atlas deploys the cluster with the default version. For more details, see documentation. Atlas always deploys the cluster with the latest stable release of the specified version. See Release Notes for latest Current Stable Release.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.num_shards: '- (Optional) Selects whether the cluster is a replica set or a sharded cluster. If you use the replicationSpecs parameter, you must set num_shards.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.paused: |-
                (Optional) - Flag that indicates whether the cluster is paused or not. You can pause M10 or larger clusters.  You cannot initiate pausing for a shared/tenant tier cluster.  See Considerations for Paused Clusters
                NOTE Pause lasts for up to 30 days. If you don't resume the cluster within 30 days, Atlas resumes the cluster.  When the cluster resumption happens Terraform will flag the changed state.  If you wish to keep the cluster paused, reapply your Terraform configuration.   If you prefer to allow the automated change of state to unpaused use:
                lifecycle { ignore_changes = [paused] }
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.pinned_fcv: '- (Optional) Pins the Feature Compatibility Version (FCV) to the current MongoDB version with a provided expiration date. To unpin the FCV the pinned_fcv attribute must be removed. This operation can take several minutes as the request processes through the MongoDB data plane. Once FCV is unpinned it will not be possible to downgrade the mongo_db_major_version. It is advised that updates to pinned_fcv are done isolated from other cluster changes. If a plan contains multiple changes, the FCV change will be applied first. If FCV is unpinned past the expiration date the pinned_fcv attribute must be removed. The following knowledge hub article and FCV documentation can be referenced for more details. See below.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.pit_enabled: '- (Optional) - Flag that indicates if the cluster uses Continuous Cloud Backup. If set to true, cloud_backup must also be set to true.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.provider_auto_scaling_compute_max_instance_size: '- (Optional) Maximum instance size to which your cluster can automatically scale (e.g., M40). Required if autoScaling.compute.enabled is true.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.provider_auto_scaling_compute_min_instance_size: '- (Optional) Minimum instance size to which your cluster can automatically scale (e.g., M10). Required if autoScaling.compute.scaleDownEnabled is true.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.provider_disk_iops: '- (Optional - AWS Only) The maximum input/output operations per second (IOPS) the system can perform. The possible values depend on the selected provider_instance_size_name and disk_size_gb.  This setting requires that provider_instance_size_name to be M30 or greater and cannot be used with clusters with local NVMe SSDs.  The default value for provider_disk_iops is the same as the cluster tier''s Standard IOPS value, as viewable in the Atlas console.  It is used in cases where a higher number of IOPS is needed and possible.  If a value is submitted that is lower or equal to the default IOPS value for the cluster tier Atlas ignores the requested value and uses the default.  More details available under the providerSettings.diskIOPS parameter: MongoDB API Clusters'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.provider_disk_type_name: '- (Optional - Azure Only) Azure disk type of the server’s root volume. If omitted, Atlas uses the default disk type for the selected providerSettings.instanceSizeName.  Example disk types and associated storage sizes: P4 - 32GB, P6 - 64GB, P10 - 128GB, P15 - 256GB, P20 - 512GB, P30 - 1024GB, P40 - 2048GB, P50 - 4095GB.  More information and the most update to date disk types/storage sizes can be located at https://docs.atlas.mongodb.com/reference/api/clusters-create-one/.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.provider_encrypt_ebs_volume: '- (Deprecated) The Flag is always true. Flag that indicates whether the Amazon EBS encryption feature encrypts the host''s root volume for both data at rest within the volume and for data moving between the volume and the cluster. Note: This setting is always enabled for clusters with local NVMe SSDs. Atlas encrypts all cluster storage and snapshot volumes, securing all cluster data on disk: a concept known as encryption at rest, by default..'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.provider_region_name: |-
                - (Optional) Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases.  Requires the Atlas region name, see the reference list for AWS, GCP, Azure.
                Do not specify this field when creating a multi-region cluster using the replicationSpec document or a Global Cluster with the replicationSpecs array.
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.provider_volume_type: |-
                - (AWS - Optional) The type of the volume. The possible values are: STANDARD and PROVISIONED.  PROVISIONED is ONLY required if setting IOPS higher than the default instance IOPS.
                -> NOTE: STANDARD is not available for NVME clusters.
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.redact_client_log_data: '- (Optional) Flag that enables or disables log redaction, see the manual for more info. Use this in conjunction with Encryption at Rest and TLS/SSL (Transport Encryption) to assist compliance with regulatory requirements. Note: Changing this setting on a cluster will trigger a rolling restart as soon as the cluster is updated. The log redaction field is updated via an Atlas API call after cluster creation. Consequently, there may be a brief period during resource creation when log redaction is not yet enabled. To ensure complete log redaction from the outset, use mongodbatlas_advanced_cluster.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.replication_factor: '- (Deprecated) Number of replica set members. Each member keeps a copy of your databases, providing high availability and data redundancy. The possible values are 3, 5, or 7. The default value is 3.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.replication_specs: '- Configuration for cluster regions.  See Replication Spec below for more details.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.retain_backups_enabled: '- (Optional) Set to true to retain backup snapshots for the deleted cluster. M10 and above only.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.tags: '- (Optional) Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.termination_protection_enabled: '- Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won''t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.timeouts: '- (Optional) The duration of time to wait for Cluster to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Cluster create & delete is 3h. Learn more about timeouts here.'
            auto_scaling_disk_gb_enabled.auto_scaling_compute_enabled.version_release_system: '- (Optional) - Release cadence that Atlas uses for this cluster. This parameter defaults to LTS. If you set this field to CONTINUOUS, you must omit the mongo_db_major_version field. Atlas accepts:'
            change_stream_options_pre_and_post_images_expire_after_seconds: '- (Optional) The minimum pre- and post-image retention time in seconds. This option corresponds to the changeStreamOptions.preAndPostImages.expireAfterSeconds cluster parameter. Defaults to -1(off). This setting controls the retention policy of change stream pre- and post-images. Pre- and post-images are the versions of a document before and after document modification, respectively.expireAfterSeconds controls how long MongoDB retains pre- and post-images. When set to -1 (off), MongoDB uses the default retention policy: pre- and post-images are retained until the corresponding change stream events are removed from the oplog. To set the minimum pre- and post-image retention time, specify an integer value greater than zero. Setting this too low could increase the risk of interrupting Realm sync or triggers processing. This parameter is only supported for MongoDB version 6.0 and above.'
            cloud_backup: ', to enable Cloud Backup.  If you create a new Atlas cluster and set backup_enabled to true, the Provider will respond with an error.  This change doesn’t affect existing clusters that use legacy backups.'
            cluster_id: '- The cluster ID.'
            connection_strings: '- Set of connection strings that your applications use to connect to this cluster. More info in Connection-strings. Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see Connection String Options. NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.'
            connection_strings.private: '-   Network-peering-endpoint-aware mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.private_endpoint: '- Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster''s nodes.'
            connection_strings.private_endpoint.#.connection_string: '- Private-endpoint-aware mongodb://connection string for this private endpoint.'
            connection_strings.private_endpoint.#.endpoints: '- Private endpoint through which you connect to Atlas when you use connection_strings.private_endpoint[n].connection_string or connection_strings.private_endpoint[n].srv_connection_string'
            connection_strings.private_endpoint.#.endpoints.#.endpoint_id: '- Unique identifier of the private endpoint.'
            connection_strings.private_endpoint.#.endpoints.#.provider_name: '- Cloud provider to which you deployed the private endpoint. Atlas returns AWS or AZURE.'
            connection_strings.private_endpoint.#.endpoints.#.region: '- Region to which you deployed the private endpoint.'
            connection_strings.private_endpoint.#.srv_connection_string: '- Private-endpoint-aware mongodb+srv:// connection string for this private endpoint. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don''t need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn''t, use connection_strings.private_endpoint[n].connection_string'
            connection_strings.private_endpoint.#.srv_shard_optimized_connection_string: '- Private endpoint-aware connection string optimized for sharded clusters that uses the mongodb+srv:// protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don''t need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn''t, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.'
            connection_strings.private_endpoint.#.type: '- Type of MongoDB process that you connect to with the connection strings. Atlas returns MONGOD for replica sets, or MONGOS for sharded clusters.'
            connection_strings.private_srv: '-  Network-peering-endpoint-aware mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.standard: '-   Public mongodb:// connection string for this cluster.'
            connection_strings.standard_srv: '- Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.'
            container_id: '- The Container ID is the id of the container created when the first cluster in the region (AWS/Azure) or project (GCP) was created.'
            custom_openssl_cipher_config_tls12: '- (Optional) The custom OpenSSL cipher suite list for TLS 1.2. This field is only valid when tls_cipher_config_mode is set to CUSTOM.'
            default_read_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for read operations set for this cluster. MongoDB 4.4 clusters default to available.'
            default_write_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for write operations set for this cluster. MongoDB 4.4 clusters default to 1.'
            electable_nodes: '- (Optional) Number of electable nodes for Atlas to deploy to the region. Electable nodes can become the primary and can facilitate local reads.'
            enabled: '- (Optional) Specifies whether or not BI Connector for Atlas is enabled on the cluster.l'
            expiration_date: '- (Required) Expiration date of the fixed FCV. This value is in the ISO 8601 timestamp format (e.g. "2024-12-04T16:25:00Z"). Note that this field cannot exceed 4 weeks from the pinned date.'
            fail_index_key_too_long: '- (Optional) When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them.'
            "false": to disable disk auto-scaling.
            id: '- (Optional) Unique identifer of the replication document for a zone in a Global Cluster. This value corresponds to the legacy sharding schema (no independent shard scaling) and is different from the Shard ID you may see in the Atlas UI.'
            javascript_enabled: '- (Optional) When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.'
            key: '- (Required) Constant that defines the set of the tag.'
            minimum_enabled_tls_protocol: '- (Optional) Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:'
            mongo_db_version: '- Version of MongoDB the cluster runs, in major-version.minor-version format.'
            mongo_uri: '- Base connection string for the cluster. Atlas only displays this field after the cluster is operational, not while it builds the cluster.'
            mongo_uri_updated: '- Lists when the connection string was last updated. The connection string changes, for example, if you change a replica set to a sharded cluster.'
            mongo_uri_with_options: '- connection string for connecting to the Atlas cluster. Includes the replicaSet, ssl, and authSource query parameters in the connection string with values appropriate for the cluster.'
            mongodbatlas_privatelink_endpoint_service: resources are fully applied. Add a depends_on = [mongodbatlas_privatelink_endpoint_service.example] to ensure connection_strings are available following terraform apply. If the expected connection string(s) do not contain a value, a terraform refresh may need to be performed to obtain the value. One can also view the status of the peered connection in the Atlas UI.
            name: '- (Required) Name of the cluster as it appears in Atlas. Once the cluster is created, its name cannot be changed. WARNING Changing the name will result in destruction of the existing cluster and the creation of a new cluster.'
            no_table_scan: '- (Optional) When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.'
            num_shards: |-
                - (Required) Number of shards up to 50 to deploy for a sharded cluster. The resource returns 1 to indicate a replica set and values of 2 and higher to indicate a sharded cluster. The returned value equals the number of shards in the cluster.
                If you are upgrading a replica set to a sharded cluster, you cannot increase the number of shards in the same update request. You should wait until after the cluster has completed upgrading to sharded and you have reconnected all application clients to the MongoDB router before adding additional shards. Otherwise, your data might become inconsistent once MongoDB Cloud begins distributing data across shards. To learn more, see Convert a replica set to a sharded cluster documentation and Convert a replica set to a sharded cluster tutorial.
            oplog_min_retention_hours: '- (Optional) Minimum retention window for cluster''s oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.'
            oplog_size_mb: '- (Optional) The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.'
            priority: is 0.
            project_id: '- (Required) The unique ID for the project to create the database user.'
            provider_instance_size_name: '- (Required) Atlas provides different instance sizes, each with a default storage capacity and RAM size. The instance size you select is used for all the data-bearing servers in your cluster. See Create a Cluster providerSettings.instanceSizeName for valid values and default resources.'
            provider_name: '- (Required) Cloud service provider on which the servers are provisioned.'
            read_only_nodes: '- (Optional) Number of read-only nodes for Atlas to deploy to the region. Read-only nodes can never become the primary, but can facilitate local-reads. Specify 0 if you do not want any read-only nodes in the region.'
            read_preference: '- (Optional) Specifies the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of readPreference and readPreferenceTags options. For details on BI Connector for Atlas read preferences, refer to the BI Connector Read Preferences Table.'
            region_name: '- (Optional) Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases.  Requires the Atlas region name, see the reference list for AWS, GCP, Azure.'
            regions_config: '- (Optional) Physical location of the region. Each regionsConfig document describes the region’s priority in elections and the number and type of MongoDB nodes Atlas deploys to the region. You must order each regionsConfigs document by regionsConfig.priority, descending. See Region Config below for more details.'
            sample_refresh_interval_bi_connector: '- (Optional) Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            sample_size_bi_connector: '- (Optional) Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            snapshot_backup_policy: '- current snapshot schedule and retention settings for the cluster.'
            snapshot_backup_policy.#.cluster_id: '- Unique identifier of the Atlas cluster.'
            snapshot_backup_policy.#.cluster_name: '- Name of the Atlas cluster that contains the snapshot backup policy.'
            snapshot_backup_policy.#.next_snapshot: '- UTC ISO 8601 formatted point in time when Atlas will take the next snapshot.'
            snapshot_backup_policy.#.policies: '- A list of policy definitions for the cluster.'
            snapshot_backup_policy.#.policies.#.id: '- Unique identifier of the backup policy.'
            snapshot_backup_policy.#.policies.#.policy_item: '- A list of specifications for a policy.'
            snapshot_backup_policy.#.policies.#.policy_item.#.frequency_interval: '- The frequency interval for a set of snapshots.'
            snapshot_backup_policy.#.policies.#.policy_item.#.frequency_type: '- A type of frequency (hourly, daily, weekly, monthly).'
            snapshot_backup_policy.#.policies.#.policy_item.#.id: '- Unique identifier for this policy item.'
            snapshot_backup_policy.#.policies.#.policy_item.#.retention_unit: '- The unit of time in which snapshot retention is measured (days, weeks, months).'
            snapshot_backup_policy.#.policies.#.policy_item.#.retention_value: '- The number of days, weeks, or months the snapshot is retained.'
            snapshot_backup_policy.#.reference_hour_of_day: '- UTC Hour of day between 0 and 23 representing which hour of the day that Atlas takes a snapshot.'
            snapshot_backup_policy.#.reference_minute_of_hour: '- UTC Minute of day between 0 and 59 representing which minute of the referenceHourOfDay that Atlas takes the snapshot.'
            snapshot_backup_policy.#.restore_window_days: '- Specifies a restore window in days for the cloud provider backup to maintain.'
            snapshot_backup_policy.#.update_snapshots: '- Specifies it''s true to apply the retention changes in the updated backup policy to snapshots that Atlas took previously.'
            srv_address: '- Connection string for connecting to the Atlas cluster. The +srv modifier forces the connection to use TLS/SSL. See the mongoURI for additional options.'
            state_name: '- Current state of the cluster. The possible states are:'
            tls_cipher_config_mode: '- (Optional) The TLS cipher suite configuration mode. Valid values include CUSTOM or DEFAULT. The DEFAULT mode uses the default cipher suites. The CUSTOM mode allows you to specify custom cipher suites for both TLS 1.2 and TLS 1.3. To unset, this should be set back to DEFAULT.'
            transaction_lifetime_limit_seconds: '- (Optional) Lifetime, in seconds, of multi-document transactions. Defaults to 60 seconds.'
            "true": to enable disk auto-scaling.
            value: '- (Required) Variable that belongs to the set of the tag.'
            version: '- Feature compatibility version of the cluster.'
            zone_name: '- (Optional) Name for the zone in a Global Cluster.'
        importStatements: []
    mongodbatlas_cluster_outage_simulation:
        subCategory: ""
        name: mongodbatlas_cluster_outage_simulation
        title: mongodbatlas_cluster_outage_simulation Resource - terraform-provider-mongodbatlas
        examples:
            - name: outage_simulation
              manifest: |-
                {
                  "cluster_name": "Cluster0",
                  "outage_filters": [
                    {
                      "cloud_provider": "AWS",
                      "region_name": "US_EAST_1"
                    },
                    {
                      "cloud_provider": "AWS",
                      "region_name": "US_EAST_2"
                    }
                  ],
                  "project_id": "64707f06c519c20c3a2b1b03"
                }
        argumentDocs:
            COMPLETE: '- MongoDB Cloud has completed the cluster outage simulation.'
            RECOVERING: '- MongoDB Cloud is recovering the cluster from the simulated outage.'
            RECOVERY_REQUESTED: '- User has requested recovery from the simulated outage.'
            REGION: '- Simulates a cluster outage for a region'
            SIMULATING: '- MongoDB Cloud is simulating cluster outage.'
            START_REQUESTED: '- User has requested cluster outage simulation.'
            STARTING: '- MongoDB Cloud is starting cluster outage simulation.'
            cloud_provider: '- (Required) The cloud provider of the region that undergoes the outage simulation. Following values are supported:'
            cluster_name: '- (Required) Name of the Atlas Cluster that is/will undergoing outage simulation.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            outage_filters: '- (Minimum one required) List of settings that specify the type of cluster outage simulation.'
            project_id: '- (Required) The unique ID for the project that contains the cluster that is/will undergoing outage simulation.'
            region_name: '- (Required) The Atlas name of the region to undergo an outage simulation.'
            simulation_id: '- Unique 24-hexadecimal character string that identifies the outage simulation.'
            start_request_date: '- Date and time when MongoDB Cloud started the regional outage simulation.'
            state: '- Current phase of the outage simulation:'
            type: '- The type of cluster outage simulation. Following values are supported:'
        importStatements: []
    mongodbatlas_custom_db_role:
        subCategory: ""
        name: mongodbatlas_custom_db_role
        title: mongodbatlas_custom_db_role Resource - terraform-provider-mongodbatlas
        examples:
            - name: test_role
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "UPDATE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    },
                    {
                      "action": "INSERT",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    },
                    {
                      "action": "REMOVE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "role_name": "myCustomRole"
                }
            - name: inherited_role_one
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "INSERT",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "role_name": "insertRole"
                }
            - name: inherited_role_two
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "SERVER_STATUS",
                      "resources": [
                        {
                          "cluster": true
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_custom_db_role.inherited_role_one.project_id}",
                  "role_name": "statusServerRole"
                }
              references:
                project_id: mongodbatlas_custom_db_role.inherited_role_one.project_id
            - name: test_role
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "UPDATE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    },
                    {
                      "action": "REMOVE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    }
                  ],
                  "inherited_roles": [
                    {
                      "database_name": "admin",
                      "role_name": "${mongodbatlas_custom_db_role.inherited_role_one.role_name}"
                    },
                    {
                      "database_name": "admin",
                      "role_name": "${mongodbatlas_custom_db_role.inherited_role_two.role_name}"
                    }
                  ],
                  "project_id": "${mongodbatlas_custom_db_role.inherited_role_one.project_id}",
                  "role_name": "myCustomRole"
                }
              references:
                inherited_roles.role_name: mongodbatlas_custom_db_role.inherited_role_two.role_name
                project_id: mongodbatlas_custom_db_role.inherited_role_one.project_id
        argumentDocs:
            action: |-
                - (Required) Name of the privilege action. For a complete list of actions available in the Atlas API, see Custom Role Actions
                -> Note: The privilege actions available to the Custom Roles API resource represent a subset of the privilege actions available in the Atlas Custom Roles UI.
            actions.resources.cluster: field.
            actions.resources.collection: and actions.resources.db fields.
            database_name: (Required) Database on which the inherited role is granted.
            id: '- Unique identifier used for terraform for internal manages and can be used to import.'
            project_id: '- (Required) The unique ID for the project to create the database user.'
            resources: '- (Required) Contains information on where the action is granted. Each object in the array either indicates a database and collection on which the action is granted, or indicates that the action is granted on the cluster resource.'
            resources.#.cluster: (Optional) Set to true to indicate that the action is granted on the cluster resource.
            resources.#.collection_name: '- (Optional) Collection on which the action is granted. If this value is an empty string, the action is granted on all collections within the database specified in the actions.resources.db field.'
            resources.#.database_name: Database on which the action is granted.
            role_name: '- (Required) Name of the custom role.'
        importStatements: []
    mongodbatlas_custom_dns_configuration_cluster_aws:
        subCategory: ""
        name: mongodbatlas_custom_dns_configuration_cluster_aws
        title: mongodbatlas_custom_dns_configuration_cluster_aws Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
        argumentDocs:
            enabled: '- (Required) Indicates whether the project''s clusters deployed to AWS use custom DNS. If true, the Get All Clusters and Get One Cluster endpoints return the connectionStrings.private and connectionStrings.privateSrv fields for clusters deployed to AWS .'
            project_id: "- Required \tUnique identifier for the project."
        importStatements: []
    mongodbatlas_data_lake_pipeline:
        subCategory: ""
        name: mongodbatlas_data_lake_pipeline
        title: mongodbatlas_data_lake_pipeline Resource - terraform-provider-mongodbatlas
        examples:
            - name: pipeline
              manifest: |-
                {
                  "name": "DataLakePipelineName",
                  "project_id": "${mongodbatlas_project.projectTest.project_id}",
                  "sink": [
                    {
                      "partition_fields": [
                        {
                          "name": "access",
                          "order": 0
                        }
                      ],
                      "type": "DLS"
                    }
                  ],
                  "source": [
                    {
                      "cluster_name": "${mongodbatlas_advanced_cluster.automated_backup_test.name}",
                      "collection_name": "listingsAndReviews",
                      "database_name": "sample_airbnb",
                      "type": "ON_DEMAND_CPS"
                    }
                  ],
                  "transformations": [
                    {
                      "field": "test",
                      "type": "EXCLUDE"
                    },
                    {
                      "field": "test22",
                      "type": "EXCLUDE"
                    }
                  ]
                }
              references:
                project_id: mongodbatlas_project.projectTest.project_id
                source.cluster_name: mongodbatlas_advanced_cluster.automated_backup_test.name
              dependencies:
                mongodbatlas_advanced_cluster.automated_backup_test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "automated-backup-test",
                      "project_id": "${var.project_id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "GCP",
                              "region_name": "US_EAST_4"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_project.projectTest: |-
                    {
                      "name": "NAME OF THE PROJECT",
                      "org_id": "ORGANIZATION ID"
                    }
        argumentDocs:
            cluster_name: '- Human-readable name that identifies the cluster.'
            collection_name: '- Human-readable name that identifies the collection.'
            created_date: '- Timestamp that indicates when the Data Lake Pipeline was created.'
            database_name: '- Human-readable name that identifies the database.'
            id: '-  Unique 24-hexadecimal digit string that identifies the Data Lake Pipeline.'
            ingestion_schedules: '- List of backup schedule policy items that you can use as a Data Lake Pipeline source.'
            ingestion_schedules.#.frequency_interval: '- Number that indicates the frequency interval for a set of snapshots.'
            ingestion_schedules.#.frequency_type: '- Human-readable label that identifies the frequency type associated with the backup policy.'
            ingestion_schedules.#.id: '- Unique 24-hexadecimal digit string that identifies this backup policy item.'
            ingestion_schedules.#.retention_unit: '- Unit of time in which MongoDB Atlas measures snapshot retention.'
            ingestion_schedules.#.retention_value: '- Duration in days, weeks, or months that MongoDB Atlas retains the snapshot.'
            last_updated_date: '- Timestamp that indicates the last time that the Data Lake Pipeline was updated.'
            name: '- (Required) Name of the Atlas Data Lake Pipeline.'
            partition_fields: '- Ordered fields used to physically organize data in the destination.'
            partition_fields.#.field_name: '- Human-readable label that identifies the field name used to partition data.'
            partition_fields.#.order: '- Sequence in which MongoDB Atlas slices the collection data to create partitions. The resource expresses this sequence starting with zero.'
            policyItemId: '- Unique 24-hexadecimal character string that identifies a policy item.'
            project_id: '- (Required) The unique ID for the project to create a data lake pipeline.'
            provider: '- Target cloud provider for this Data Lake Pipeline.'
            region: '- Target cloud provider region for this Data Lake Pipeline. Supported cloud provider regions.'
            snapshots: '- List of backup snapshots that you can use to trigger an on demand pipeline run.'
            snapshots.#.copy_region: '- List that identifies the regions to which MongoDB Atlas copies the snapshot.'
            snapshots.#.created_at: '- Date and time when MongoDB Atlas took the snapshot.'
            snapshots.#.expires_at: '- Date and time when MongoDB Atlas deletes the snapshot.'
            snapshots.#.frequency_type: '- Human-readable label that identifies how often this snapshot triggers.'
            snapshots.#.id: '- Unique 24-hexadecimal digit string that identifies the snapshot.'
            snapshots.#.master_key: '- Unique string that identifies the Amazon Web Services (AWS) Key Management Service (KMS) Customer Master Key (CMK) used to encrypt the snapshot.'
            snapshots.#.mongod_version: '- Version of the MongoDB host that this snapshot backs up.'
            snapshots.#.policies: '- List that contains unique identifiers for the policy items.'
            snapshots.#.provider: '- Human-readable label that identifies the cloud provider that stores this snapshot.'
            snapshots.#.replica_set_name: '- Human-readable label that identifies the replica set from which MongoDB Atlas took this snapshot.'
            snapshots.#.size: '- List of backup snapshots that you can use to trigger an on demand pipeline run.'
            snapshots.#.snapshot_type: '- Human-readable label that identifies when this snapshot triggers.'
            snapshots.#.status: '- Human-readable label that indicates the stage of the backup process for this snapshot.'
            snapshots.#.type: '- Human-readable label that categorizes the cluster as a replica set or sharded cluster.'
            state: '- State of this Data Lake Pipeline.'
            transformations: '- Fields to be excluded for this Data Lake Pipeline.'
            transformations.#.field: '- Key in the document.'
            transformations.#.type: '- Type of transformation applied during the export of the namespace in a Data Lake Pipeline.'
            type: '- Type of ingestion destination of this Data Lake Pipeline.'
        importStatements: []
    mongodbatlas_database_user:
        subCategory: ""
        name: mongodbatlas_database_user
        title: mongodbatlas_database_user Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "auth_database_name": "admin",
                  "labels": [
                    {
                      "key": "My Key",
                      "value": "My Value"
                    }
                  ],
                  "password": "test-acc-password",
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    {
                      "database_name": "dbforApp",
                      "role_name": "readWrite"
                    },
                    {
                      "database_name": "admin",
                      "role_name": "readAnyDatabase"
                    }
                  ],
                  "scopes": [
                    {
                      "name": "My cluster name",
                      "type": "CLUSTER"
                    },
                    {
                      "name": "My second cluster name",
                      "type": "CLUSTER"
                    }
                  ],
                  "username": "test-acc-username"
                }
            - name: test
              manifest: |-
                {
                  "auth_database_name": "$external",
                  "labels": [
                    {
                      "key": "%s",
                      "value": "%s"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    {
                      "database_name": "admin",
                      "role_name": "readAnyDatabase"
                    }
                  ],
                  "scopes": [
                    {
                      "name": "My cluster name",
                      "type": "CLUSTER"
                    }
                  ],
                  "username": "test-acc-username",
                  "x509_type": "MANAGED"
                }
            - name: test
              manifest: |-
                {
                  "auth_database_name": "$external",
                  "aws_iam_type": "ROLE",
                  "labels": [
                    {
                      "key": "%s",
                      "value": "%s"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    {
                      "database_name": "admin",
                      "role_name": "readAnyDatabase"
                    }
                  ],
                  "scopes": [
                    {
                      "name": "My cluster name",
                      "type": "CLUSTER"
                    }
                  ],
                  "username": "${aws_iam_role.test.arn}"
                }
              references:
                username: aws_iam_role.test.arn
            - name: test
              manifest: |-
                {
                  "auth_database_name": "admin",
                  "oidc_auth_type": "IDP_GROUP",
                  "project_id": "6414908c207f4d22f4d8f232",
                  "roles": [
                    {
                      "database_name": "admin",
                      "role_name": "readWriteAnyDatabase"
                    }
                  ],
                  "username": "64d613677e1ad50839cce4db/testUserOr"
                }
        argumentDocs:
            $external: if x509_type is MANAGED or CUSTOMER or aws_iam_type is USER or ROLE.
            CUSTOMER: '-  The user is being created for use with Self-Managed X.509. Users created with this x509Type require a Common Name (CN) in the username field. Externally authenticated users can only be created on the $external database.'
            GROUP: '- LDAP server authenticates this user using their LDAP user and authorizes this user using their LDAP group. To learn more about LDAP security, see Set up User Authentication and Authorization with LDAP. username must also be a fully qualified distinguished name, as defined in RFC-2253.'
            IDP_GROUP: '- OIDC Workforce federated authentication group. To learn more about OIDC federated authentication, see Set up Workforce Identity Federation with OIDC.'
            MANAGED: '- The user is being created for use with Atlas-managed X.509.Externally authenticated users can only be created on the $external database.'
            NONE: "-\tThe user does not use X.509 authentication."
            ROLE: '-  New database user has credentials associated with an AWS IAM role.'
            USER: '- New database user has AWS IAM user credentials.'
            admin: if x509_type and aws_iam_type are omitted or NONE.
            auth_database_name: |-
                - (Required) Database against which Atlas authenticates the user. A user must provide both a username and authentication database to log into MongoDB.
                Accepted values include:
            aws_iam_type: '- (Optional) If this value is set, the new database user authenticates with AWS IAM credentials. If no value is given, Atlas uses the default value of NONE. The accepted types are:'
            collection_name: '- (Optional) Collection for which the role applies. You can specify a collection for the read and readWrite roles. If you do not specify a collection for read and readWrite, the role applies to all collections in the database (excluding some collections in the system. database).'
            database_name: '- (Required) Database on which the user has the specified role. A role on the admin database can include privileges that apply to the other databases. This field should be set to admin for a custom MongoDB role.'
            id: '- The database user''s name.'
            key: '- The key that you want to write.'
            ldap_auth_type: '- (Optional) Method by which the provided username is authenticated. If no value is given, Atlas uses the default value of NONE.'
            name: '- (Required) Name of the cluster or Atlas Data Lake that the user has access to.'
            oidc_auth_type: '- (Optional) Human-readable label that indicates whether the new database user authenticates with OIDC (OpenID Connect) federated authentication. If no value is given, Atlas uses the default value of NONE. The accepted types are:'
            password: '- (Required) User''s initial password. A value is required to create the database user, however the argument may be removed from your Terraform configuration after user creation without impacting the user, password or Terraform management. If you do change management of the password to outside of Terraform it is advised to remove the argument from the Terraform configuration. IMPORTANT --- Passwords may show up in Terraform related logs and it will be stored in the Terraform state file as plain-text. Password can be changed after creation using your preferred method, e.g. via the MongoDB Atlas UI, to ensure security.'
            project_id: '- (Required) The unique ID for the project to create the database user.'
            role_name: '- (Required) Name of the role to grant. See Create a Database User roles.roleName for valid values and restrictions.'
            roles: "- (Required) \tList of user’s roles and the databases / collections on which the roles apply. A role allows the user to perform particular actions on the specified database. A role on the admin database can include privileges that apply to the other databases as well. See Roles below for more details."
            type: '- (Required) Type of resource that the user has access to. Valid values are: CLUSTER and DATA_LAKE'
            username: '- (Required) Username for authenticating to MongoDB. USER_ARN or ROLE_ARN if aws_iam_type is USER or ROLE.'
            value: '- The value that you want to write.'
            x509_type: '- (Optional) X.509 method by which the provided username is authenticated. If no value is given, Atlas uses the default value of NONE. The accepted types are:'
        importStatements: []
    mongodbatlas_encryption_at_rest:
        subCategory: ""
        name: mongodbatlas_encryption_at_rest
        title: mongodbatlas_encryption_at_rest Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "aws_kms_config": [
                    {
                      "customer_master_key_id": "${aws_kms_key.kms_key.id}",
                      "enabled": true,
                      "region": "${var.atlas_region}",
                      "role_id": "${mongodbatlas_cloud_provider_access_authorization.auth_role.role_id}"
                    }
                  ],
                  "project_id": "${var.atlas_project_id}"
                }
              references:
                aws_kms_config.customer_master_key_id: aws_kms_key.kms_key.id
                aws_kms_config.region: var.atlas_region
                aws_kms_config.role_id: mongodbatlas_cloud_provider_access_authorization.auth_role.role_id
                project_id: var.atlas_project_id
              dependencies:
                mongodbatlas_advanced_cluster.cluster: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "encryption_at_rest_provider": "AWS",
                      "name": "MyCluster",
                      "project_id": "${mongodbatlas_encryption_at_rest.test.project_id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "US_EAST_1"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_cloud_provider_access_authorization.auth_role: |-
                    {
                      "aws": [
                        {
                          "iam_assumed_role_arn": "${aws_iam_role.test_role.arn}"
                        }
                      ],
                      "project_id": "${var.atlas_project_id}",
                      "role_id": "${mongodbatlas_cloud_provider_access_setup.setup_only.role_id}"
                    }
                mongodbatlas_cloud_provider_access_setup.setup_only: |-
                    {
                      "project_id": "${var.atlas_project_id}",
                      "provider_name": "AWS"
                    }
            - name: default
              manifest: '{}'
            - name: test
              manifest: |-
                {
                  "azure_key_vault_config": [
                    {
                      "azure_environment": "AZURE",
                      "client_id": "${var.azure_client_id}",
                      "enabled": true,
                      "key_identifier": "${var.azure_key_identifier}",
                      "key_vault_name": "${var.azure_key_vault_name}",
                      "resource_group_name": "${var.azure_resource_group_name}",
                      "secret": "${var.azure_client_secret}",
                      "subscription_id": "${var.azure_subscription_id}",
                      "tenant_id": "${var.azure_tenant_id}"
                    }
                  ],
                  "project_id": "${var.atlas_project_id}"
                }
              references:
                azure_key_vault_config.client_id: var.azure_client_id
                azure_key_vault_config.key_identifier: var.azure_key_identifier
                azure_key_vault_config.key_vault_name: var.azure_key_vault_name
                azure_key_vault_config.resource_group_name: var.azure_resource_group_name
                azure_key_vault_config.secret: var.azure_client_secret
                azure_key_vault_config.subscription_id: var.azure_subscription_id
                azure_key_vault_config.tenant_id: var.azure_tenant_id
                project_id: var.atlas_project_id
            - name: test
              manifest: |-
                {
                  "google_cloud_kms_config": [
                    {
                      "enabled": true,
                      "key_version_resource_id": "projects/my-project-common-0/locations/us-east4/keyRings/my-key-ring-0/cryptoKeys/my-key-0/cryptoKeyVersions/1",
                      "service_account_key": "{\"type\": \"service_account\",\"project_id\": \"my-project-common-0\",\"private_key_id\": \"e120598ea4f88249469fcdd75a9a785c1bb3\",\"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEuwIBA(truncated)SfecnS0mT94D9\\n-----END PRIVATE KEY-----\\n\",\"client_email\": \"my-email-kms-0@my-project-common-0.iam.gserviceaccount.com\",\"client_id\": \"10180967717292066\",\"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-email-kms-0%40my-project-common-0.iam.gserviceaccount.com\"}"
                    }
                  ],
                  "project_id": "${var.atlas_project_id}"
                }
              references:
                project_id: var.atlas_project_id
        argumentDocs:
            access_key_id: (String, Sensitive) Unique alphanumeric string that identifies an Identity and Access Management (IAM) access key with permissions required to access your Amazon Web Services (AWS) Customer Master Key (CMK).
            aws_kms_config: (Block List) Amazon Web Services (AWS) KMS configuration details and encryption at rest configuration set for the specified project. (see below for nested schema)
            azure_environment: (String) Azure environment in which your account credentials reside.
            azure_key_vault_config: (Block List) Details that define the configuration of Encryption at Rest using Azure Key Vault (AKV). (see below for nested schema)
            client_id: (String, Sensitive) Unique 36-hexadecimal character string that identifies an Azure application associated with your Azure Active Directory tenant.
            customer_master_key_id: (String, Sensitive) Unique alphanumeric string that identifies the Amazon Web Services (AWS) Customer Master Key (CMK) you used to encrypt and decrypt the MongoDB master keys.
            enabled: (Boolean) Flag that indicates whether someone enabled encryption at rest for the specified project through Amazon Web Services (AWS) Key Management Service (KMS). To disable encryption at rest using customer key management and remove the configuration details, pass only this parameter with a value of false.
            google_cloud_kms_config: (Block List) Details that define the configuration of Encryption at Rest using Google Cloud Key Management Service (KMS). (see below for nested schema)
            id: (String) The ID of this resource.
            key_identifier: (String, Sensitive) Web address with a unique key that identifies for your Azure Key Vault.
            key_vault_name: (String) Unique string that identifies the Azure Key Vault that contains your key.
            key_version_resource_id: (String, Sensitive) Resource path that displays the key version resource ID for your Google Cloud KMS.
            project_id: (String) Unique 24-hexadecimal digit string that identifies your project.
            region: (String) Physical location where MongoDB Atlas deploys your AWS-hosted MongoDB cluster nodes. The region you choose can affect network latency for clients accessing your databases. When MongoDB Cloud deploys a dedicated cluster, it checks if a VPC or VPC connection exists for that provider and region. If not, MongoDB Atlas creates them as part of the deployment. MongoDB Atlas assigns the VPC a CIDR block. To limit a new VPC peering connection to one CIDR block and region, create the connection first. Deploy the cluster after the connection starts.
            require_private_networking: (Boolean) Enable connection to your Azure Key Vault over private networking.
            resource_group_name: (String) Name of the Azure resource group that contains your Azure Key Vault.
            role_id: (String) Unique 24-hexadecimal digit string that identifies an Amazon Web Services (AWS) Identity and Access Management (IAM) role. This IAM role has the permissions required to manage your AWS customer master key.
            secret: (String, Sensitive) Private data that you need secured and that belongs to the specified Azure Key Vault (AKV) tenant (azureKeyVault.tenantID). This data can include any type of sensitive data such as passwords, database connection strings, API keys, and the like. AKV stores this information as encrypted binary data.
            secret_access_key: (String, Sensitive) Human-readable label of the Identity and Access Management (IAM) secret access key with permissions required to access your Amazon Web Services (AWS) customer master key.
            service_account_key: (String, Sensitive) JavaScript Object Notation (JSON) object that contains the Google Cloud Key Management Service (KMS). Format the JSON as a string and not as an object.
            subscription_id: (String, Sensitive) Unique 36-hexadecimal character string that identifies your Azure subscription.
            tenant_id: (String, Sensitive) Unique 36-hexadecimal character string that identifies the Azure Active Directory tenant within your Azure subscription.
            valid: (Boolean) Flag that indicates whether the Amazon Web Services (AWS) Key Management Service (KMS) encryption key can encrypt and decrypt data.
        importStatements: []
    mongodbatlas_encryption_at_rest_private_endpoint:
        subCategory: ""
        name: mongodbatlas_encryption_at_rest_private_endpoint
        title: mongodbatlas_encryption_at_rest_private_endpoint Resource - terraform-provider-mongodbatlas
        examples:
            - name: endpoint
              manifest: |-
                {
                  "cloud_provider": "AZURE",
                  "project_id": "${mongodbatlas_encryption_at_rest.ear.project_id}",
                  "region_name": "${var.azure_region_name}"
                }
              references:
                project_id: mongodbatlas_encryption_at_rest.ear.project_id
                region_name: var.azure_region_name
              dependencies:
                azapi_update_resource.approval: |-
                    {
                      "body": "${jsonencode({\n    properties = {\n      privateLinkServiceConnectionState = {\n        description = \"Approved via Terraform\"\n        status      = \"Approved\"\n      }\n    }\n  })}",
                      "name": "${mongodbatlas_encryption_at_rest_private_endpoint.endpoint.private_endpoint_connection_name}",
                      "parent_id": "${local.key_vault_resource_id}",
                      "type": "Microsoft.KeyVault/Vaults/PrivateEndpointConnections@2023-07-01"
                    }
                mongodbatlas_encryption_at_rest.ear: |-
                    {
                      "azure_key_vault_config": [
                        {
                          "azure_environment": "AZURE",
                          "client_id": "${var.azure_client_id}",
                          "enabled": true,
                          "key_identifier": "${var.azure_key_identifier}",
                          "key_vault_name": "${var.azure_key_vault_name}",
                          "require_private_networking": true,
                          "resource_group_name": "${var.azure_resource_group_name}",
                          "secret": "${var.azure_client_secret}",
                          "subscription_id": "${var.azure_subscription_id}",
                          "tenant_id": "${var.azure_tenant_id}"
                        }
                      ],
                      "project_id": "${var.atlas_project_id}"
                    }
        argumentDocs:
            cloud_provider: (String) Label that identifies the cloud provider for the Encryption At Rest private endpoint.
            error_message: (String) Error message for failures associated with the Encryption At Rest private endpoint.
            id: (String) Unique 24-hexadecimal digit string that identifies the Private Endpoint Service.
            private_endpoint_connection_name: (String) Connection name of the Azure Private Endpoint.
            project_id: (String) Unique 24-hexadecimal digit string that identifies your project.
            region_name: (String) Cloud provider region in which the Encryption At Rest private endpoint is located.
            status: (String) State of the Encryption At Rest private endpoint.
        importStatements: []
    mongodbatlas_event_trigger:
        subCategory: ""
        name: mongodbatlas_event_trigger
        title: mongodbatlas_event_trigger Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_collection": "COLLECTION NAME",
                  "config_database": "DATABASE NAME",
                  "config_full_document": false,
                  "config_full_document_before": false,
                  "config_match": "{\n  \"updateDescription.updatedFields\": {\n    \"status\": \"blocked\"\n  }\n}\n",
                  "config_operation_types": [
                    "INSERT",
                    "UPDATE"
                  ],
                  "config_project": "{\"updateDescription.updatedFields\":{\"status\":\"blocked\"}}",
                  "config_service_id": "SERVICE ID",
                  "disabled": false,
                  "event_processors": [
                    {
                      "aws_eventbridge": [
                        {
                          "config_account_id": "AWS ACCOUNT ID",
                          "config_region": "AWS REGIOn"
                        }
                      ]
                    }
                  ],
                  "function_id": "FUNCTION ID",
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "DATABASE"
                }
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_collection": "COLLECTION NAME",
                  "config_database": "DATABASE NAME",
                  "config_full_document": false,
                  "config_full_document_before": false,
                  "config_match": "{\"updateDescription.updatedFields\":{\"status\":\"blocked\"}}",
                  "config_operation_type": "LOGIN",
                  "config_operation_types": [
                    "INSERT",
                    "UPDATE"
                  ],
                  "config_project": "{\"updateDescription.updatedFields\":{\"status\":\"blocked\"}}",
                  "config_providers": [
                    "anon-user"
                  ],
                  "config_schedule": "*",
                  "config_service_id": "1",
                  "disabled": false,
                  "event_processors": [
                    {
                      "aws_eventbridge": [
                        {
                          "config_account_id": "AWS ACCOUNT ID",
                          "config_region": "AWS REGIOn"
                        }
                      ]
                    }
                  ],
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "DATABASE",
                  "unordered": false
                }
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_operation_type": "LOGIN",
                  "config_providers": [
                    "anon-user"
                  ],
                  "disabled": false,
                  "function_id": "1",
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "AUTHENTICATION"
                }
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_schedule": "*",
                  "disabled": false,
                  "function_id": "1",
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "SCHEDULED"
                }
        argumentDocs:
            app_id: '- (Required) The ObjectID of your application.'
            config_collection: '- Optional for DATABASE type. The name of the MongoDB collection that the trigger watches for change events. The collection must be part of the specified database.'
            config_database: '- Required for DATABASE type. The name of the MongoDB database to watch.'
            config_full_document: '- Optional for DATABASE type. If true, indicates that UPDATE change events should include the most current majority-committed version of the modified document in the fullDocument field.'
            config_match: '- Optional for DATABASE type. A $match expression document that MongoDB Realm includes in the underlying change stream pipeline for the trigger. This is useful when you want to filter change events beyond their operation type. The trigger will only fire if the expression evaluates to true for a given change event.'
            config_operation_type: '- Required for AUTHENTICATION type. The authentication operation type to listen for. Possible Values: LOGIN, CREATE, DELETE'
            config_operation_types: '- Required for DATABASE type. The database event operation types to listen for. This must contain at least one value. Possible Values: INSERT, UPDATE, REPLACE, DELETE'
            config_project: '- Optional for DATABASE type. A $project expression document that Realm uses to filter the fields that appear in change event objects.'
            config_providers: '- Required for AUTHENTICATION type. A list of one or more authentication provider id values. The trigger will only listen for authentication events produced by these providers.'
            config_schedule: '- Required for SCHEDULED type. A cron expression that defines the trigger schedule.'
            config_service_id: '- Required for DATABASE type. The ID of the MongoDB Service associated with the trigger.'
            disabled: '- (Optional) Default: false If true, the trigger is disabled.'
            event_processors: '- (Optional) An object where each field name is an event processor ID and each value is an object that configures its corresponding event processor. The following event processors are supported: AWS_EVENTBRIDGE For an example configuration object, see Send Trigger Events to AWS EventBridge.'
            event_processors.0.aws_eventbridge.config_account_id: '- (Optional) AWS Account ID.'
            event_processors.0.aws_eventbridge.config_region: '- (Optional) Region of AWS Account.'
            function_id: '- (Optional) The ID of the function associated with the trigger.'
            function_name: '- The name of the function associated with the trigger.'
            id: '- Terraform''s unique identifier used internally for state management.'
            name: '- (Required) The name of the trigger.'
            project_id: '- (Required) The unique ID for the project to create the trigger.'
            trigger_id: '- The unique ID of the trigger.'
            type: '- (Required) The type of the trigger. Possible Values: DATABASE, AUTHENTICATION,SCHEDULED'
            unordered: '- Only Available for Database Triggers. If true, event ordering is disabled and this trigger can process events in parallel. If false, event ordering is enabled and the trigger executes serially.'
        importStatements: []
    mongodbatlas_federated_database_instance:
        subCategory: ""
        name: mongodbatlas_federated_database_instance
        title: mongodbatlas_federated_database_instance Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "name": "TENANT NAME OF THE FEDERATED DATABASE INSTANCE",
                  "project_id": "PROJECT ID",
                  "storage_databases": [
                    {
                      "collections": [
                        {
                          "data_sources": [
                            {
                              "collection": "COLLECTION IN THE CLUSTER",
                              "database": "DB IN THE CLUSTER",
                              "store_name": "CLUSTER NAME"
                            }
                          ],
                          "name": "NAME OF THE COLLECTION"
                        }
                      ],
                      "name": "VirtualDatabase0"
                    }
                  ],
                  "storage_stores": [
                    {
                      "cluster_name": "CLUSTER NAME",
                      "name": "STORE 1 NAME",
                      "project_id": "PROJECT ID",
                      "provider": "atlas",
                      "read_preference": [
                        {
                          "mode": "secondary"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cloud_provider_config": [
                    {
                      "aws": [
                        {
                          "role_id": "AWS ROLE ID",
                          "test_s3_bucket": "S3 BUCKET NAME"
                        }
                      ]
                    }
                  ],
                  "name": "TENANT NAME OF THE FEDERATED DATABASE INSTANCE",
                  "project_id": "PROJECT ID",
                  "storage_databases": [
                    {
                      "collections": [
                        {
                          "data_sources": [
                            {
                              "collection": "COLLECTION IN THE CLUSTER",
                              "database": "DB IN THE CLUSTER",
                              "store_name": "CLUSTER NAME"
                            },
                            {
                              "path": "S3 BUCKET PATH",
                              "store_name": "S3 BUCKET NAME"
                            }
                          ],
                          "name": "NAME OF THE COLLECTION"
                        }
                      ],
                      "name": "VirtualDatabase0"
                    }
                  ],
                  "storage_stores": [
                    {
                      "cluster_name": "CLUSTER NAME",
                      "name": "STORE 1 NAME",
                      "project_id": "PROJECT ID",
                      "provider": "atlas",
                      "read_preference": [
                        {
                          "mode": "secondary"
                        }
                      ]
                    },
                    {
                      "bucket": "STORE 2 NAME",
                      "delimiter": "/",
                      "name": "S3 BUCKET NAME",
                      "prefix": "S3 BUCKET PREFIX",
                      "provider": "s3",
                      "region": "AWS REGION"
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "data_process_region": [
                    {
                      "cloud_provider": "AWS",
                      "region": "OREGON_USA"
                    }
                  ],
                  "name": "NAME OF THE FEDERATED DATABASE INSTANCE",
                  "project_id": "PROJECT ID"
                }
        argumentDocs:
            ACTIVE: '- The Federated Database Instance is active and verified. You can query the data stores associated with the Federated Database Instance.'
            DELETED: '- The Federated Database Instance was deleted.'
            cloud_provider_config: '- (Optional) Cloud provider linked to this data federated instance.'
            cloud_provider_config.aws: '- (Required) AWS provider of the cloud service where the Federated Database Instance can access the S3 Bucket. Note this parameter is only required if using cloud_provider_config since AWS is currently the only supported Cloud vendor on this feature at this time.'
            cloud_provider_config.aws.role_id: '- (Required) Unique identifier of the role that the Federated Instance can use to access the data stores. If necessary, use the Atlas UI or API to retrieve the role ID. You must also specify the test_s3_bucket.'
            cloud_provider_config.aws.test_s3_bucket: '- (Required) Name of the S3 data bucket that the provided role ID is authorized to access. You must also specify the role_id.'
            data_process_region: '- (Optional) The cloud provider region to which the Federated Instance routes client connections for data processing.'
            data_process_region.cloud_provider: '- (Required) Name of the cloud service provider. Atlas Federated Database only supports AWS.'
            data_process_region.region: '- (Required) Name of the region to which the Federanted Instnace routes client connections for data processing. See the documention for the available region.'
            external_id: '- Unique identifier associated with the IAM Role that the Federated Database Instance assumes when accessing the data stores.'
            hostnames: '- The list of hostnames assigned to the Federated Database Instance. Each string in the array is a hostname assigned to the Federated Database Instance.'
            iam_assumed_role_arn: '- Amazon Resource Name (ARN) of the IAM Role that the Federated Database Instance assumes when accessing S3 Bucket data stores. The IAM Role must support the following actions against each S3 bucket:'
            iam_user_arn: '- Amazon Resource Name (ARN) of the user that the Federated Database Instance assumes when accessing S3 Bucket data stores.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            name: '- (Required) Name of the Atlas Federated Database Instance.'
            project_id: '- (Required) The unique ID for the project to create a Federated Database Instance.'
            state: '- Current state of the Federated Database Instance:'
            storage_databases: '- Configuration details for mapping each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see databases. An empty object indicates that the Federated Database Instance has no mapping configuration for any data store.'
            storage_databases.#.collections: '-     Array of objects where each object represents a collection and data sources that map to a stores data store.'
            storage_databases.#.collections.#.data_sources: '-     Array of objects where each object represents a stores data store to map with the collection.'
            storage_databases.#.collections.#.data_sources.#.allow_insecure: '- Flag that validates the scheme in the specified URLs. If true, allows insecure HTTP scheme, doesn''t verify the server''s certificate chain and hostname, and accepts any certificate with any hostname presented by the server. If false, allows secure HTTPS scheme only.'
            storage_databases.#.collections.#.data_sources.#.collection: '- Human-readable label that identifies the collection in the database.'
            storage_databases.#.collections.#.data_sources.#.collection_regex: '- Regex pattern to use for creating the wildcard (*) collection.'
            storage_databases.#.collections.#.data_sources.#.database: '- Human-readable label that identifies the database, which contains the collection in the cluster.'
            storage_databases.#.collections.#.data_sources.#.database_regex: '- Regex pattern to use for creating the wildcard database.'
            storage_databases.#.collections.#.data_sources.#.dataset_name: '-     Human-readable label that identifies the dataset that Atlas generates for an ingestion pipeline run or Online Archive.'
            storage_databases.#.collections.#.data_sources.#.default_format: '- Default format that Federated Database assumes if it encounters a file without an extension while searching the storeName.'
            storage_databases.#.collections.#.data_sources.#.path: '- File path that controls how MongoDB Cloud searches for and parses files in the storeName before mapping them to a collection. Specify / to capture all files and folders from the prefix path.'
            storage_databases.#.collections.#.data_sources.#.provenance_field_name: '- Name for the field that includes the provenance of the documents in the results.'
            storage_databases.#.collections.#.data_sources.#.store_name: '-     Name of a data store to map to the <collection>. Must match the name of an object in the stores array.'
            storage_databases.#.collections.#.data_sources.#.storeName: '- Human-readable label that identifies the data store that MongoDB Cloud maps to the collection.'
            storage_databases.#.collections.#.data_sources.#.urls: '- URLs of the publicly accessible data files. You can''t specify URLs that require authentication.'
            storage_databases.#.collections.#.name: '- Name of the collection.'
            storage_databases.#.name: '- Name of the database to which the Federated Database Instance maps the data contained in the data store.'
            storage_databases.#.views: '-     Array of objects where each object represents an aggregation pipeline on a collection. To learn more about views, see Views.'
            storage_databases.#.views.#.name: '- Name of the view.'
            storage_databases.#.views.#.pipeline: '- Aggregation pipeline stage(s) to apply to the source collection.'
            storage_databases.#.views.#.source: '-  Name of the source collection for the view.'
            storage_stores: '- Each object in the array represents a data store. Federated Database uses the storage.databases configuration details to map data in each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see stores. An empty object indicates that the Federated Database Instance has no configured data stores.'
            storage_stores.#.allow_insecure: '- Flag that validates the scheme in the specified URLs.'
            storage_stores.#.bucket: '- Name of the AWS S3 bucket.'
            storage_stores.#.cluster_name: '- Human-readable label of the MongoDB Cloud cluster on which the store is based.'
            storage_stores.#.default_format: '- Default format that Data Lake assumes if it encounters a file without an extension while searching the storeName.'
            storage_stores.#.delimiter: '- The delimiter that separates storage_databases.#.collections.#.data_sources.#.path segments in the data store.'
            storage_stores.#.include_tags: '- Determines whether or not to use S3 tags on the files in the given path as additional partition attributes.'
            storage_stores.#.name: '- Name of the data store.'
            storage_stores.#.prefix: '- Prefix the Federated Database Instance applies when searching for files in the S3 bucket.'
            storage_stores.#.provider: '- Defines where the data is stored.'
            storage_stores.#.public: '- Flag that indicates whether the bucket is public.'
            storage_stores.#.read_preference: '- MongoDB Cloud cluster read preference, which describes how to route read requests to the cluster.'
            storage_stores.#.read_preference.maxStalenessSeconds: '- Maximum replication lag, or staleness, for reads from secondaries.'
            storage_stores.#.read_preference.mode: '- Read preference mode that specifies to which replica set member to route the read requests.'
            storage_stores.#.read_preference.tag_sets: '- List that contains tag sets or tag specification documents.'
            storage_stores.#.read_preference.tags: '- List of all tags within a tag set'
            storage_stores.#.read_preference.tags.name: '- Human-readable label of the tag.'
            storage_stores.#.read_preference.tags.value: '- Value of the tag.'
            storage_stores.#.region: '- Name of the AWS region in which the S3 bucket is hosted.'
            storage_stores.#.urls: '- Comma-separated list of publicly accessible HTTP URLs where data is stored.'
        importStatements: []
    mongodbatlas_federated_query_limit:
        subCategory: ""
        name: mongodbatlas_federated_query_limit
        title: mongodbatlas_federated_query_limit Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "limit_name": "bytesProcessed.weekly",
                  "overrun_policy": "BLOCK",
                  "project_id": "64707f06c519c20c3a2b1b03",
                  "tenant_name": "FederatedDatabseInstance0",
                  "value": 5147483648
                }
        argumentDocs:
            bytesProcessed.daily: ': Limit on the number of bytes processed for the data federation instance for the current day.'
            bytesProcessed.monthly: ': Limit on the number of bytes processed for the data federation instance for the current month.'
            bytesProcessed.query: ': Limit on the number of bytes processed during a single data federation query.'
            bytesProcessed.weekly: ': Limit on the number of bytes processed for the data federation instance for the current week.'
            current_usage: '- Amount that indicates the current usage of the limit.'
            default_limit: '- Default value of the limit.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            lastModifiedDate: '- Only used for Data Federation limits. Timestamp that indicates when this usage limit was last modified. This field uses the ISO 8601 timestamp format in UTC.'
            limit_name: '- (Required) String enum that indicates whether the identity provider is active or not. Accepted values are:'
            maximumLimit: '- Maximum value of the limit.'
            name: '- Name that identifies the user-managed limit to modify.'
            overrun_policy: '- (Required) String enum that identifies action to take when the usage limit is exceeded. If limit span is set to QUERY, this is ignored because MongoDB Cloud stops the query when it exceeds the usage limit. Accepted values are "BLOCK" OR "BLOCK_AND_KILL"'
            project_id: '- (Required) The unique ID for the project to create a Federated Database Instance.'
            tenant_name: '- (Required) Name of the Atlas Federated Database Instance.'
            value: '- (Required) Amount to set the limit to.'
        importStatements: []
    mongodbatlas_federated_settings_identity_provider:
        subCategory: ""
        name: mongodbatlas_federated_settings_identity_provider
        title: mongodbatlas_federated_settings_identity_provider Resource - terraform-provider-mongodbatlas
        examples:
            - name: identity_provider
              manifest: |-
                {
                  "associated_domains": [
                    "yourdomain.com"
                  ],
                  "federation_settings_id": "627a9687f7f7f7f774de306f14",
                  "issuer_uri": "http://www.okta.com/exk17q7f7f7f7fp50h8",
                  "name": "mongodb_federation_test",
                  "request_binding": "HTTP-POST",
                  "response_signature_algorithm": "SHA-256",
                  "sso_debug_enabled": true,
                  "sso_url": "https://mysso.oktapreview.com/app/mysso_terraformtestsso/exk17q7f7f7f7f50h8/sso/saml",
                  "status": "ACTIVE"
                }
        argumentDocs:
            associated_domains: '- List that contains the domains associated with the identity provider.'
            audience: '- (Required for OIDC IdPs) Identifier of the intended recipient of the token used in OIDC IdP.'
            authorization_type: '- (Required for OIDC IdPs) Indicates whether authorization is granted based on group membership or user ID. Valid values are GROUP or USER.'
            client_id: '- Client identifier that is assigned to an application by the OIDC Identity Provider.'
            description: '- (Required for OIDC IdPs) The description of the identity provider.'
            federation_settings_id: '- (Required) Unique 24-hexadecimal digit string that identifies the federated authentication configuration.'
            groups_claim: '- (Required for OIDC IdP with authorization_type = GROUP) Identifier of the claim which contains OIDC IdP Group IDs in the token.'
            idp_id: '- Unique 24-hexadecimal digit string that identifies the IdP.'
            issuer_uri: '- (Required) Unique string that identifies the issuer of the IdP.'
            name: '- (Required) Human-readable label that identifies the identity provider.'
            okta_idp_id: '- Unique 20-hexadecimal digit string that identifies the IdP.'
            protocol: '- The protocol of the identity provider. Either SAML or OIDC.'
            request_binding: '- SAML Authentication Request Protocol HTTP method binding (POST or REDIRECT) that Federated Authentication uses to send the authentication request. Atlas supports the following binding values:'
            requested_scopes: '- Scopes that MongoDB applications will request from the authorization endpoint used for OIDC IdPs.'
            response_signature_algorithm: '- Signature algorithm that Federated Authentication uses to encrypt the identity provider signature.  Valid values include SHA-1 and SHA-256.'
            sso_debug_enabled: '- Flag that indicates whether the identity provider has SSO debug enabled.'
            sso_url: '- Unique string that identifies the intended audience of the SAML assertion.'
            status: '- String enum that indicates whether the identity provider is active or not. Accepted values are ACTIVE or INACTIVE.'
            user_claim: |-
                - (Required for OIDC IdP) Identifier of the claim which contains the user ID in the token used for OIDC IdPs.
                userClaim is required for OIDC IdP with authorizationType GROUP and USER.
        importStatements: []
    mongodbatlas_federated_settings_org_config:
        subCategory: ""
        name: mongodbatlas_federated_settings_org_config
        title: mongodbatlas_federated_settings_org_config Resource - terraform-provider-mongodbatlas
        examples:
            - name: org_connection
              manifest: |-
                {
                  "data_access_identity_provider_ids": [
                    "64d613677e1ad50839cce4db"
                  ],
                  "domain_allow_list": [
                    "mydomain.com"
                  ],
                  "domain_restriction_enabled": false,
                  "federation_settings_id": "627a9687f7f7f7f774de306f14",
                  "identity_provider_id": "0oaqyt9fc2ySTWnA0357",
                  "org_id": "627a9683ea7ff7f74de306f14",
                  "post_auth_role_grants": [
                    "ORG_MEMBER"
                  ]
                }
        argumentDocs:
            data_access_identity_provider_ids: '- (Optional) The collection of unique ids representing the identity providers that can be used for data access in this organization.'
            domain_allow_list: '- List that contains the approved domains from which organization users can log in.'
            domain_restriction_enabled: '- (Required) Flag that indicates whether domain restriction is enabled for the connected organization.'
            email_address: '- Email address of the the user that conflicts with selected domains.'
            federation_settings_id: '- (Required) Unique 24-hexadecimal digit string that identifies the federated authentication configuration.'
            first_name: '- First name of the the user that conflicts with selected domains.'
            identity_provider_id: '- (Optional) Legacy 20-hexadecimal digit string that identifies the SAML access identity provider that this connected org config is associated with. Removing the attribute or providing the value "" will detach/remove the SAML identity provider. This id can be found in two ways:'
            last_name: '- Last name of the the user that conflicts with selected domains.'
            okta_idp_id: on the mongodbatlas_federated_settings_identity_provider resource
            org_id: '- (Required) Unique 24-hexadecimal digit string that identifies the organization that contains your projects.'
            post_auth_role_grants: '- (Optional) List that contains the default roles granted to users who authenticate through the IdP in a connected organization.'
            user_conflicts: '- List that contains the users who have an email address that doesn''t match any domain on the allowed list. See below'
            user_id: '- Name of the Atlas user that conflicts with selected domains.'
        importStatements: []
    mongodbatlas_federated_settings_org_role_mapping:
        subCategory: ""
        name: mongodbatlas_federated_settings_org_role_mapping
        title: mongodbatlas_federated_settings_org_role_mapping Resource - terraform-provider-mongodbatlas
        examples:
            - name: org_group_role_mapping_import
              manifest: |-
                {
                  "external_group_name": "myGrouptest",
                  "federation_settings_id": "627a9687f7f7f7f774de306f14",
                  "org_id": "627a9683e7f7f7ff7fe306f14",
                  "role_assignments": [
                    {
                      "org_id": "627a9683e7f7f7ff7fe306f14",
                      "roles": [
                        "ORG_MEMBER",
                        "ORG_GROUP_CREATOR",
                        "ORG_BILLING_ADMIN"
                      ]
                    },
                    {
                      "group_id": "628aa20d7f7f7f7f7098b81b8",
                      "roles": [
                        "GROUP_OWNER",
                        "GROUP_DATA_ACCESS_ADMIN",
                        "GROUP_SEARCH_INDEX_EDITOR",
                        "GROUP_DATA_ACCESS_READ_ONLY"
                      ]
                    },
                    {
                      "group_id": "628aa20d7f7f7f7f7078b81b8",
                      "roles": [
                        "GROUP_OWNER",
                        "GROUP_DATA_ACCESS_ADMIN",
                        "GROUP_SEARCH_INDEX_EDITOR",
                        "GROUP_DATA_ACCESS_READ_ONLY",
                        "GROUP_DATA_ACCESS_READ_WRITE"
                      ]
                    }
                  ]
                }
        argumentDocs:
            external_group_name: '- Unique human-readable label that identifies the identity provider group to which this role mapping applies.'
            federation_settings_id: '- (Required) Unique 24-hexadecimal digit string that identifies the federated authentication configuration.'
            group_id: '- Unique identifier of the project to which you want the role mapping to apply.'
            org_id: '- Unique 24-hexadecimal digit string that identifies the organization that contains your projects.'
            role_assignments: '- Atlas roles and the unique identifiers of the groups and organizations associated with each role.'
            role_mapping_id: '- Unique 24-hexadecimal digit string that identifies this role mapping.'
            roles: |-
                - Specifies the Roles that are attached to the Role Mapping. Available role IDs can be found on the User Roles
                Reference.
        importStatements: []
    mongodbatlas_flex_cluster:
        subCategory: ""
        name: mongodbatlas_flex_cluster
        title: mongodbatlas_flex_cluster Resource - terraform-provider-mongodbatlas
        examples:
            - name: example-cluster
              manifest: |-
                {
                  "name": "${var.cluster_name}",
                  "project_id": "${var.project_id}",
                  "provider_settings": {
                    "backing_provider_name": "AWS",
                    "region_name": "US_EAST_1"
                  },
                  "termination_protection_enabled": true
                }
              references:
                name: var.cluster_name
                project_id: var.project_id
        argumentDocs:
            backing_provider_name: (String) Cloud service provider on which MongoDB Cloud provisioned the flex cluster.
            backup_settings: (Attributes) Flex backup configuration (see below for nested schema)
            cluster_type: (String) Flex cluster topology.
            connection_strings: (Attributes) Collection of Uniform Resource Locators that point to the MongoDB database. (see below for nested schema)
            create_date: (String) Date and time when MongoDB Cloud created this instance. This parameter expresses its value in ISO 8601 format in UTC.
            disk_size_gb: (Number) Storage capacity available to the flex cluster expressed in gigabytes.
            enabled: (Boolean) Flag that indicates whether backups are performed for this flex cluster. Backup uses TODO for flex clusters.
            id: (String) Unique 24-hexadecimal digit string that identifies the instance.
            mongo_db_version: (String) Version of MongoDB that the instance runs.
            name: (String) Human-readable label that identifies the instance.
            project_id: (String) Unique 24-hexadecimal character string that identifies the project.
            provider_name: (String) Human-readable label that identifies the cloud service provider.
            provider_settings: (Attributes) Group of cloud provider settings that configure the provisioned MongoDB flex cluster. (see below for nested schema)
            region_name: (String) Human-readable label that identifies the geographic location of your MongoDB flex cluster. The region you choose can affect network latency for clients accessing your databases. For a complete list of region names, see AWS, GCP, and Azure.
            standard: (String) Public connection string that you can use to connect to this cluster. This connection string uses the mongodb:// protocol.
            standard_srv: (String) Public connection string that you can use to connect to this flex cluster. This connection string uses the mongodb+srv:// protocol.
            state_name: (String) Human-readable label that indicates the current operating condition of this instance.
            tags: (Map of String) Map that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the instance.
            termination_protection_enabled: (Boolean) Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won't delete the cluster. If set to false, MongoDB Cloud will delete the cluster.
            version_release_system: (String) Method by which the cluster maintains the MongoDB versions.
        importStatements: []
    mongodbatlas_global_cluster_config:
        subCategory: ""
        name: mongodbatlas_global_cluster_config
        title: mongodbatlas_global_cluster_config Resource - terraform-provider-mongodbatlas
        examples:
            - name: config
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.test.name}",
                  "custom_zone_mappings": [
                    {
                      "location": "CA",
                      "zone": "Zone 1"
                    }
                  ],
                  "managed_namespaces": [
                    {
                      "collection": "publishers",
                      "custom_shard_key": "city",
                      "db": "mydata",
                      "is_custom_shard_key_hashed": false,
                      "is_shard_key_unique": false
                    }
                  ],
                  "project_id": "${mongodbatlas_advanced_cluster.test.project_id}"
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.test.name
                project_id: mongodbatlas_advanced_cluster.test.project_id
              dependencies:
                mongodbatlas_advanced_cluster.test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "GEOSHARDED",
                      "name": "\u003cCLUSTER-NAME\u003e",
                      "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M30",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "EU_CENTRAL_1"
                            }
                          ],
                          "zone_name": "Zone 1"
                        },
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M30",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "US_EAST_2"
                            }
                          ],
                          "zone_name": "Zone 2"
                        }
                      ]
                    }
        argumentDocs:
            cluster_name: '- (Required) The name of the Global Cluster.'
            collection: "-\t(Required) The name of the collection associated with the managed namespace."
            custom_shard_key: "- (Required)\tThe custom shard key for the collection. Global Clusters require a compound shard key consisting of a location field and a user-selected second key, the custom shard key."
            custom_zone_mapping: '- (Deprecated) A map of all custom zone mappings defined for the Global Cluster to replication_specs.*.id. This attribute is deprecated, use custom_zone_mapping_zone_id instead.'
            custom_zone_mapping_zone_id: '- A map of all custom zone mappings defined for the Global Cluster to replication_specs.*.zone_id. Atlas automatically maps each location code to the closest geographical zone. Custom zone mappings allow administrators to override these automatic mappings. If your Global Cluster does not have any custom zone mappings, this document is empty.'
            custom_zone_mappings: '- (Optional) Each element in the list maps one ISO location code to a zone in your Global Cluster. See Custom Zone Mapping below for more details.'
            db: '- (Required) The name of the database containing the collection.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            is_custom_shard_key_hashed: '- (Optional) Specifies whether the custom shard key for the collection is hashed. If omitted, defaults to false. If false, Atlas uses ranged sharding. This is only available for Atlas clusters with MongoDB v4.4 and later.'
            is_shard_key_unique: '- (Optional) Specifies whether the underlying index enforces a unique constraint. If omitted, defaults to false. You cannot specify true when using hashed shard keys.'
            location: '- (Required) The ISO location code to which you want to map a zone in your Global Cluster. You can find a list of all supported location codes here.'
            managed_namespaces: '- (Optional) Add a managed namespaces to a Global Cluster. For more information about managed namespaces, see Global Clusters. See Managed Namespace below for more details.'
            project_id: '- (Required) The unique ID for the project to create the database user.'
            zone: '- (Required) The name of the zone in your Global Cluster that you want to map to location.'
        importStatements: []
    mongodbatlas_ldap_configuration:
        subCategory: ""
        name: mongodbatlas_ldap_configuration
        title: mongodbatlas_ldap_configuration Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "authentication_enabled": true,
                  "bind_password": "PASSWORD",
                  "bind_username": "USERNAME",
                  "hostname": "HOSTNAME",
                  "port": 636,
                  "project_id": "${mongodbatlas_project.test.id}"
                }
              references:
                project_id: mongodbatlas_project.test.id
              dependencies:
                mongodbatlas_project.test: |-
                    {
                      "name": "NAME OF THE PROJECT",
                      "org_id": "ORG ID"
                    }
            - name: test
              manifest: |-
                {
                  "authentication_enabled": true,
                  "authz_query_template": "{USER}?memberOf?base",
                  "bind_password": "PASSWORD",
                  "bind_username": "USERNAME",
                  "ca_certificate": "CA CERTIFICATE",
                  "hostname": "HOSTNAME",
                  "port": 636,
                  "project_id": "${mongodbatlas_project.test.id}",
                  "user_to_dn_mapping": [
                    {
                      "ldap_query": "DC=example,DC=com??sub?(userPrincipalName={0})",
                      "match": "(.+)"
                    }
                  ]
                }
              references:
                project_id: mongodbatlas_project.test.id
              dependencies:
                mongodbatlas_project.test: |-
                    {
                      "name": "NAME OF THE PROJECT",
                      "org_id": "ORG ID"
                    }
        argumentDocs:
            authentication_enabled: '- (Required) Specifies whether user authentication with LDAP is enabled.'
            authorization_enabled: '- (Optional) Specifies whether user authorization with LDAP is enabled. You cannot enable user authorization with LDAP without first enabling user authentication with LDAP.'
            authz_query_template: '- (Optional) An LDAP query template that Atlas executes to obtain the LDAP groups to which the authenticated user belongs. Used only for user authorization. Use the {USER} placeholder in the URL to substitute the authenticated username. The query is relative to the host specified with hostname. The formatting for the query must conform to RFC4515 and RFC 4516. If you do not provide a query template, Atlas attempts to use the default value: {USER}?memberOf?base.'
            bind_password: '- (Required) The password used to authenticate the bind_username.'
            bind_username: '- (Required) The user DN that Atlas uses to connect to the LDAP server. Must be the full DN, such as CN=BindUser,CN=Users,DC=myldapserver,DC=mycompany,DC=com.'
            ca_certificate: '- (Optional) CA certificate used to verify the identify of the LDAP server. Self-signed certificates are allowed.'
            hostname: '- (Required) The hostname or IP address of the LDAP server. The server must be visible to the internet or connected to your Atlas cluster with VPC Peering.'
            port: '- (Optional) The port to which the LDAP server listens for client connections. Default: 636'
            project_id: '- (Required) The unique ID for the project to configure LDAP.'
            user_to_dn_mapping: '- (Optional) Maps an LDAP username for authentication to an LDAP Distinguished Name (DN). Each document contains a match regular expression and either a substitution or ldap_query template used to transform the LDAP username extracted from the regular expression. Atlas steps through the each document in the array in the given order, checking the authentication username against the match filter. If a match is found, Atlas applies the transformation and uses the output to authenticate the user. Atlas does not check the remaining documents in the array. For more details and examples see the MongoDB Atlas API Reference.'
            user_to_dn_mapping.0.ldap_query: '- (Optional) An LDAP query formatting template that inserts the LDAP name matched by the match regular expression into an LDAP query URI as specified by RFC 4515 and RFC 4516. Each numeric value is replaced by the corresponding regular expression capture group extracted from the LDAP username that matched the match regular expression.'
            user_to_dn_mapping.0.match: '- (Optional) A regular expression to match against a provided LDAP username. Each parenthesis-enclosed section represents a regular expression capture group used by the substitution or ldap_query template.'
            user_to_dn_mapping.0.substitution: '- (Optional) An LDAP Distinguished Name (DN) formatting template that converts the LDAP name matched by the match regular expression into an LDAP Distinguished Name. Each bracket-enclosed numeric value is replaced by the corresponding regular expression capture group extracted from the LDAP username that matched the match regular expression.'
        importStatements: []
    mongodbatlas_ldap_verify:
        subCategory: ""
        name: mongodbatlas_ldap_verify
        title: mongodbatlas_ldap_verify Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "bind_password": "PASSWORD",
                  "bind_username": "USERNAME",
                  "depends_on": [
                    "${mongodbatlas_advanced_cluster.test}"
                  ],
                  "hostname": "HOSTNAME",
                  "port": 636,
                  "project_id": "${mongodbatlas_project.test.id}"
                }
              references:
                project_id: mongodbatlas_project.test.id
              dependencies:
                mongodbatlas_advanced_cluster.test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "NAME OF THE CLUSTER",
                      "project_id": "${mongodbatlas_project.test.id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "US_EAST_1"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_project.test: |-
                    {
                      "name": "NAME OF THE PROJECT",
                      "org_id": "ORG ID"
                    }
        argumentDocs:
            authz_query_template: '- (Optional) An LDAP query template that Atlas executes to obtain the LDAP groups to which the authenticated user belongs. Used only for user authorization. Use the {USER} placeholder in the URL to substitute the authenticated username. The query is relative to the host specified with hostname. The formatting for the query must conform to RFC4515 and RFC 4516. If you do not provide a query template, Atlas attempts to use the default value: {USER}?memberOf?base.'
            bind_password: '- (Required) The password used to authenticate the bind_username.'
            bind_username: '- (Required) The user DN that Atlas uses to connect to the LDAP server. Must be the full DN, such as CN=BindUser,CN=Users,DC=myldapserver,DC=mycompany,DC=com.'
            ca_certificate: '- (Optional) CA certificate used to verify the identify of the LDAP server. Self-signed certificates are allowed.'
            hostname: '- (Required) The hostname or IP address of the LDAP server. The server must be visible to the internet or connected to your Atlas cluster with VPC Peering.'
            links: '- One or more links to sub-resources. The relations in the URLs are explained in the Web Linking Specification.'
            port: '- (Optional) The port to which the LDAP server listens for client connections. Default: 636'
            project_id: '- (Required) The unique ID for the project to configure LDAP.'
            request_id: '- The unique identifier for the request to verify the LDAP over TLS/SSL configuration.'
            status: '- The current status of the LDAP over TLS/SSL configuration. One of the following values: PENDING, SUCCESS, and FAILED.'
            validations: '- Array of validation messages related to the verification of the provided LDAP over TLS/SSL configuration details. The array contains a document for each test that Atlas runs. Atlas stops running tests after the first failure. The following return values can be seen here: Values'
        importStatements: []
    mongodbatlas_maintenance_window:
        subCategory: ""
        name: mongodbatlas_maintenance_window
        title: mongodbatlas_maintenance_window Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "day_of_week": 3,
                  "hour_of_day": 4,
                  "project_id": "\u003cyour-project-id\u003e"
                }
            - name: test
              manifest: |-
                {
                  "defer": true,
                  "project_id": "\u003cyour-project-id\u003e"
                }
        argumentDocs:
            auto_defer: '- Defer any scheduled maintenance for the given project for one week.'
            auto_defer_once_enabled: '- Flag that indicates whether you want to defer all maintenance windows one week they would be triggered.'
            day_of_week: '- (Required) Day of the week when you would like the maintenance window to start as a 1-based integer: Su=1, M=2, T=3, W=4, T=5, F=6, Sa=7.'
            defer: '- Defer the next scheduled maintenance for the given project for one week.'
            hour_of_day: '- Hour of the day when you would like the maintenance window to start. This parameter uses the 24-hour clock, where midnight is 0, noon is 12 (Time zone is UTC).'
            number_of_deferrals: '- Number of times the current maintenance event for this project has been deferred, there can be a maximum of 2 deferrals.'
            project_id: '- The unique identifier of the project for the Maintenance Window.'
            start_asap: '- Flag indicating whether project maintenance has been directed to start immediately. If you request that maintenance begin immediately, this field returns true from the time the request was made until the time the maintenance event completes.'
        importStatements: []
    mongodbatlas_mongodb_employee_access_grant:
        subCategory: ""
        name: mongodbatlas_mongodb_employee_access_grant
        title: mongodbatlas_mongodb_employee_access_grant Resource - terraform-provider-mongodbatlas
        examples:
            - name: example
              manifest: |-
                {
                  "cluster_name": "${var.cluster_name}",
                  "expiration_time": "2025-01-01T12:00:00Z",
                  "grant_type": "CLUSTER_INFRASTRUCTURE_AND_APP_SERVICES_SYNC_DATA",
                  "project_id": "${var.project_id}"
                }
              references:
                cluster_name: var.cluster_name
                project_id: var.project_id
        argumentDocs:
            cluster_name: (String) Human-readable label that identifies this cluster.
            expiration_time: (String) Expiration date for the employee access grant.
            grant_type: (String) Level of access to grant to MongoDB Employees. Possible values are CLUSTER_DATABASE_LOGS, CLUSTER_INFRASTRUCTURE or CLUSTER_INFRASTRUCTURE_AND_APP_SERVICES_SYNC_DATA.
            project_id: (String) Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        importStatements: []
    mongodbatlas_network_container:
        subCategory: ""
        name: mongodbatlas_network_container
        title: mongodbatlas_network_container Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "10.8.0.0/21",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_name": "AWS",
                  "region_name": "US_EAST_1"
                }
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "10.8.0.0/21",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_name": "GCP",
                  "regions": [
                    "US_EAST_4",
                    "US_WEST_3"
                  ]
                }
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "10.8.0.0/21",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_name": "AZURE",
                  "region": "US_EAST_2"
                }
        argumentDocs:
            atlas_cidr_block: '- (Required) CIDR block that Atlas uses for the Network Peering containers in your project.  Atlas uses the specified CIDR block for all other Network Peering connections created in the project. The Atlas CIDR block must be at least a /24 and at most a /21 in one of the following private networks:'
            azure_subscription_id: '- Unique identifier of the Azure subscription in which the VNet resides.'
            container_id: '- The Network Peering Container ID.'
            gcp_project_id: '- Unique identifier of the GCP project in which the network peer resides. Returns null. This value is populated once you create a new network peering connection with the network peering resource.'
            id: '- Terraform''s unique identifier used internally for state management.'
            network_name: '- Unique identifier of the Network Peering connection in the Atlas project. Returns null. This value is populated once you create a new network peering connection with the network peering resource.'
            project_id: '- (Required) Unique identifier for the Atlas project for this Network Peering Container.'
            provider_name: '- (Required GCP and AZURE, Optional but recommended for AWS) Cloud provider for this Network Peering connection.  Accepted values are GCP, AWS, AZURE. If omitted, Atlas sets this parameter to AWS.'
            provisioned: '- Indicates whether the project has Network Peering connections deployed in the container.'
            region: '- (Required AZURE only) Atlas region where the container resides, see the reference list for Atlas Azure region names Azure.'
            region_name: '- (Required AWS only) The Atlas AWS region name for where this container will exist, see the reference list for Atlas AWS region names AWS.'
            regions: '- (Optional GCP only) Atlas regions where the container resides. Provide this field only if you provide an atlas_cidr_block smaller than /18. GCP Regions values.'
            vnet_name: "- \tThe name of the Azure VNet. Returns null. This value is populated once you create a new network peering connection with the network peering resource."
            vpc_id: '- Unique identifier of Atlas'' AWS VPC.'
        importStatements: []
    mongodbatlas_network_peering:
        subCategory: ""
        name: mongodbatlas_network_peering
        title: mongodbatlas_network_peering Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "accepter_region_name": "us-east-1",
                  "aws_account_id": "abc123abc123",
                  "container_id": "507f1f77bcf86cd799439011",
                  "project_id": "${local.project_id}",
                  "provider_name": "AWS",
                  "route_table_cidr_block": "192.168.0.0/24",
                  "vpc_id": "vpc-abc123abc123"
                }
              references:
                project_id: local.project_id
              dependencies:
                aws_vpc_peering_connection_accepter.peer: |-
                    {
                      "auto_accept": true,
                      "vpc_peering_connection_id": "${mongodbatlas_network_peering.test.connection_id}"
                    }
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "10.8.0.0/21",
                      "project_id": "${local.project_id}",
                      "provider_name": "AWS",
                      "region_name": "US_EAST_1"
                    }
            - name: test
              manifest: |-
                {
                  "container_id": "${mongodbatlas_network_container.test.container_id}",
                  "gcp_project_id": "${local.GCP_PROJECT_ID}",
                  "network_name": "default",
                  "project_id": "${local.project_id}",
                  "provider_name": "GCP"
                }
              references:
                container_id: mongodbatlas_network_container.test.container_id
                gcp_project_id: local.GCP_PROJECT_ID
                project_id: local.project_id
              dependencies:
                google_compute_network_peering.peering: |-
                    {
                      "name": "peering-gcp-terraform-test",
                      "network": "${data.google_compute_network.default.self_link}",
                      "peer_network": "https://www.googleapis.com/compute/v1/projects/${mongodbatlas_network_peering.test.atlas_gcp_project_id}/global/networks/${mongodbatlas_network_peering.test.atlas_vpc_name}"
                    }
                mongodbatlas_advanced_cluster.test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "depends_on": [
                        "${google_compute_network_peering.peering}"
                      ],
                      "name": "terraform-manually-test",
                      "project_id": "${local.project_id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "GCP",
                              "region_name": "US_EAST_4"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "10.8.0.0/21",
                      "project_id": "${local.project_id}",
                      "provider_name": "GCP"
                    }
            - name: test
              manifest: |-
                {
                  "azure_directory_id": "${local.AZURE_DIRECTORY_ID}",
                  "azure_subscription_id": "${local.AZURE_SUBSCRIPTION_ID}",
                  "container_id": "${mongodbatlas_network_container.test.container_id}",
                  "project_id": "${local.project_id}",
                  "provider_name": "AZURE",
                  "resource_group_name": "${local.AZURE_RESOURCES_GROUP_NAME}",
                  "vnet_name": "${local.AZURE_VNET_NAME}"
                }
              references:
                azure_directory_id: local.AZURE_DIRECTORY_ID
                azure_subscription_id: local.AZURE_SUBSCRIPTION_ID
                container_id: mongodbatlas_network_container.test.container_id
                project_id: local.project_id
                resource_group_name: local.AZURE_RESOURCES_GROUP_NAME
                vnet_name: local.AZURE_VNET_NAME
              dependencies:
                mongodbatlas_advanced_cluster.test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "depends_on": [
                        "${mongodbatlas_network_peering.test}"
                      ],
                      "name": "terraform-manually-test",
                      "project_id": "${local.project_id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AZURE",
                              "region_name": "US_EAST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "${local.ATLAS_CIDR_BLOCK}",
                      "project_id": "${local.project_id}",
                      "provider_name": "AZURE",
                      "region": "US_EAST_2"
                    }
            - name: mongo_peer
              manifest: |-
                {
                  "accepter_region_name": "us-east-2",
                  "aws_account_id": "${local.AWS_ACCOUNT_ID}",
                  "container_id": "${one(values(mongodbatlas_advanced_cluster.test.container_id))}",
                  "project_id": "${local.project_id}",
                  "provider_name": "AWS",
                  "route_table_cidr_block": "172.31.0.0/16",
                  "vpc_id": "${aws_default_vpc.default.id}"
                }
              references:
                aws_account_id: local.AWS_ACCOUNT_ID
                project_id: local.project_id
                vpc_id: aws_default_vpc.default.id
              dependencies:
                aws_default_vpc.default: |-
                    {
                      "tags": {
                        "Name": "Default VPC"
                      }
                    }
                aws_vpc_peering_connection_accepter.aws_peer: |-
                    {
                      "auto_accept": true,
                      "tags": {
                        "Side": "Accepter"
                      },
                      "vpc_peering_connection_id": "${mongodbatlas_network_peering.mongo_peer.connection_id}"
                    }
                mongodbatlas_advanced_cluster.test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "terraform-manually-test",
                      "project_id": "${local.project_id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "US_EAST_1"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "192.168.0.0/18",
                  "container_id": "${one(values(mongodbatlas_advanced_cluster.test.replication_specs[0].container_id))}",
                  "gcp_project_id": "${local.GCP_PROJECT_ID}",
                  "network_name": "default",
                  "project_id": "${local.project_id}",
                  "provider_name": "GCP"
                }
              references:
                gcp_project_id: local.GCP_PROJECT_ID
                project_id: local.project_id
              dependencies:
                google_compute_network_peering.peering: |-
                    {
                      "name": "peering-gcp-terraform-test",
                      "network": "${data.google_compute_network.default.self_link}",
                      "peer_network": "https://www.googleapis.com/compute/v1/projects/${mongodbatlas_network_peering.test.atlas_gcp_project_id}/global/networks/${mongodbatlas_network_peering.test.atlas_vpc_name}"
                    }
                mongodbatlas_advanced_cluster.test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "terraform-manually-test",
                      "project_id": "${local.project_id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "GCP",
                              "region_name": "US_EAST_2"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "azure_directory_id": "${local.AZURE_DIRECTORY_ID}",
                  "azure_subscription_id": "${local.AZURE_SUBSCRIPTION_ID}",
                  "container_id": "${one(values(mongodbatlas_advanced_cluster.test.replication_specs[0].container_id))}",
                  "project_id": "${local.project_id}",
                  "provider_name": "AZURE",
                  "resource_group_name": "${local.AZURE_RESOURCE_GROUP_NAME}",
                  "vnet_name": "${local.AZURE_VNET_NAME}"
                }
              references:
                azure_directory_id: local.AZURE_DIRECTORY_ID
                azure_subscription_id: local.AZURE_SUBSCRIPTION_ID
                project_id: local.project_id
                resource_group_name: local.AZURE_RESOURCE_GROUP_NAME
                vnet_name: local.AZURE_VNET_NAME
              dependencies:
                mongodbatlas_advanced_cluster.test: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "name": "cluster-azure",
                      "project_id": "${local.project_id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AZURE",
                              "region_name": "US_EAST_2"
                            }
                          ]
                        }
                      ]
                    }
        argumentDocs:
            accepter_region_name: '- (Required - AWS) Specifies the AWS region where the peer VPC resides. For complete lists of supported regions, see Amazon Web Services.'
            atlas_gcp_project_id: '- The Atlas GCP Project ID for the GCP VPC used by your atlas cluster that is needed to set up the reciprocal connection.'
            atlas_vpc_name: '- Name of the GCP VPC used by your atlas cluster that is needed to set up the reciprocal connection.'
            aws_account_id: '- (Required - AWS) AWS Account ID of the owner of the peer VPC.'
            azure_directory_id: '- (Required - AZURE) Unique identifier for an Azure AD directory.'
            azure_subscription_id: '- (Required - AZURE) Unique identifier of the Azure subscription in which the VNet resides.'
            connection_id: '-  Unique identifier of the Atlas network peering container.'
            container_id: '- (Required) Unique identifier of the MongoDB Atlas container for the provider (GCP) or provider/region (AWS, AZURE). You can create an MongoDB Atlas container using the network_container resource or it can be obtained from the cluster returned values if a cluster has been created before the first container.'
            error_message: '- When "status" : "FAILED", Atlas provides a description of the error.'
            error_state: '- Description of the Atlas error when status is Failed, Otherwise, Atlas returns null.'
            error_state_name: '- Error state, if any. The VPC peering connection error state value can be one of the following: REJECTED, EXPIRED, INVALID_ARGUMENT.'
            gcp_project_id: '- (Required - GCP) GCP project ID of the owner of the network peer.'
            id: '- Terraform''s unique identifier used internally for state management.'
            network_name: '- (Required - GCP) Name of the network peer to which Atlas connects.'
            peer_id: '- Unique identifier of the Atlas network peer.'
            project_id: '- (Required) The unique ID for the MongoDB Atlas project to create the database user.'
            provider_name: '- (Required) Cloud provider to whom the peering connection is being made. (Possible Values AWS, AZURE, GCP).'
            resource_group_name: '- (Required - AZURE) Name of your Azure resource group.'
            route_table_cidr_block: '- (Required - AWS) AWS VPC CIDR block or subnet.'
            status: '- Status of the Atlas network peering connection.  Azure/GCP: ADDING_PEER, AVAILABLE, FAILED, DELETING GCP Only:  WAITING_FOR_USER.'
            status_name: '- (AWS Only) The VPC peering connection status value can be one of the following: INITIATING, PENDING_ACCEPTANCE, FAILED, FINALIZING, AVAILABLE, TERMINATING.'
            vnet_name: '- (Required - AZURE) Name of your Azure VNet.'
            vpc_id: '- (Required) Unique identifier of the AWS peer VPC (Note: this is not the same as the Atlas AWS VPC that is returned by the network_container resource).'
        importStatements: []
    mongodbatlas_online_archive:
        subCategory: ""
        name: mongodbatlas_online_archive
        title: mongodbatlas_online_archive Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${var.cluster_name}",
                  "coll_name": "${var.collection_name}",
                  "criteria": [
                    {
                      "date_field": "dateField",
                      "expire_after_days": 5,
                      "type": "DATE"
                    }
                  ],
                  "db_name": "${var.database_name}",
                  "partition_fields": [
                    {
                      "field_name": "dateField",
                      "order": 0
                    },
                    {
                      "field_name": "firstName",
                      "order": 1
                    },
                    {
                      "field_name": "lastName",
                      "order": 2
                    }
                  ],
                  "project_id": "${var.project_id}",
                  "schedule": [
                    {
                      "end_hour": 1,
                      "end_minute": 1,
                      "start_hour": 1,
                      "start_minute": 1,
                      "type": "DAILY"
                    }
                  ]
                }
              references:
                cluster_name: var.cluster_name
                coll_name: var.collection_name
                db_name: var.database_name
                project_id: var.project_id
            - name: test
              manifest: |-
                {
                  "cluster_name": "${var.cluster_name}",
                  "coll_name": "${var.collection_name}",
                  "criteria": [
                    {
                      "query": "{ \"department\": \"engineering\" }",
                      "type": "CUSTOM"
                    }
                  ],
                  "db_name": "${var.database_name}",
                  "partition_fields": [
                    {
                      "field_name": "firstName",
                      "order": 0
                    },
                    {
                      "field_name": "secondName",
                      "order": 1
                    }
                  ],
                  "project_id": "${var.project_id}"
                }
              references:
                cluster_name: var.cluster_name
                coll_name: var.collection_name
                db_name: var.database_name
                project_id: var.project_id
            - name: test
              manifest: |-
                {
                  "cluster_name": "${var.cluster_name}",
                  "coll_name": "${var.collection_name}",
                  "criteria": [
                    {
                      "query": "{ \"department\": \"engineering\" }",
                      "type": "CUSTOM"
                    }
                  ],
                  "data_process_region": [
                    {
                      "cloud_provider": "AZURE",
                      "region": "US_EAST_2"
                    }
                  ],
                  "db_name": "${var.database_name}",
                  "partition_fields": [
                    {
                      "field_name": "firstName",
                      "order": 0
                    }
                  ],
                  "project_id": "${var.project_id}"
                }
              references:
                cluster_name: var.cluster_name
                coll_name: var.collection_name
                db_name: var.database_name
                project_id: var.project_id
        argumentDocs:
            DATE: is selected, the partition_fields.field_name must be completed with the date_field value
            archive_id: '- ID of the online archive.'
            cloud_provider: '- Human-readable label that identifies the Cloud service provider where you wish to store your archived data. AZURE may be selected only if Azure is the Cloud service provider for the cluster and no AWS online archive has been created for the cluster.'
            cluster_name: '- (Required) Name of the cluster that contains the collection.'
            coll_name: '- (Required) Name of the collection.'
            collection_type: '- Type of MongoDB collection that you want to return. This value can be "TIMESERIES" or "STANDARD". Default is "STANDARD".'
            criteria: '- (Required) Criteria to use for archiving data. See criteria.'
            data_expiration_rule: '- (Optional) Rule for specifying when data should be deleted from the archive. See data expiration rule.'
            data_process_region: '- (Optional) Settings to configure the region where you wish to store your archived data. See data process region. This field is immutable hence cannot be updated.'
            date_field: '- Indexed database parameter that stores the date that determines when data moves to the online archive. MongoDB Cloud archives the data when the current date exceeds the date in this database parameter plus the number of days specified through the expireAfterDays parameter.'
            date_format: '- Syntax used to write the date after which data moves to the online archive. Date can be expressed as ISO 8601 or Epoch timestamps. The Epoch timestamp can be expressed as nanoseconds, milliseconds, or seconds. You must set type to DATE if collectionType is TIMESERIES. Valid values:  ISODATE (default), EPOCH_SECONDS, EPOCH_MILLIS, EPOCH_NANOSECONDS.'
            day_of_month: '- Day of the month when the scheduled archive starts. This field should be provided only when schedule type is MONTHLY.'
            day_of_week: '- Day of the week when the scheduled archive starts. The week starts with Monday (1) and ends with Sunday (7). This field should be provided only when schedule type is WEEKLY.'
            db_name: '- (Required) Name of the database that contains the collection.'
            end_hour: '- Hour of the day when the scheduled window to run one online archive ends.'
            end_minute: '- Minute of the hour when the scheduled window to run one online archive ends.'
            expire_after_days: '- Number of days after the value in the criteria.dateField when MongoDB Cloud archives data in the specified cluster.'
            field_name: '- Human-readable label that identifies the parameter that MongoDB Cloud uses to partition data. To specify a nested parameter, use the dot notation.'
            field_type: '- Data type of the parameter that that MongoDB Cloud uses to partition data. Partition parameters of type UUID must be of binary subtype 4. MongoDB Cloud skips partition parameters of type UUID with subtype 3. Valid values: date, int, long, objectId, string, uuid.'
            order: '- Sequence in which MongoDB Cloud slices the collection data to create partitions. The resource expresses this sequence starting with zero. The value of the criteria.dateField parameter defaults as the first item in the partition sequence.'
            partition_fields: '- (Recommended) Fields to use to partition data. You can specify up to two frequently queried fields (or up to three fields when one of them is date_field) to use for partitioning data. Queries that don’t contain the specified fields require a full collection scan of all archived documents, which takes longer and increases your costs. To learn more about how partition improves query performance, see Data Structure in S3. The value of a partition field can be up to a maximum of 700 characters. Documents with values exceeding 700 characters are not archived. See partition fields.'
            paused: '- (Optional) State of the online archive. This is required for pausing an active online archive or resuming a paused online archive. If the collection has another active online archive, the resume request fails.'
            project_id: '- (Required) The unique ID for the project'
            query: '- JSON query to use to select documents for archiving. Atlas uses the specified query with the db.collection.find(query) command. The empty document {} to return all documents is not supported.'
            region: '- Human-readable label that identifies the geographic location of the region where you wish to store your archived data. For allowed values, see MongoDB Atlas API documentation'
            schedule: '- Regular frequency and duration when archiving process occurs. See schedule.'
            start_hour: '- Hour of the day when the when the scheduled window to run one online archive starts.'
            start_minute: '- Minute of the hour when the scheduled window to run one online archive starts.'
            state: '- Status of the online archive. Valid values are: Pending, Archiving, Idle, Pausing, Paused, Orphaned and Deleted'
            sync_creation: '- (Optional) Flag that indicates whether the provider will wait for the state of the online archive to reach IDLE or ACTIVE when creating an online archive. Defaults to false.'
            type: '- Type of criteria (DATE, CUSTOM)'
        importStatements: []
    mongodbatlas_org_invitation:
        subCategory: ""
        name: mongodbatlas_org_invitation
        title: mongodbatlas_org_invitation Resource - terraform-provider-mongodbatlas
        examples:
            - name: test0
              manifest: |-
                {
                  "org_id": "\u003cORG-ID\u003e",
                  "roles": [
                    "ORG_OWNER"
                  ],
                  "username": "test0-acc-username"
                }
            - name: test0
              manifest: |-
                {
                  "org_id": "\u003cORG-ID\u003e",
                  "roles": [
                    "ORG_MEMBER",
                    "ORG_BILLING_ADMIN"
                  ],
                  "username": "test0-acc-username"
                }
            - name: test1
              manifest: |-
                {
                  "org_id": "\u003cORG-ID\u003e",
                  "roles": [
                    "ORG_MEMBER"
                  ],
                  "teams_ids": [
                    "\u003cTEAM-0-ID\u003e",
                    "\u003cTEAM-1-ID\u003e"
                  ],
                  "username": "test1-acc-username"
                }
        argumentDocs:
            created_at: '- Timestamp in ISO 8601 date and time format in UTC when Atlas sent the invitation.'
            expires_at: '- Timestamp in ISO 8601 date and time format in UTC when the invitation expires. Users have 30 days to accept an invitation.'
            id: '- Autogenerated unique string that identifies this resource.'
            invitation_id: '- Unique 24-hexadecimal digit string that identifies the invitation in Atlas.'
            inviter_username: '- Atlas user who invited username to the organization.'
            org_id: '- (Required) Unique 24-hexadecimal digit string that identifies the organization to which you want to invite a user.'
            roles: '- (Required) Atlas roles to assign to the invited user. If the user accepts the invitation, Atlas assigns these roles to them. The MongoDB Documentation describes the roles a user can have.'
            teams_ids: '- (Optional) An array of unique 24-hexadecimal digit strings that identify the teams that the user was invited to join.'
            username: '- (Required) Email address of the invited user. This is the address to which Atlas sends the invite. If the user accepts the invitation, they log in to Atlas with this username.'
        importStatements: []
    mongodbatlas_organization:
        subCategory: ""
        name: mongodbatlas_organization
        title: mongodbatlas_organization Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "description": "test API key from Org Creation Test",
                  "name": "testCreateORG",
                  "org_owner_id": "6205e5fffff79cde6f",
                  "role_names": [
                    "ORG_OWNER"
                  ]
                }
        argumentDocs:
            api_access_list_required: '- (Optional) Flag that indicates whether to require API operations to originate from an IP Address added to the API access list for the specified organization.'
            description: '- (Required) Programmatic API Key description'
            federation_settings_id: '- (Optional) Unique 24-hexadecimal digit string that identifies the federation to link the newly created organization to. If specified, the proposed Organization Owner of the new organization must have the Organization Owner role in an organization associated with the federation.'
            gen_ai_features_enabled: '- (Optional) Flag that indicates whether this organization has access to generative AI features. This setting only applies to Atlas Commercial and defaults to true. With this setting on, Project Owners may be able to enable or disable individual AI features at the project level. To learn more, see https://www.mongodb.com/docs/generative-ai-faq/.'
            multi_factor_auth_required: '- (Optional) Flag that indicates whether to require users to set up Multi-Factor Authentication (MFA) before accessing the specified organization. To learn more, see: https://www.mongodb.com/docs/atlas/security-multi-factor-authentication/.'
            name: '- (Required) The name of the organization you want to create. (Cannot be changed via this Provider after creation.)'
            org_id: '- The organization id.'
            org_owner_id: '- (Required) Unique 24-hexadecimal digit string that identifies the Atlas user that you want to assign the Organization Owner role. This user must be a member of the same organization as the calling API key.  This is only required when authenticating with Programmatic API Keys. MongoDB Atlas Admin API - Get User By Username'
            private_key: '- Redacted private key returned for this organization API key. This key displays unredacted when first created and is saved within the Terraform state file.'
            public_key: '- Public API key value set for the specified organization API key.'
            restrict_employee_access: '- (Optional) Flag that indicates whether to block MongoDB Support from accessing Atlas infrastructure for any deployment in the specified organization without explicit permission. Once this setting is turned on, you can grant MongoDB Support a 24-hour bypass access to the Atlas deployment to resolve support issues. To learn more, see: https://www.mongodb.com/docs/atlas/security-restrict-support-access/.'
            role_names: '- (Required) List of Organization roles that the Programmatic API key needs to have. Ensure that you provide at least one role and ensure all roles are valid for the Organization.  You must specify an array even if you are only associating a single role with the Programmatic API key. The MongoDB Documentation describes the roles that you can assign to a Programmatic API key.'
        importStatements: []
    mongodbatlas_private_endpoint_regional_mode:
        subCategory: ""
        name: mongodbatlas_private_endpoint_regional_mode
        title: mongodbatlas_private_endpoint_regional_mode Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "project_id": "${var.atlasprojectid}"
                }
              references:
                project_id: var.atlasprojectid
              dependencies:
                aws_vpc_endpoint.test_west: |-
                    {
                      "provider": "${aws.west}",
                      "security_group_ids": [
                        "sg-3f238186"
                      ],
                      "service_name": "${mongodbatlas_privatelink_endpoint.test_west.endpoint_service_name}",
                      "subnet_ids": [
                        "subnet-de0406d2"
                      ],
                      "vpc_endpoint_type": "Interface",
                      "vpc_id": "vpc-7fc0a543"
                    }
                mongodbatlas_advanced_cluster.cluster_atlas: |-
                    {
                      "backup_enabled": true,
                      "cluster_type": "GEOSHARDED",
                      "depends_on": [
                        "${mongodbatlas_privatelink_endpoint_service.test_west}",
                        "${mongodbatlas_privatelink_endpoint_service.test_east}",
                        "${mongodbatlas_private_endpoint_regional_mode.test}"
                      ],
                      "name": "${var.cluster_name}",
                      "project_id": "${var.atlasprojectid}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M30",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "${var.atlas_region_east}"
                            },
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M30",
                                  "node_count": 2
                                }
                              ],
                              "priority": 6,
                              "provider_name": "AWS",
                              "region_name": "${var.atlas_region_west}"
                            }
                          ],
                          "zone_name": "Zone 1"
                        },
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M30",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "${var.atlas_region_east}"
                            },
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M30",
                                  "node_count": 2
                                }
                              ],
                              "priority": 6,
                              "provider_name": "AWS",
                              "region_name": "${var.atlas_region_west}"
                            }
                          ],
                          "zone_name": "Zone 1"
                        }
                      ]
                    }
                mongodbatlas_privatelink_endpoint.test_east: |-
                    {
                      "project_id": "var.atlasprojectid"
                    }
                mongodbatlas_privatelink_endpoint.test_west: |-
                    {
                      "project_id": "${var.atlasprojectid}",
                      "provider_name": "AWS",
                      "region": "US_WEST_1"
                    }
                mongodbatlas_privatelink_endpoint_service.test_west: |-
                    {
                      "endpoint_service_id": "${aws_vpc_endpoint.test_west.id}",
                      "private_link_id": "${mongodbatlas_privatelink_endpoint.test_west.private_link_id}",
                      "project_id": "${mongodbatlas_privatelink_endpoint.test_west.project_id}",
                      "provider_name": "AWS"
                    }
        argumentDocs:
            enabled: '- (Optional) Flag that indicates whether the regionalized private endpoint setting is enabled for the project.   Set this value to true to create more than one private endpoint in a cloud provider region to connect to multi-region and global Atlas sharded clusters. You can enable this setting only if your Atlas project contains no replica sets. You can''t disable this setting if you have:'
            mongodbatlas_advanced_cluster.cluster_atlas.connection_strings: will differ based on the value of mongodbatlas_private_endpoint_regional_mode.test.enabled.
            mongodbatlas_advanced_cluster.cluster_atlas.depends_on: '- Make your cluster dependent on the project''s mongodbatlas_private_endpoint_regional_mode as well as any relevant mongodbatlas_privatelink_endpoint_service resources.  See an example.'
            project_id: '- (Required) Unique identifier for the project.'
            timeouts: '- (Optional) The duration of time to wait for Cluster to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint Regional Mode operations is 3h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_privatelink_endpoint:
        subCategory: ""
        name: mongodbatlas_privatelink_endpoint
        title: mongodbatlas_privatelink_endpoint Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "provider_name": "AWS/AZURE",
                  "region": "US_EAST_1",
                  "timeouts": [
                    {
                      "create": "30m",
                      "delete": "20m"
                    }
                  ]
                }
        argumentDocs:
            AVAILABLE: Atlas is creating the network load balancer and VPC endpoint service.
            DELETING: |-
                The AWS PrivateLink connection is being deleted.
                AZURE:
            FAILED: A system failure has occurred.
            INITIATING: Atlas is creating the load balancer and the Private Link Service.
            WAITING_FOR_USER: The Atlas network load balancer and VPC endpoint service are created and ready to receive connection requests. When you receive this status, create an interface endpoint to continue configuring the AWS PrivateLink connection.
            endpoint_group_names: '- GCP network endpoint groups corresponding to the Private Service Connect endpoint service.'
            endpoint_service_name: '- Name of the PrivateLink endpoint service in AWS. Returns null while the endpoint service is being created.'
            error_message: |-
                - Error message pertaining to the AWS PrivateLink connection. Returns null if there are no errors.
                AWS:
            id: '- The Terraform''s unique identifier used internally for state management.'
            interface_endpoints: |-
                - Unique identifiers of the interface endpoints in your VPC that you added to the AWS PrivateLink connection.
                AZURE:
            private_endpoints: '- All private endpoints that you have added to this Azure Private Link Service.'
            private_link_id: '- Unique identifier of the AWS PrivateLink connection.'
            private_link_service_name: |-
                - Name of the Azure Private Link Service that Atlas manages.
                GCP:
            project_id: "- Required \tUnique identifier for the project."
            provider_name: '- (Required) Name of the cloud provider for which you want to create the private endpoint service. Atlas accepts AWS, AZURE or GCP.'
            region: |-
                - (Required) Cloud provider region in which you want to create the private endpoint connection.
                Accepted values are: AWS regions, AZURE regions and GCP regions
            region_name: '- GCP region for the Private Service Connect endpoint service.'
            service_attachment_names: '- Unique alphanumeric and special character strings that identify the service attachments associated with the GCP Private Service Connect endpoint service. Returns an empty list while Atlas creates the service attachments.'
            status: |-
                - Status of the AWS PrivateLink connection or Status of the Azure Private Link Service. Atlas returns one of the following values:
                AWS:
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 1h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_serverless:
        subCategory: ""
        name: mongodbatlas_privatelink_endpoint_serverless
        title: mongodbatlas_privatelink_endpoint_serverless Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "provider_name": "AWS"
                }
              references:
                instance_name: mongodbatlas_serverless_instance.test.name
              dependencies:
                mongodbatlas_serverless_instance.test: |-
                    {
                      "continuous_backup_enabled": true,
                      "name": "test-db",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_settings_backing_provider_name": "AWS",
                      "provider_settings_provider_name": "SERVERLESS",
                      "provider_settings_region_name": "US_EAST_1"
                    }
        argumentDocs:
            cloud_provider_endpoint_id: '- Unique string that identifies the private endpoint''s network interface.'
            comment: '- Human-readable string to associate with this private endpoint.'
            endpoint_id: '- Unique 24-hexadecimal digit string that identifies the private endpoint.'
            endpoint_service_name: '- Unique string that identifies the PrivateLink endpoint service.'
            instance_name: '- (Required) Human-readable label that identifies the serverless instance.'
            private_link_service_resource_id: '- Root-relative path that identifies the Azure Private Link Service that MongoDB Cloud manages.'
            project_id: '- (Required) Unique 24-digit hexadecimal string that identifies the project.'
            provider_name: '- (Required) Cloud provider name; AWS is currently supported'
            status: '- Human-readable label that indicates the current operating status of the private endpoint. Values include: RESERVATION_REQUESTED, RESERVED, INITIATING, AVAILABLE, FAILED, DELETING.'
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_service:
        subCategory: ""
        name: mongodbatlas_privatelink_endpoint_service
        title: mongodbatlas_privatelink_endpoint_service Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "endpoint_service_id": "${aws_vpc_endpoint.ptfe_service.id}",
                  "private_link_id": "${mongodbatlas_privatelink_endpoint.test.private_link_id}",
                  "project_id": "${mongodbatlas_privatelink_endpoint.test.project_id}",
                  "provider_name": "AWS"
                }
              references:
                endpoint_service_id: aws_vpc_endpoint.ptfe_service.id
                private_link_id: mongodbatlas_privatelink_endpoint.test.private_link_id
                project_id: mongodbatlas_privatelink_endpoint.test.project_id
              dependencies:
                aws_vpc_endpoint.ptfe_service: |-
                    {
                      "security_group_ids": [
                        "sg-3f238186"
                      ],
                      "service_name": "${mongodbatlas_privatelink_endpoint.test.endpoint_service_name}",
                      "subnet_ids": [
                        "subnet-de0406d2"
                      ],
                      "vpc_endpoint_type": "Interface",
                      "vpc_id": "vpc-7fc0a543"
                    }
                mongodbatlas_privatelink_endpoint.test: |-
                    {
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_name": "AWS",
                      "region": "US_EAST_1"
                    }
            - name: test
              manifest: |-
                {
                  "endpoint_service_id": "${azurerm_private_endpoint.test.id}",
                  "private_endpoint_ip_address": "${azurerm_private_endpoint.test.private_service_connection.0.private_ip_address}",
                  "private_link_id": "${mongodbatlas_privatelink_endpoint.test.private_link_id}",
                  "project_id": "${mongodbatlas_privatelink_endpoint.test.project_id}",
                  "provider_name": "AZURE"
                }
              references:
                endpoint_service_id: azurerm_private_endpoint.test.id
                private_endpoint_ip_address: azurerm_private_endpoint.test.private_service_connection.0.private_ip_address
                private_link_id: mongodbatlas_privatelink_endpoint.test.private_link_id
                project_id: mongodbatlas_privatelink_endpoint.test.project_id
              dependencies:
                azurerm_private_endpoint.test: |-
                    {
                      "location": "${data.azurerm_resource_group.test.location}",
                      "name": "endpoint-test",
                      "private_service_connection": [
                        {
                          "is_manual_connection": true,
                          "name": "${mongodbatlas_privatelink_endpoint.test.private_link_service_name}",
                          "private_connection_resource_id": "${mongodbatlas_privatelink_endpoint.test.private_link_service_resource_id}",
                          "request_message": "Azure Private Link test"
                        }
                      ],
                      "resource_group_name": "${var.resource_group_name}",
                      "subnet_id": "${azurerm_subnet.test.id}"
                    }
                mongodbatlas_privatelink_endpoint.test: |-
                    {
                      "project_id": "${var.project_id}",
                      "provider_name": "AZURE",
                      "region": "eastus2"
                    }
            - name: test
              manifest: |-
                {
                  "depends_on": [
                    "${google_compute_forwarding_rule.default}"
                  ],
                  "dynamic": {
                    "endpoints": [
                      {
                        "content": [
                          {
                            "endpoint_name": "${google_compute_forwarding_rule.default[endpoints.key].name}",
                            "ip_address": "${endpoints.value[\"address\"]}"
                          }
                        ],
                        "for_each": "${google_compute_address.default}"
                      }
                    ]
                  },
                  "endpoint_service_id": "${google_compute_network.default.name}",
                  "gcp_project_id": "${var.gcp_project}",
                  "private_link_id": "${mongodbatlas_privatelink_endpoint.test.private_link_id}",
                  "project_id": "${mongodbatlas_privatelink_endpoint.test.project_id}",
                  "provider_name": "GCP"
                }
              references:
                dynamic.content.ip_address: endpoints.value["address"]
                dynamic.for_each: google_compute_address.default
                endpoint_service_id: google_compute_network.default.name
                gcp_project_id: var.gcp_project
                private_link_id: mongodbatlas_privatelink_endpoint.test.private_link_id
                project_id: mongodbatlas_privatelink_endpoint.test.project_id
              dependencies:
                google_compute_address.default: |-
                    {
                      "address": "10.0.42.${count.index}",
                      "address_type": "INTERNAL",
                      "count": 50,
                      "depends_on": [
                        "${mongodbatlas_privatelink_endpoint.test}"
                      ],
                      "name": "tf-test${count.index}",
                      "project": "${google_compute_subnetwork.default.project}",
                      "region": "${var.gcp_region}",
                      "subnetwork": "${google_compute_subnetwork.default.id}"
                    }
                google_compute_forwarding_rule.default: |-
                    {
                      "count": 50,
                      "ip_address": "${google_compute_address.default[count.index].id}",
                      "load_balancing_scheme": "",
                      "name": "${google_compute_address.default[count.index].name}",
                      "network": "${google_compute_network.default.id}",
                      "project": "${google_compute_address.default[count.index].project}",
                      "region": "${google_compute_address.default[count.index].region}",
                      "target": "${mongodbatlas_privatelink_endpoint.test.service_attachment_names[count.index]}"
                    }
                google_compute_network.default: |-
                    {
                      "name": "my-network",
                      "project": "${var.gcp_project}"
                    }
                google_compute_subnetwork.default: |-
                    {
                      "ip_cidr_range": "10.0.0.0/16",
                      "name": "my-subnet",
                      "network": "${google_compute_network.default.id}",
                      "project": "${google_compute_network.default.project}",
                      "region": "${var.gcp_region}"
                    }
                mongodbatlas_privatelink_endpoint.test: |-
                    {
                      "project_id": "${var.project_id}",
                      "provider_name": "GCP",
                      "region": "${var.gcp_region}"
                    }
        argumentDocs:
            AVAILABLE: '- Atlas VPC resources are connected to the VPC endpoint in your VPC. You can connect to Atlas clusters in this region using AWS PrivateLink.'
            DELETING: '- Atlas is removing the interface endpoint from the private endpoint connection.'
            FAILED: '- Atlas failed to accept the connection your private endpoint.'
            INITIATING: '- Atlas has not yet accepted the connection to your private endpoint.'
            NONE: '- Atlas created the network load balancer and VPC endpoint service, but AWS hasn’t yet created the VPC endpoint.'
            PENDING: '- AWS is establishing the connection between your VPC endpoint and the Atlas VPC endpoint service.'
            PENDING_ACCEPTANCE: '- AWS has received the connection request from your VPC endpoint to the Atlas VPC endpoint service.'
            REJECTED: '- AWS failed to establish a connection between Atlas VPC resources to the VPC endpoint in your VPC.'
            aws_connection_status: |-
                - Status of the interface endpoint for AWS.
                Returns one of the following values:
            azure_status: |-
                - Status of the interface endpoint for AZURE.
                Returns one of the following values:
            delete_requested: '- Indicates if Atlas received a request to remove the interface endpoint from the private endpoint connection.'
            endpoint_group_name: '- (Optional) Unique identifier of the endpoint group. The endpoint group encompasses all of the endpoints that you created in GCP.'
            endpoint_service_id: '- (Required) Unique identifier of the interface endpoint you created in your VPC with the AWS, AZURE or GCP resource.'
            endpoints: '- (Optional) Collection of individual private endpoints that comprise your endpoint group. Only for GCP. See below.'
            endpoints.endpoint_name: '- (Optional) Forwarding rule that corresponds to the endpoint you created in GCP.'
            endpoints.ip_address: '- (Optional) Private IP address of the endpoint you created in GCP.'
            error_message: '- Error message pertaining to the interface endpoint. Returns null if there are no errors.'
            gcp_project_id: '- (Optional) Unique identifier of the GCP project in which you created your endpoints. Only for GCP.'
            gcp_status: |-
                - Status of the interface endpoint for GCP.
                Returns one of the following values:
            id: '- The Terraform''s unique identifier used internally for state management.'
            interface_endpoint_id: '- Unique identifier of the interface endpoint.'
            private_endpoint_connection_name: '- Name of the connection for this private endpoint that Atlas generates.'
            private_endpoint_ip_address: '- (Optional) Private IP address of the private endpoint network interface you created in your Azure VNet. Only for AZURE.'
            private_endpoint_resource_id: '- Unique identifier of the private endpoint.'
            private_link_id: '- (Required) Unique identifier of the AWS or AZURE PrivateLink connection which is created by mongodbatlas_privatelink_endpoint resource.'
            project_id: '- (Required) Unique identifier for the project.'
            provider_name: '- (Required) Cloud provider for which you want to create a private endpoint. Atlas accepts AWS, AZURE or GCP.'
            status: '- Status of the endpoint. Atlas returns one of the values shown above.'
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_service_data_federation_online_archive:
        subCategory: ""
        name: mongodbatlas_privatelink_endpoint_service_data_federation_online_archive
        title: mongodbatlas_privatelink_endpoint_service_data_federation_online_archive Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "comment": "Test",
                  "customer_endpoint_dns_name": "${aws_vpc_endpoint.test.dns_entry[0].dns_name}",
                  "endpoint_id": "${aws_vpc_endpoint.test.id}",
                  "project_id": "${mongodbatlas_project.atlas-project.id}",
                  "provider_name": "AWS",
                  "region": "US_EAST_1"
                }
              references:
                customer_endpoint_dns_name: aws_vpc_endpoint.test.dns_entry[0].dns_name
                endpoint_id: aws_vpc_endpoint.test.id
                project_id: mongodbatlas_project.atlas-project.id
              dependencies:
                aws_vpc_endpoint.test: |-
                    {
                      "security_group_ids": [
                        "sg-3f238186"
                      ],
                      "service_name": "\u003cSERVICE-NAME\u003e",
                      "subnet_ids": [
                        "subnet-de0406d2"
                      ],
                      "vpc_endpoint_type": "Interface",
                      "vpc_id": "vpc-7fc0a543"
                    }
                mongodbatlas_project.atlas-project: |-
                    {
                      "name": "${var.atlas_project_name}",
                      "org_id": "${var.atlas_org_id}"
                    }
        argumentDocs:
            comment: '- (Optional) Human-readable string to associate with this private endpoint.'
            customer_endpoint_dns_name: '- (Optional) Human-readable label to identify VPC endpoint DNS name.'
            endpoint_id: (Required) - Unique 22-character alphanumeric string that identifies the private endpoint. See Atlas Data Lake supports Amazon Web Services private endpoints using the AWS PrivateLink feature.
            project_id: (Required) - Unique 24-hexadecimal digit string that identifies your project.
            provider_name: (Required) - Human-readable label that identifies the cloud service provider.
            region: '-  Human-readable label to identify the region of VPC endpoint.  Requires the Atlas region name, see the reference list for AWS, GCP, Azure.'
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is definded by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
            type: '- Human-readable label that identifies the resource type associated with this private endpoint.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_service_serverless:
        subCategory: ""
        name: mongodbatlas_privatelink_endpoint_service_serverless
        title: mongodbatlas_privatelink_endpoint_service_serverless Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cloud_provider_endpoint_id": "${aws_vpc_endpoint.ptfe_service.id}",
                  "comment": "New serverless endpoint",
                  "endpoint_id": "${mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id}",
                  "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "provider_name": "AWS"
                }
              references:
                cloud_provider_endpoint_id: aws_vpc_endpoint.ptfe_service.id
                endpoint_id: mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id
                instance_name: mongodbatlas_serverless_instance.test.name
              dependencies:
                aws_vpc_endpoint.ptfe_service: |-
                    {
                      "security_group_ids": [
                        "sg-3f238186"
                      ],
                      "service_name": "${mongodbatlas_privatelink_endpoint_serverless.test.endpoint_service_name}",
                      "subnet_ids": [
                        "subnet-de0406d2"
                      ],
                      "vpc_endpoint_type": "Interface",
                      "vpc_id": "vpc-7fc0a543"
                    }
                mongodbatlas_privatelink_endpoint_serverless.test: |-
                    {
                      "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_name": "AWS"
                    }
                mongodbatlas_serverless_instance.test: |-
                    {
                      "continuous_backup_enabled": true,
                      "name": "test-db",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_settings_backing_provider_name": "AWS",
                      "provider_settings_provider_name": "SERVERLESS",
                      "provider_settings_region_name": "US_EAST_1"
                    }
            - name: test
              manifest: |-
                {
                  "cloud_provider_endpoint_id": "${azurerm_private_endpoint.test.id}",
                  "comment": "test",
                  "endpoint_id": "${mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id}",
                  "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                  "private_endpoint_ip_address": "${azurerm_private_endpoint.test.private_service_connection.0.private_ip_address}",
                  "project_id": "${mongodbatlas_privatelink_endpoint_serverless.test.project_id}",
                  "provider_name": "AZURE"
                }
              references:
                cloud_provider_endpoint_id: azurerm_private_endpoint.test.id
                endpoint_id: mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id
                instance_name: mongodbatlas_serverless_instance.test.name
                private_endpoint_ip_address: azurerm_private_endpoint.test.private_service_connection.0.private_ip_address
                project_id: mongodbatlas_privatelink_endpoint_serverless.test.project_id
              dependencies:
                azurerm_private_endpoint.test: |-
                    {
                      "location": "${data.azurerm_resource_group.test.location}",
                      "name": "endpoint-test",
                      "private_service_connection": [
                        {
                          "is_manual_connection": true,
                          "name": "${mongodbatlas_privatelink_endpoint_serverless.test.private_link_service_name}",
                          "private_connection_resource_id": "${mongodbatlas_privatelink_endpoint_serverless.test.private_link_service_resource_id}",
                          "request_message": "Azure Private Link test"
                        }
                      ],
                      "resource_group_name": "${var.resource_group_name}",
                      "subnet_id": "${azurerm_subnet.test.id}"
                    }
                mongodbatlas_privatelink_endpoint_serverless.test: |-
                    {
                      "project_id": "${var.project_id}",
                      "provider_name": "AZURE"
                    }
                mongodbatlas_serverless_instance.test: |-
                    {
                      "continuous_backup_enabled": true,
                      "name": "test-db",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_settings_backing_provider_name": "AZURE",
                      "provider_settings_provider_name": "SERVERLESS",
                      "provider_settings_region_name": "US_EAST"
                    }
        argumentDocs:
            cloud_provider_endpoint_id: '- (Optional) Unique string that identifies the private endpoint''s network interface.'
            comment: '- (Optional) Human-readable string to associate with this private endpoint.'
            endpoint_id: '- (Required) Unique 24-hexadecimal digit string that identifies the private endpoint.'
            endpoint_service_name: '- Unique string that identifies the PrivateLink endpoint service.'
            error_message: '- Human-readable error message that indicates the error condition associated with establishing the private endpoint connection.'
            instance_name: '- (Required) Human-readable label that identifies the serverless instance.'
            private_endpoint_ip_address: '- (Optional) IPv4 address of the private endpoint in your Azure VNet that someone added to this private endpoint service.'
            private_link_service_resource_id: '- Root-relative path that identifies the Azure Private Link Service that MongoDB Cloud manages.'
            project_id: '- (Required) Unique 24-digit hexadecimal string that identifies the project.'
            provider_name: '- (Required) Cloud provider for which you want to create a private endpoint. Atlas accepts AWS, AZURE.'
            status: '- Human-readable label that indicates the current operating status of the private endpoint. Values include: RESERVATION_REQUESTED, RESERVED, INITIATING, AVAILABLE, FAILED, DELETING.'
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_project:
        subCategory: ""
        name: mongodbatlas_project
        title: mongodbatlas_project Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "is_collect_database_specifics_statistics_enabled": true,
                  "is_data_explorer_enabled": true,
                  "is_extended_storage_sizes_enabled": true,
                  "is_performance_advisor_enabled": true,
                  "is_realtime_performance_panel_enabled": true,
                  "is_schema_advisor_enabled": true,
                  "is_slow_operation_thresholding_enabled": true,
                  "limits": [
                    {
                      "name": "atlas.project.deployment.clusters",
                      "value": 26
                    },
                    {
                      "name": "atlas.project.deployment.nodesPerPrivateLinkRegion",
                      "value": 51
                    }
                  ],
                  "name": "project-name",
                  "org_id": "${data.mongodbatlas_roles_org_id.test.org_id}",
                  "project_owner_id": "\u003cOWNER_ACCOUNT_ID\u003e",
                  "teams": [
                    {
                      "role_names": [
                        "GROUP_OWNER"
                      ],
                      "team_id": "5e0fa8c99ccf641c722fe645"
                    },
                    {
                      "role_names": [
                        "GROUP_READ_ONLY",
                        "GROUP_DATA_ACCESS_READ_WRITE"
                      ],
                      "team_id": "5e1dd7b4f2a30ba80a70cd4rw"
                    }
                  ]
                }
              references:
                org_id: data.mongodbatlas_roles_org_id.test.org_id
        argumentDocs:
            cluster_count: '- The number of Atlas clusters deployed in the project.'
            created: '- The ISO-8601-formatted timestamp of when Atlas created the project.'
            id: '- The project id.'
            ip_addresses: '- IP addresses in a project categorized by services. See IP Addresses. WARNING: this attribute is deprecated and will be removed in version 1.21.0. Use the mongodbatlas_project_ip_addresses data source instead.'
            is_collect_database_specifics_statistics_enabled: '- (Optional) Flag that indicates whether to enable statistics in cluster metrics collection for the project. By default, this flag is set to true.'
            is_data_explorer_enabled: '- (Optional) Flag that indicates whether to enable Data Explorer for the project. If enabled, you can query your database with an easy to use interface.  When Data Explorer is disabled, you cannot terminate slow operations from the Real-Time Performance Panel or create indexes from the Performance Advisor. You can still view Performance Advisor recommendations, but you must create those indexes from mongosh. By default, this flag is set to true.'
            is_extended_storage_sizes_enabled: '- (Optional) Flag that indicates whether to enable extended storage sizes for the specified project. Clusters with extended storage sizes must be on AWS or GCP, and cannot span multiple regions. When extending storage size, initial syncs and cross-project snapshot restores will be slow. This setting should only be used as a measure of temporary relief; consider sharding if more storage is required.'
            is_performance_advisor_enabled: '- (Optional) Flag that indicates whether to enable Performance Advisor and Profiler for the project. If enabled, you can analyze database logs to recommend performance improvements. By default, this flag is set to true.'
            is_realtime_performance_panel_enabled: '- (Optional) Flag that indicates whether to enable Real Time Performance Panel for the project. If enabled, you can see real time metrics from your MongoDB database. By default, this flag is set to true.'
            is_schema_advisor_enabled: '- (Optional) Flag that indicates whether to enable Schema Advisor for the project. If enabled, you receive customized recommendations to optimize your data model and enhance performance. Disable this setting to disable schema suggestions in the Performance Advisor and the Data Explorer. By default, this flag is set to true.'
            is_slow_operation_thresholding_enabled: '- (Deprecated) (Optional) Flag that enables MongoDB Cloud to use its slow operation threshold for the specified project. The threshold determines which operations the Performance Advisor and Query Profiler considers slow. When enabled, MongoDB Cloud uses the average execution time for operations on your cluster to determine slow-running queries. As a result, the threshold is more pertinent to your cluster workload. The slow operation threshold is enabled by default for dedicated clusters (M10+). When disabled, MongoDB Cloud considers any operation that takes longer than 100 milliseconds to be slow. Note: To use this attribute, the requesting API Key must have the Project Owner role, if not it will show a warning and will return false. If you are not using this field, you don''t need to take any action.'
            name: '- (Required) The name of the project you want to create.'
            org_id: '- (Required) The ID of the organization you want to create the project within.'
            project_owner_id: '- (Optional) Unique 24-hexadecimal digit string that identifies the Atlas user account to be granted the Project Owner role on the specified project. If you set this parameter, it overrides the default value of the oldest Organization Owner.'
            region_usage_restrictions: '- (Optional - set value to GOV_REGIONS_ONLY) Designates that this project can be used for government regions only.  If not set the project will default to standard regions.   You cannot deploy clusters across government and standard regions in the same project. AWS is the only cloud provider for AtlasGov.  For more information see MongoDB Atlas for Government.'
            role_names: '- (Required) Each string in the array represents a project role you want to assign to the team. Every user associated with the team inherits these roles. You must specify an array even if you are only associating a single role with the team. The MongoDB Documentation describes the roles a user can have.'
            services.clusters.#.cluster_name: '- Human-readable label that identifies the cluster.'
            services.clusters.#.inbound: '- List of inbound IP addresses associated with the cluster. If your network allows outbound HTTP requests only to specific IP addresses, you must allow access to the following IP addresses so that your application can connect to your Atlas cluster.'
            services.clusters.#.outbound: '- List of outbound IP addresses associated with the cluster. If your network allows inbound HTTP requests only from specific IP addresses, you must allow access from the following IP addresses so that your Atlas cluster can communicate with your webhooks and KMS.'
            tags: '- (Optional) Map that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the project. See below.'
            team_id: '- (Required) The unique identifier of the team you want to associate with the project. The team and project must share the same parent organization.'
            value: '- (Required) Amount to set the limit to. Use the Project Limit Documentation under limitName parameter to verify the override limits.'
            with_default_alerts_settings: '- (Optional) It allows users to disable the creation of the default alert settings. By default, this flag is set to true.'
        importStatements: []
    mongodbatlas_project_api_key:
        subCategory: ""
        name: mongodbatlas_project_api_key
        title: mongodbatlas_project_api_key Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "description": "Description of your API key",
                  "project_assignment": [
                    {
                      "project_id": "64259ee860c43338194b0f8e",
                      "role_names": [
                        "GROUP_OWNER"
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "description": "Description of your API key",
                  "project_assignment": [
                    {
                      "project_id": "64259ee860c43338194b0f8e",
                      "role_names": [
                        "GROUP_READ_ONLY",
                        "GROUP_OWNER"
                      ]
                    },
                    {
                      "project_id": "74259ee860c43338194b0f8e",
                      "role_names": [
                        "GROUP_READ_ONLY"
                      ]
                    }
                  ]
                }
        argumentDocs:
            api_key_id: '- Unique identifier for this Project API key.'
            description: '- (Required) Description of this Project API key.'
            project_assignment.project_id: '- (Required) Project ID to assign to Access Key'
            project_assignment.role_names: '- (Required) List of Project roles that the Programmatic API key needs to have. Ensure you provide: at least one role and ensure all roles are valid for the Project. You must specify an array even if you are only associating a single role with the Programmatic API key. The MongoDB Documentation describes the valid roles that can be assigned.'
        importStatements: []
    mongodbatlas_project_invitation:
        subCategory: ""
        name: mongodbatlas_project_invitation
        title: mongodbatlas_project_invitation Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    "GROUP_DATA_ACCESS_READ_WRITE"
                  ],
                  "username": "test-acc-username"
                }
            - name: test
              manifest: |-
                {
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    "GROUP_READ_ONLY",
                    "GROUP_DATA_ACCESS_READ_ONLY"
                  ],
                  "username": "test-acc-username"
                }
        argumentDocs:
            created_at: '- Timestamp in ISO 8601 date and time format in UTC when Atlas sent the invitation.'
            expires_at: '- Timestamp in ISO 8601 date and time format in UTC when the invitation expires. Users have 30 days to accept an invitation.'
            id: '- Autogenerated Unique ID for this resource.'
            invitation_id: '- Unique 24-hexadecimal digit string that identifies the invitation in Atlas.'
            inviter_username: '- Atlas user who invited username to the project.'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies the project to which you want to invite a user.'
            roles: '- (Required) List of Atlas roles to assign to the invited user. If the user accepts the invitation, Atlas assigns these roles to them. Refer to the MongoDB Documentation for information on valid roles.'
            username: '- (Required) Email address to which Atlas sent the invitation. The user uses this email address as their Atlas username if they accept this invitation.'
        importStatements: []
    mongodbatlas_project_ip_access_list:
        subCategory: ""
        name: mongodbatlas_project_ip_access_list
        title: mongodbatlas_project_ip_access_list Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cidr_block": "1.2.3.4/32",
                  "comment": "cidr block for tf acc testing",
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "comment": "ip address for tf acc testing",
                  "ip_address": "2.3.4.5",
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "aws_security_group": "sg-0026348ec11780bd1",
                  "comment": "TestAcc for awsSecurityGroup",
                  "depends_on": [
                    "mongodbatlas_network_peering.test"
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
              dependencies:
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "192.168.208.0/21",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_name": "AWS",
                      "region_name": "US_EAST_1"
                    }
                mongodbatlas_network_peering.test: |-
                    {
                      "accepter_region_name": "us-east-1",
                      "aws_account_id": "232589400519",
                      "container_id": "${mongodbatlas_network_container.test.container_id}",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_name": "AWS",
                      "route_table_cidr_block": "172.31.0.0/16",
                      "vpc_id": "vpc-0d93d6f69f1578bd8"
                    }
        argumentDocs:
            aws_security_group: '- (Optional) Unique identifier of the AWS security group to add to the access list. Your access list entry can include only one awsSecurityGroup, one cidrBlock, or one ipAddress.'
            cidr_block: '- (Optional) Range of IP addresses in CIDR notation to be added to the access list. Your access list entry can include only one awsSecurityGroup, one cidrBlock, or one ipAddress.'
            comment: '- (Optional) Comment to add to the access list entry.'
            id: '- Unique identifier used for terraform for internal manages and can be used to import.'
            ip_address: '- (Optional) Single IP address to be added to the access list. Mutually exclusive with awsSecurityGroup and cidrBlock.'
            project_id: '- (Required) Unique identifier for the project to which you want to add one or more access list entries.'
        importStatements: []
    mongodbatlas_push_based_log_export:
        subCategory: ""
        name: mongodbatlas_push_based_log_export
        title: mongodbatlas_push_based_log_export Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "bucket_name": "${aws_s3_bucket.log_bucket.bucket}",
                  "iam_role_id": "${mongodbatlas_cloud_provider_access_authorization.auth_role.role_id}",
                  "prefix_path": "push-based-log-test",
                  "project_id": "${mongodbatlas_project.project-tf.id}"
                }
              references:
                bucket_name: aws_s3_bucket.log_bucket.bucket
                iam_role_id: mongodbatlas_cloud_provider_access_authorization.auth_role.role_id
                project_id: mongodbatlas_project.project-tf.id
              dependencies:
                mongodbatlas_cloud_provider_access_authorization.auth_role: |-
                    {
                      "aws": [
                        {
                          "iam_assumed_role_arn": "${aws_iam_role.test_role.arn}"
                        }
                      ],
                      "project_id": "${mongodbatlas_project.project-tf.id}",
                      "role_id": "${mongodbatlas_cloud_provider_access_setup.setup_only.role_id}"
                    }
                mongodbatlas_cloud_provider_access_setup.setup_only: |-
                    {
                      "project_id": "${mongodbatlas_project.project-tf.id}",
                      "provider_name": "AWS"
                    }
                mongodbatlas_project.project-tf: |-
                    {
                      "name": "${var.atlas_project_name}",
                      "org_id": "${var.atlas_org_id}"
                    }
        argumentDocs:
            bucket_name: (String) The name of the bucket to which the agent sends the logs to.
            create: (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
            create_date: (String) Date and time that this feature was enabled on.
            delete: (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
            iam_role_id: (String) ID of the AWS IAM role that is used to write to the S3 bucket.
            prefix_path: (String) S3 directory in which vector writes in order to store the logs. An empty string denotes the root directory.
            project_id: (String) Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
            state: (String) Describes whether or not the feature is enabled and what status it is in.
            timeouts: (Attributes) (see below for nested schema)
            update: (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
        importStatements: []
    mongodbatlas_resource_policy:
        subCategory: ""
        name: mongodbatlas_resource_policy
        title: mongodbatlas_resource_policy Resource - terraform-provider-mongodbatlas
        examples:
            - name: project_ip_access_list
              manifest: |-
                {
                  "name": "forbid-access-from-anywhere",
                  "org_id": "${var.org_id}",
                  "policies": [
                    {
                      "body": "        forbid (\n                principal,\n                action == cloud::Action::\"project.edit\",\n                resource\n        )\n                when {\n                context.project.ipAccessList.contains(ip(\"0.0.0.0/0\"))\n        };\n"
                    }
                  ]
                }
              references:
                org_id: var.org_id
            - name: cloud_provider
              manifest: |-
                {
                  "name": "forbid-cloud-provider",
                  "org_id": "${var.org_id}",
                  "policies": [
                    {
                      "body": "${templatefile(\"${path.module}/cloud-provider.cedar\", {\n        CLOUD_PROVIDER = \"azure\"\n      })}"
                    },
                    {
                      "body": "${templatefile(\"${path.module}/cloud-provider.cedar\", {\n        CLOUD_PROVIDER = \"aws\"\n      })}"
                    }
                  ]
                }
              references:
                org_id: var.org_id
            - name: cloud_region
              manifest: |-
                {
                  "name": "forbid-cloud-region",
                  "org_id": "${var.org_id}",
                  "policies": [
                    {
                      "body": "${data.cedar_policyset.cloud_region.text}"
                    }
                  ]
                }
              references:
                org_id: var.org_id
        argumentDocs:
            body: (String) A string that defines the permissions for the policy. The syntax used is the Cedar Policy language.
            created_by_user: (Attributes) The user that last updated the Atlas resource policy. (see below for nested schema)
            created_date: (String) Date and time in UTC when the Atlas resource policy was created.
            id: (String) Unique 24-hexadecimal digit string that identifies an Atlas resource policy.
            last_updated_by_user: (Attributes) The user that last updated the Atlas resource policy. (see below for nested schema)
            last_updated_date: (String) Date and time in UTC when the Atlas resource policy was last updated.
            name: (String) Human-readable label that describes the Atlas resource policy.
            org_id: (String) Unique 24-hexadecimal digit string that identifies the organization that contains your projects. Use the /orgs endpoint to retrieve all organizations to which the authenticated user has access.
            policies: (Attributes List) List of policies that make up the Atlas resource policy. (see below for nested schema)
            version: (String) A string that identifies the version of the Atlas resource policy.
        importStatements: []
    mongodbatlas_search_deployment:
        subCategory: ""
        name: mongodbatlas_search_deployment
        title: mongodbatlas_search_deployment Resource - terraform-provider-mongodbatlas
        examples:
            - name: example
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_advanced_cluster.example.name}",
                  "project_id": "${mongodbatlas_project.example.id}",
                  "specs": [
                    {
                      "instance_size": "S20_HIGHCPU_NVME",
                      "node_count": 2
                    }
                  ]
                }
              references:
                cluster_name: mongodbatlas_advanced_cluster.example.name
                project_id: mongodbatlas_project.example.id
              dependencies:
                mongodbatlas_advanced_cluster.example: |-
                    {
                      "cluster_type": "REPLICASET",
                      "name": "ClusterExample",
                      "project_id": "${mongodbatlas_project.example.id}",
                      "replication_specs": [
                        {
                          "region_configs": [
                            {
                              "electable_specs": [
                                {
                                  "instance_size": "M10",
                                  "node_count": 3
                                }
                              ],
                              "priority": 7,
                              "provider_name": "AWS",
                              "region_name": "US_EAST_1"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_project.example: |-
                    {
                      "name": "project-name",
                      "org_id": "${var.org_id}"
                    }
        argumentDocs:
            cluster_name: (String) Label that identifies the cluster to return the search nodes for.
            create: (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
            delete: (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
            id: (String) Unique 24-hexadecimal digit string that identifies the search deployment.
            instance_size: (String) Hardware specification for the search node instance sizes. The MongoDB Atlas API describes the valid values. More details can also be found in the Search Node Documentation.
            node_count: (Number) Number of search nodes in the cluster.
            project_id: (String) Unique 24-hexadecimal digit string that identifies your project.
            specs: (Attributes List) List of settings that configure the search nodes for your cluster. This list is currently limited to defining a single element. (see below for nested schema)
            state_name: (String) Human-readable label that indicates the current operating condition of this search deployment.
            timeouts: (Attributes) (see below for nested schema)
            update: (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
        importStatements: []
    mongodbatlas_search_index:
        subCategory: ""
        name: mongodbatlas_search_index
        title: mongodbatlas_search_index Resource - terraform-provider-mongodbatlas
        examples:
            - name: test-basic-search-index
              manifest: |-
                {
                  "analyzer": "lucene.standard",
                  "cluster_name": "\u003cCLUSTER_NAME\u003e",
                  "collection_name": "collection_test",
                  "database": "database_test",
                  "mappings_dynamic": true,
                  "name": "test-basic-search-index",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "search_analyzer": "lucene.standard"
                }
            - name: test-basic-search-vector
              manifest: |-
                {
                  "cluster_name": "\u003cCLUSTER_NAME\u003e",
                  "collection_name": "collection_test",
                  "database": "database_test",
                  "fields": "[{\n      \"type\": \"vector\",\n      \"path\": \"plot_embedding\",\n      \"numDimensions\": 1536,\n      \"similarity\": \"euclidean\"\n}]\n",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "type": "vectorSearch"
                }
            - name: test-advanced-search-index
              manifest: |-
                {
                  "analyzer": "lucene.standard",
                  "analyzers": " [{\n \"name\": \"index_analyzer_test_name\",\n \"charFilters\": [{\n\"type\": \"mapping\",\n\"mappings\": {\"\\\\\" : \"/\"}\n   \t}],\n \"tokenizer\": {\n \"type\": \"nGram\",\n \"minGram\": 2,\n \"maxGram\": 5\n\t},\n \"tokenFilters\": [{\n\"type\": \"length\",\n\"min\": 20,\n\"max\": 33\n   \t}]\n }]\n",
                  "cluster_name": "\u003cCLUSTER_NAME\u003e",
                  "collection_name": "collection_test",
                  "database": "database_test",
                  "mappings_dynamic": false,
                  "mappings_fields": "{\n      \"address\": {\n        \"type\": \"document\",\n        \"fields\": {\n          \"city\": {\n            \"type\": \"string\",\n            \"analyzer\": \"lucene.simple\",\n            \"ignoreAbove\": 255\n          },\n          \"state\": {\n            \"type\": \"string\",\n            \"analyzer\": \"lucene.english\"\n          }\n        }\n      },\n      \"company\": {\n        \"type\": \"string\",\n        \"analyzer\": \"lucene.whitespace\",\n        \"multi\": {\n          \"mySecondaryAnalyzer\": {\n            \"type\": \"string\",\n            \"analyzer\": \"lucene.french\"\n          }\n        }\n      },\n      \"employees\": {\n        \"type\": \"string\",\n        \"analyzer\": \"lucene.standard\"\n      }\n}\n",
                  "name": "test-advanced-search-index",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "search_analyzer": "lucene.standard",
                  "synonyms": [
                    {
                      "analyzer": "lucene.simple",
                      "name": "synonym_test",
                      "source_collection": "collection_test"
                    }
                  ]
                }
        argumentDocs:
            '<original> : <replacement>': "Example\nanalyzers = <<-EOF [{\n  \"name\":\"name_analyzer\",        \n  \"type\": \"mapping\",\n  \"mappings\":  \n  {\n     \"\\\\\" : \"/\"\n  }\n  }]\n  EOF"
            analyzer: '- Analyzer to use when creating the index. Defaults to lucene.standard'
            analyzers: '- Custom analyzers to use in this index. This is an array of JSON objects.'
            charFilters: '- Array containing zero or more character filters. Always require a type field, and some take additional options as well'
            cluster_name: '- (Required) The name of the cluster where you want to create the search index within.'
            collection_name: '- (Required) Name of the collection the index is on. NOTE: The collection must exist before creating the index.'
            database: '- (Required) Name of the database the collection is in.'
            "false": '- to be case-sensitive and remove only tokens that exactly match the specified case'
            fields: '- Array of Fields to configure this vectorSearch index. It is mandatory for vector searches and it must contain at least one vector type field. This field needs to be a JSON string in order to be decoded correctly.'
            german2: (Alternative German language stemmer. Handles the umlaut by expanding ü to ue in most contexts.)
            group: '- (Required) Index of the character group within the matching expression to extract into tokens. Use 0 to extract all character groups.'
            ignoreCase: '- The flag that indicates whether or not to ignore case of stop words when filtering the tokens to remove. The value can be one of the following:'
            ignoredTags: '- a list of HTML tags to exclude from filtering'
            include: '- to include the original tokens with the encoded tokens in the output of the token filter. We recommend this value if you want queries on both the original tokens as well as the encoded forms.'
            index_id: '- The unique identifier of the Atlas Search index.'
            kp: (Kraaij-Pohlmann stemmer, an alternative stemmer for Dutch.)
            lovins: (The first-ever published "Lovins JB" stemming algorithm.)
            mappings_dynamic: '- Indicates whether the search index uses dynamic or static mapping. For dynamic mapping, set the value to true. For static mapping, specify the fields to index using mappings_fields'
            mappings_fields: '- attribute is required in search indexes when mappings_dynamic is false. This field needs to be a JSON string in order to be decoded correctly.'
            matches: '- (Required) Acceptable values are:'
            max: '- The maximum length of a token. Must be greater than or equal to min.'
            maxGram: '- (Required) Number of characters to include in the longest token created.'
            maxShingleSize: '- (Required) Maximum number of tokens per shingle. Must be greater than or equal to minShingleSize.'
            maxTokenLength: '- Maximum length for a single token. Tokens greater than this length are split at maxTokenLength into multiple tokens.'
            min: '- The minimum length of a token. Must be less than or equal to max.'
            minGram: '- (Required) Number of characters to include in the shortest token created.'
            minShingleSize: '- (Required) Minimum number of tokens per shingle. Must be less than or equal to maxShingleSize.'
            name: '- (Required) The name of the search index you want to create.'
            nfc: (Canonical Decomposition, followed by Canonical Composition)
            nfd: (Canonical Decomposition)
            nfkc: (Compatibility Decomposition, followed by Canonical Composition)
            nfkd: (Compatibility Decomposition)
            normalizationForm: '- Normalization form to apply. Accepted values are:'
            omit: '- to omit the original tokens and include only the encoded tokens in the output of the token filter. Use this value if you want to only query on the encoded forms of the original tokens.'
            originalTokens: '- Specifies whether to include or omit the original tokens in the output of the token filter. Value can be one of the following:'
            pattern: '- (Required) A regular expression to match against.'
            porter: (The original Porter English stemming algorithm.)
            project_id: '- (Required) The ID of the organization or project you want to create the search index within.'
            replacement: '- (Required) Replacement string to substitute wherever a matching pattern occurs.'
            search_analyzer: '- Analyzer to use when searching the index. Defaults to lucene.standard'
            source_collection: '- (Required) Name of the source MongoDB collection for the synonyms. Documents in this collection must be in the format described in the Synonyms Source Collection Documents.'
            status: '- Current status of the index.'
            stemmerName: '- (Required) The following values are valid:'
            stored_source: '- String that can be "true" (store all fields), "false" (default, don''t store any field), or a JSON string that contains the list of fields to store (include) or not store (exclude) on Atlas Search. To learn more, see Stored Source Fields.'
            synonyms: '- Synonyms mapping definition to use in this index.'
            termNotInBounds: '- Accepted values are:'
            termsNotInBounds: '- Accepted values are:'
            timeouts: '- (Optional) The duration of time to wait for Search Index to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Serach Index create & update is 3h. Learn more about timeouts here.'
            token: '- (Required) The list of stop words that correspond to the tokens to remove. Value must be one or more stop words.'
            token_filters: '- Array containing zero or more token filters. Always require a type field, and some take additional options as well:'
            tokenizer: '- (Required) Tokenizer to use in search indexes. Determines how Atlas Search splits up text into discrete chunks of indexing. Always require a type field, and some take additional options as well.'
            "true": '- to ignore case and remove all tokens that match the specified stop words'
            type: '- (Optional) Type of index: search or vectorSearch. Default type is search.'
            types: 'of character filters:'
            wait_for_index_build_completion: '- (Optional) Wait for search index to achieve Active status before terraform considers resource built.'
        importStatements: []
    mongodbatlas_serverless_instance:
        subCategory: ""
        name: mongodbatlas_serverless_instance
        title: mongodbatlas_serverless_instance Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "name": "\u003cSERVERLESS_INSTANCE_NAME\u003e",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "provider_settings_backing_provider_name": "AWS",
                  "provider_settings_provider_name": "SERVERLESS",
                  "provider_settings_region_name": "US_EAST_1"
                }
        argumentDocs:
            auto_indexing: '- (Deprecated, Optional) Flag that indicates whether the serverless instance uses Serverless Auto Indexing. This parameter defaults to true.'
            connection_strings_private_endpoint_srv: '- List of Serverless Private Endpoint Connections'
            connection_strings_standard_srv: '- Public mongodb+srv:// connection string that you can use to connect to this serverless instance.'
            continuous_backup_enabled: '- (Deprecated, Optional) Flag that indicates whether the serverless instance uses Serverless Continuous Backup. If this parameter is false or not used, the serverless instance uses Basic Backup.'
            create_date: '- Timestamp that indicates when MongoDB Cloud created the serverless instance. The timestamp displays in the ISO 8601 date and time format in UTC.'
            id: '- Unique 24-hexadecimal digit string that identifies the serverless instance.'
            key: '- (Required) Constant that defines the set of the tag.'
            mongo_db_version: '- Version of MongoDB that the serverless instance runs, in <major version>.<minor version> format.'
            name: '- (Required) Human-readable label that identifies the serverless instance.'
            project_id: '- (Required) The ID of the organization or project you want to create the serverless instance within.'
            provider_settings_backing_provider_name: '- (Required) Cloud service provider on which MongoDB Cloud provisioned the serverless instance.'
            provider_settings_provider_name: '- (Required) Cloud service provider that applies to the provisioned the serverless instance.'
            provider_settings_region_name: |-
                - (Required)
                Human-readable label that identifies the physical location of your MongoDB serverless instance. The region you choose can affect network latency for clients accessing your databases.
            state_name: '- Stage of deployment of this serverless instance when the resource made its request.'
            tags: '- (Optional) Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.'
            termination_protection_enabled: '- Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won''t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.'
            value: '- (Required) Variable that belongs to the set of the tag.'
        importStatements: []
    mongodbatlas_stream_connection:
        subCategory: ""
        name: mongodbatlas_stream_connection
        title: mongodbatlas_stream_connection Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "Cluster0",
                  "connection_name": "ConnectionName",
                  "instance_name": "InstanceName",
                  "project_id": "${var.project_id}",
                  "type": "Cluster"
                }
              references:
                project_id: var.project_id
            - name: test
              manifest: |-
                {
                  "authentication": {
                    "mechanism": "SCRAM-256",
                    "password": "somepassword",
                    "username": "user"
                  },
                  "bootstrap_servers": "localhost:9091,localhost:9092",
                  "config": {
                    "auto.offset.reset": "latest"
                  },
                  "connection_name": "KafkaConnection",
                  "instance_name": "NewInstance",
                  "project_id": "${var.project_id}",
                  "security": {
                    "protocol": "PLAINTEXT"
                  },
                  "type": "Kafka"
                }
              references:
                project_id: var.project_id
            - name: test
              manifest: |-
                {
                  "authentication": {
                    "mechanism": "PLAIN",
                    "password": "somepassword",
                    "username": "user"
                  },
                  "bootstrap_servers": "localhost:9091,localhost:9092",
                  "config": {
                    "auto.offset.reset": "latest"
                  },
                  "connection_name": "KafkaConnection",
                  "instance_name": "NewInstance",
                  "project_id": "${var.project_id}",
                  "security": {
                    "broker_public_certificate": "-----BEGIN CERTIFICATE-----\u003cCONTENT\u003e-----END CERTIFICATE-----",
                    "protocol": "SSL"
                  },
                  "type": "Kafka"
                }
              references:
                project_id: var.project_id
        argumentDocs:
            access: '- Information about the networking access. See access.'
            authentication: '- User credentials required to connect to a Kafka cluster. Includes the authentication type, as well as the parameters for that authentication mode. See authentication.'
            bootstrap_servers: '- Comma separated list of server addresses.'
            broker_public_certificate: '- A trusted, public x509 certificate for connecting to Kafka over SSL. String value of the certificate must be defined in the attribute.'
            cluster_name: '- Name of the cluster configured for this connection.'
            config: '- A map of Kafka key-value pairs for optional configuration. This is a flat object, and keys can have ''.'' characters.'
            connection_id: '- Id of the Private Link connection when type is PRIVATE_LINK.'
            connection_name: '- (Required) Human-readable label that identifies the stream connection. In the case of the Sample type, this is the name of the sample source.'
            db_role_to_execute: '- The name of a Built in or Custom DB Role to connect to an Atlas Cluster. See DBRoleToExecute.'
            instance_name: '- (Required) Human-readable label that identifies the stream instance.'
            mechanism: '- Style of authentication. Can be one of PLAIN, SCRAM-256, or SCRAM-512.'
            networking: '- Networking Access Type can either be PUBLIC (default) or VPC. See networking.'
            password: '- Password of the account to connect to the Kafka cluster.'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies your project.'
            protocol: '- Describes the transport type. Can be either PLAINTEXT or SSL.'
            role: '- The name of the role to use. Value can be  atlasAdmin, readWriteAnyDatabase, or readAnyDatabase if type is set to BUILT_IN, or the name of a user-defined role if type is set to CUSTOM.'
            security: '- Properties for the secure transport connection to Kafka. For SSL, this can include the trusted certificate to use. See security.'
            type: '- (Required) Type of connection. Can be either Cluster, Kafka or Sample.'
            username: '- Username of the account to connect to the Kafka cluster.'
        importStatements: []
    mongodbatlas_stream_instance:
        subCategory: ""
        name: mongodbatlas_stream_instance
        title: mongodbatlas_stream_instance Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "data_process_region": {
                    "cloud_provider": "AWS",
                    "region": "VIRGINIA_USA"
                  },
                  "instance_name": "InstanceName",
                  "project_id": "${var.project_id}"
                }
              references:
                project_id: var.project_id
        argumentDocs:
            cloud_provider: '- (Required) Label that identifies the cloud service provider where MongoDB Cloud performs stream processing. The MongoDB Atlas API describes the valid values.'
            data_process_region: '- (Required) Cloud service provider and region where MongoDB Cloud performs stream processing. See data process region.'
            hostnames: '- List that contains the hostnames assigned to the stream instance.'
            instance_name: '- (Required) Human-readable label that identifies the stream instance.'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies your project.'
            region: '- (Required) Name of the cloud provider region hosting Atlas Stream Processing. The MongoDB Atlas API describes the valid values.'
            stream_config: '- (Optional) Configuration options for an Atlas Stream Processing Instance. See stream config'
            tier: '- (Required) Selected tier for the Stream Instance. Configures Memory / VCPU allowances. The MongoDB Atlas API describes the valid values.'
        importStatements: []
    mongodbatlas_stream_privatelink_endpoint:
        subCategory: ""
        name: mongodbatlas_stream_privatelink_endpoint
        title: mongodbatlas_stream_privatelink_endpoint Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "dns_domain": "${confluent_network.private_link.dns_domain}",
                  "dns_sub_domain": "${confluent_network.private_link.zonal_subdomains}",
                  "project_id": "${var.project_id}",
                  "provider_name": "AWS",
                  "region": "${var.aws_region}",
                  "service_endpoint_id": "${confluent_network.private_link.aws[0].private_link_endpoint_service}",
                  "vendor": "CONFLUENT"
                }
              references:
                dns_domain: confluent_network.private_link.dns_domain
                dns_sub_domain: confluent_network.private_link.zonal_subdomains
                project_id: var.project_id
                region: var.aws_region
                service_endpoint_id: confluent_network.private_link.aws[0].private_link_endpoint_service
              dependencies:
                confluent_environment.staging: |-
                    {
                      "display_name": "Staging"
                    }
                confluent_kafka_cluster.dedicated: |-
                    {
                      "availability": "MULTI_ZONE",
                      "cloud": "${confluent_network.private_link.cloud}",
                      "dedicated": [
                        {
                          "cku": 2
                        }
                      ],
                      "display_name": "example-dedicated-cluster",
                      "environment": [
                        {
                          "id": "${confluent_environment.staging.id}"
                        }
                      ],
                      "network": [
                        {
                          "id": "${confluent_network.private_link.id}"
                        }
                      ],
                      "region": "${confluent_network.private_link.region}"
                    }
                confluent_network.private_link: |-
                    {
                      "cloud": "AWS",
                      "connection_types": [
                        "PRIVATELINK"
                      ],
                      "display_name": "terraform-test-private-link-network-manual",
                      "dns_config": [
                        {
                          "resolution": "PRIVATE"
                        }
                      ],
                      "environment": [
                        {
                          "id": "${confluent_environment.staging.id}"
                        }
                      ],
                      "region": "${var.aws_region}",
                      "zones": "${keys(var.subnets_to_privatelink)}"
                    }
                confluent_private_link_access.aws: |-
                    {
                      "aws": [
                        {
                          "account": "${var.aws_account_id}"
                        }
                      ],
                      "display_name": "example-private-link-access",
                      "environment": [
                        {
                          "id": "${confluent_environment.staging.id}"
                        }
                      ],
                      "network": [
                        {
                          "id": "${confluent_network.private_link.id}"
                        }
                      ]
                    }
        argumentDocs:
            dns_domain: (String) Domain name of Privatelink connected cluster.
            dns_sub_domain: (List of String) Sub-Domain name of Confluent cluster. These are typically your availability zones.
            id: (String) The ID of the Private Link connection.
            interface_endpoint_id: (String) Interface endpoint ID that is created from the specified service endpoint ID.
            project_id: (String) Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
            provider_name: (String) Provider where the Kafka cluster is deployed.
            region: (String) Domain name of Confluent cluster.
            service_endpoint_id: (String) Service Endpoint ID.
            state: (String) Status of the connection.
            vendor: (String) Vendor who manages the Kafka cluster.
        importStatements: []
    mongodbatlas_stream_processor:
        subCategory: ""
        name: mongodbatlas_stream_processor
        title: mongodbatlas_stream_processor Resource - terraform-provider-mongodbatlas
        examples:
            - name: stream-processor-sample-example
              manifest: |-
                {
                  "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                  "pipeline": "${jsonencode([\n    { \"$source\" = { \"connectionName\" = resource.mongodbatlas_stream_connection.example-sample.connection_name } },\n    { \"$emit\" = { \"connectionName\" : resource.mongodbatlas_stream_connection.example-cluster.connection_name, \"db\" : \"sample\", \"coll\" : \"solar\", \"timeseries\" : { \"timeField\" : \"_ts\" } } }\n  ])}",
                  "processor_name": "sampleProcessorName",
                  "project_id": "${var.project_id}",
                  "state": "STARTED"
                }
              references:
                instance_name: mongodbatlas_stream_instance.example.instance_name
                project_id: var.project_id
              dependencies:
                mongodbatlas_stream_connection.example-cluster: |-
                    {
                      "cluster_name": "${var.cluster_name}",
                      "connection_name": "ClusterConnection",
                      "db_role_to_execute": {
                        "role": "atlasAdmin",
                        "type": "BUILT_IN"
                      },
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "type": "Cluster"
                    }
                mongodbatlas_stream_connection.example-kafka: |-
                    {
                      "authentication": {
                        "mechanism": "PLAIN",
                        "password": "${var.kafka_password}",
                        "username": "${var.kafka_username}"
                      },
                      "bootstrap_servers": "localhost:9092,localhost:9092",
                      "config": {
                        "auto.offset.reset": "earliest"
                      },
                      "connection_name": "KafkaPlaintextConnection",
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "security": {
                        "protocol": "PLAINTEXT"
                      },
                      "type": "Kafka"
                    }
                mongodbatlas_stream_connection.example-sample: |-
                    {
                      "connection_name": "sample_stream_solar",
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "type": "Sample"
                    }
                mongodbatlas_stream_instance.example: |-
                    {
                      "data_process_region": {
                        "cloud_provider": "AWS",
                        "region": "VIRGINIA_USA"
                      },
                      "instance_name": "InstanceName",
                      "project_id": "${var.project_id}"
                    }
            - name: stream-processor-cluster-to-kafka-example
              manifest: |-
                {
                  "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                  "pipeline": "${jsonencode([\n    { \"$source\" = { \"connectionName\" = resource.mongodbatlas_stream_connection.example-cluster.connection_name } },\n    { \"$emit\" = { \"connectionName\" : resource.mongodbatlas_stream_connection.example-kafka.connection_name, \"topic\" : \"topic_from_cluster\" } }\n  ])}",
                  "processor_name": "clusterProcessorName",
                  "project_id": "${var.project_id}",
                  "state": "CREATED"
                }
              references:
                instance_name: mongodbatlas_stream_instance.example.instance_name
                project_id: var.project_id
              dependencies:
                mongodbatlas_stream_connection.example-cluster: |-
                    {
                      "cluster_name": "${var.cluster_name}",
                      "connection_name": "ClusterConnection",
                      "db_role_to_execute": {
                        "role": "atlasAdmin",
                        "type": "BUILT_IN"
                      },
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "type": "Cluster"
                    }
                mongodbatlas_stream_connection.example-kafka: |-
                    {
                      "authentication": {
                        "mechanism": "PLAIN",
                        "password": "${var.kafka_password}",
                        "username": "${var.kafka_username}"
                      },
                      "bootstrap_servers": "localhost:9092,localhost:9092",
                      "config": {
                        "auto.offset.reset": "earliest"
                      },
                      "connection_name": "KafkaPlaintextConnection",
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "security": {
                        "protocol": "PLAINTEXT"
                      },
                      "type": "Kafka"
                    }
                mongodbatlas_stream_connection.example-sample: |-
                    {
                      "connection_name": "sample_stream_solar",
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "type": "Sample"
                    }
                mongodbatlas_stream_instance.example: |-
                    {
                      "data_process_region": {
                        "cloud_provider": "AWS",
                        "region": "VIRGINIA_USA"
                      },
                      "instance_name": "InstanceName",
                      "project_id": "${var.project_id}"
                    }
            - name: stream-processor-kafka-to-cluster-example
              manifest: |-
                {
                  "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                  "options": {
                    "dlq": {
                      "coll": "exampleColumn",
                      "connection_name": "${resource.mongodbatlas_stream_connection.example-cluster.connection_name}",
                      "db": "exampleDb"
                    }
                  },
                  "pipeline": "${jsonencode([\n    { \"$source\" = { \"connectionName\" = resource.mongodbatlas_stream_connection.example-kafka.connection_name, \"topic\" : \"topic_source\" } },\n    { \"$emit\" = { \"connectionName\" : resource.mongodbatlas_stream_connection.example-cluster.connection_name, \"db\" : \"kafka\", \"coll\" : \"topic_source\", \"timeseries\" : { \"timeField\" : \"ts\" } }\n  }])}",
                  "processor_name": "kafkaProcessorName",
                  "project_id": "${var.project_id}",
                  "state": "CREATED"
                }
              references:
                instance_name: mongodbatlas_stream_instance.example.instance_name
                project_id: var.project_id
              dependencies:
                mongodbatlas_stream_connection.example-cluster: |-
                    {
                      "cluster_name": "${var.cluster_name}",
                      "connection_name": "ClusterConnection",
                      "db_role_to_execute": {
                        "role": "atlasAdmin",
                        "type": "BUILT_IN"
                      },
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "type": "Cluster"
                    }
                mongodbatlas_stream_connection.example-kafka: |-
                    {
                      "authentication": {
                        "mechanism": "PLAIN",
                        "password": "${var.kafka_password}",
                        "username": "${var.kafka_username}"
                      },
                      "bootstrap_servers": "localhost:9092,localhost:9092",
                      "config": {
                        "auto.offset.reset": "earliest"
                      },
                      "connection_name": "KafkaPlaintextConnection",
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "security": {
                        "protocol": "PLAINTEXT"
                      },
                      "type": "Kafka"
                    }
                mongodbatlas_stream_connection.example-sample: |-
                    {
                      "connection_name": "sample_stream_solar",
                      "instance_name": "${mongodbatlas_stream_instance.example.instance_name}",
                      "project_id": "${var.project_id}",
                      "type": "Sample"
                    }
                mongodbatlas_stream_instance.example: |-
                    {
                      "data_process_region": {
                        "cloud_provider": "AWS",
                        "region": "VIRGINIA_USA"
                      },
                      "instance_name": "InstanceName",
                      "project_id": "${var.project_id}"
                    }
        argumentDocs:
            coll: (String) Name of the collection to use for the DLQ.
            connection_name: (String) Name of the connection to write DLQ messages to. Must be an Atlas connection.
            db: (String) Name of the database to use for the DLQ.
            dlq: (Attributes) Dead letter queue for the stream processor. Refer to the MongoDB Atlas Docs for more information. (see below for nested schema)
            id: (String) Unique 24-hexadecimal character string that identifies the stream processor.
            instance_name: (String) Human-readable label that identifies the stream instance.
            options: (Attributes) Optional configuration for the stream processor. (see below for nested schema)
            pipeline: (String) Stream aggregation pipeline you want to apply to your streaming data. MongoDB Atlas Docs contain more information. Using jsonencode is recommended when setting this attribute. For more details see the Aggregation Pipelines Documentation
            processor_name: (String) Human-readable label that identifies the stream processor.
            project_id: (String) Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
            state: (String) The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are CREATED, STARTED or STOPPED. When a Stream Processor is created without specifying the state, it will default to CREATED state.
            stats: (String) The stats associated with the stream processor. Refer to the MongoDB Atlas Docs for more information.
        importStatements: []
    mongodbatlas_team:
        subCategory: ""
        name: mongodbatlas_team
        title: mongodbatlas_team Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "name": "myNewTeam",
                  "org_id": "\u003cORGANIZATION-ID\u003e",
                  "usernames": [
                    "user1@email.com",
                    "user2@email.com",
                    "user3@email.com"
                  ]
                }
        argumentDocs:
            id: "-\tThe Terraform's unique identifier used internally for state management."
            name: '- (Required) The name of the team you want to create.'
            org_id: '- (Required) The unique identifier for the organization you want to associate the team with.'
            team_id: '- The unique identifier for the team.'
            usernames: '- (Required) The Atlas usernames (email address). You can only add Atlas users who are part of the organization. Users who have not accepted an invitation to join the organization cannot be added as team members. There is a maximum of 250 Atlas users per team.'
        importStatements: []
    mongodbatlas_teams Resource - terraform-provider-mongodbatlas:
        subCategory: ""
        name: mongodbatlas_teams Resource - terraform-provider-mongodbatlas
        title: mongodbatlas_teams Resource - terraform-provider-mongodbatlas
        argumentDocs: {}
        importStatements: []
    mongodbatlas_third_party_integration:
        subCategory: ""
        name: mongodbatlas_third_party_integration
        title: mongodbatlas_third_party_integration Resource - terraform-provider-mongodbatlas
        examples:
            - name: test_datadog
              manifest: |-
                {
                  "api_key": "\u003cAPI-KEY\u003e",
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "region": "\u003cREGION\u003e",
                  "type": "DATADOG"
                }
        argumentDocs:
            api_key: '- Your API Key.'
            enabled: '- Whether your cluster has Prometheus enabled.'
            id: '- Unique identifier of the integration.'
            microsoft_teams_webhook_url: '-  Your Microsoft Teams incoming webhook URL.'
            password: '- Your Prometheus password.'
            project_id: '- (Required) The unique ID for the project to get all Third-Party service integrations'
            region: (Required) - PagerDuty region that indicates the API Uniform Resource Locator (URL) to use, either "US" or "EU". PagerDuty will use "US" by default.
            routing_key: '- An optional field for your Routing Key.'
            secret: '- An optional field for your webhook secret.'
            service_discovery: '- Indicates which service discovery method is used, either file or http.'
            service_key: '- Your Service Key.'
            type: '- (Required) Third-Party Integration Settings type'
            url: '- Your webhook URL.'
            user_name: '- Your Prometheus username.'
        importStatements: []
    mongodbatlas_x509_authentication_database_user:
        subCategory: ""
        name: mongodbatlas_x509_authentication_database_user
        title: mongodbatlas_x509_authentication_database_user Resource - terraform-provider-mongodbatlas
        examples:
            - name: test
              manifest: |-
                {
                  "months_until_expiration": 2,
                  "project_id": "${mongodbatlas_database_user.user.project_id}",
                  "username": "${mongodbatlas_database_user.user.username}"
                }
              references:
                project_id: mongodbatlas_database_user.user.project_id
                username: mongodbatlas_database_user.user.username
              dependencies:
                mongodbatlas_database_user.user: |-
                    {
                      "database_name": "$external",
                      "labels": [
                        {
                          "key": "My Key",
                          "value": "My Value"
                        }
                      ],
                      "project_id": "64b926dd56206839b1c8bae9",
                      "roles": [
                        {
                          "database_name": "admin",
                          "role_name": "atlasAdmin"
                        }
                      ],
                      "username": "myUsername",
                      "x509_type": "MANAGED"
                    }
            - name: test
              manifest: |-
                {
                  "customer_x509_cas": "-----BEGIN CERTIFICATE-----\nMIICmTCCAgICCQDZnHzklxsT9TANBgkqhkiG9w0BAQsFADCBkDELMAkGA1UEBhMC\nVVMxDjAMBgNVBAgMBVRleGFzMQ8wDQYDVQQHDAZBdXN0aW4xETAPBgNVBAoMCHRl\nc3QuY29tMQ0wCwYDVQQLDARUZXN0MREwDwYDVQQDDAh0ZXN0LmNvbTErMCkGCSqG\nSIb3DQEJARYcbWVsaXNzYS5wbHVua2V0dEBtb25nb2RiLmNvbTAeFw0yMDAyMDQy\nMDQ2MDFaFw0yMTAyMDMyMDQ2MDFaMIGQMQswCQYDVQQGEwJVUzEOMAwGA1UECAwF\nVGV4YXMxDzANBgNVBAcMBkF1c3RpbjERMA8GA1UECgwIdGVzdC5jb20xDTALBgNV\nBAsMBFRlc3QxETAPBgNVBAMMCHRlc3QuY29tMSswKQYJKoZIhvcNAQkBFhxtZWxp\nc3NhLnBsdW5rZXR0QG1vbmdvZGIuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCB\niQKBgQCf1LRqr1zftzdYx2Aj9G76tb0noMPtj6faGLlPji1+m6Rn7RWD9L0ntWAr\ncURxvypa9jZ9MXFzDtLevvd3tHEmfrUT3ukNDX6+Jtc4kWm+Dh2A70Pd+deKZ2/O\nFh8audEKAESGXnTbeJCeQa1XKlIkjqQHBNwES5h1b9vJtFoLJwIDAQABMA0GCSqG\nSIb3DQEBCwUAA4GBADMUncjEPV/MiZUcVNGmktP6BPmEqMXQWUDpdGW2+Tg2JtUA\n7MMILtepBkFzLO+GlpZxeAlXO0wxiNgEmCRONgh4+t2w3e7a8GFijYQ99FHrAC5A\niul59bdl18gVqXia1Yeq/iK7Ohfy/Jwd7Hsm530elwkM/ZEkYDjBlZSXYdyz\n-----END CERTIFICATE-----\"\n",
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
              dependencies:
                mongodbatlas_database_user.user: |-
                    {
                      "database_name": "$external",
                      "labels": [
                        {
                          "key": "My Key",
                          "value": "My Value"
                        }
                      ],
                      "project_id": "64b926dd56206839b1c8bae9",
                      "roles": [
                        {
                          "database_name": "admin",
                          "role_name": "atlasAdmin"
                        }
                      ],
                      "username": "myUsername",
                      "x509_type": "CUSTOMER"
                    }
        argumentDocs:
            certificates: '- Array of objects where each details one unexpired database user certificate.'
            certificates.#.created_at: '- Timestamp in ISO 8601 date and time format in UTC when Atlas created this X.509 certificate.'
            certificates.#.group_id: '- Unique identifier of the Atlas project to which this certificate belongs.'
            certificates.#.id: '- Serial number of this certificate.'
            certificates.#.not_after: '- Timestamp in ISO 8601 date and time format in UTC when this certificate expires.'
            certificates.#.subject: '- Fully distinguished name of the database user to which this certificate belongs. To learn more, see RFC 2253.'
            current_certificate: '- Contains the last X.509 certificate and private key created for a database user.'
            customer_x509_cas: '- (Optional) PEM string containing one or more customer CAs for database user authentication.'
            months_until_expiration: '- (Required) A number of months that the created certificate is valid for before expiry, up to 24 months. By default is 3.'
            project_id: '- (Required) Identifier for the Atlas project associated with the X.509 configuration.'
            username: '- (Optional) Username of the database user to create a certificate for.'
        importStatements: []
